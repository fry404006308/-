
# transformer测试


sentences: 

```python
[['我 喜 欢 你 P', 'S I love you . P', 'I love you . E P']]
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>中文字典库</div>


src_vocab: 

```python
{'P': 0, '我': 1, '喜': 2, '欢': 3, '你': 4}
```


src_idx2word: 

```python
{0: 'P', 1: '我', 2: '喜', 3: '欢', 4: '你'}
```


src_vocab_size: 

```python
5
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>英语字典库</div>


tgt_vocab: 

```python
{'P': 0, 'I': 1, 'love': 2, 'you': 3, 'S': 4, 'E': 5, '.': 6}
```


idx2word: 

```python
{0: 'P', 1: 'I', 2: 'love', 3: 'you', 4: 'S', 5: 'E', 6: '.'}
```


tgt_vocab_size: 

```python
7
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>裁剪的句子的长度</div>


src_len: 

```python
5
```


tgt_len: 

```python
6
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>超参数</div>


d_model: 

```python
4
```


d_ff: 

```python
8
```


d_k = d_v: 

```python
2
```


n_layers: 

```python
2
```


n_heads: 

```python
2
```


# make_data


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


sentences: 

```python
[['我 喜 欢 你 P', 'S I love you . P', 'I love you . E P']]
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


enc_inputs: 

```python
[[1, 2, 3, 4, 0]]
```


dec_inputs: 

```python
[[4, 1, 2, 3, 6, 0]]
```


dec_outputs: 

```python
[[1, 2, 3, 6, 5, 0]]
```


# 训练阶段


# 训练的每个epoch


# ----------------------


# ----------------------


# -------训练epoch：1


# 训练每一个loader中的数据：1


# Transformer


# 阶段一：encoder


<div style='color:#fe618e;font-weight:800;font-size:23px;'>encoder得到注意力操作</div>


: 

```python
enc_outputs, enc_self_attns = self.encoder(enc_inputs)
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


enc_inputs: 

```python
tensor([[1, 2, 3, 4, 0]])
```


enc_inputs.shape: 

```python
torch.Size([1, 5])
```


# Encoder中


<div style='color:#3296ee;font-weight:800;font-size:23px;'>enc_inputs转换为词向量的结果</div>


: 

```python
enc_outputs = self.src_emb(enc_inputs)
```


enc_outputs: 

```python
tensor([[[-0.9033, -1.7691, -0.0503, -0.9602],
         [ 0.4731, -1.6754, -0.2503, -1.5553],
         [ 0.3855, -0.1603, -1.3074,  0.1681],
         [-1.0159, -0.1112, -1.7430,  0.2556],
         [ 0.7371, -0.8480,  1.6767,  0.6005]]], grad_fn=<EmbeddingBackward0>)
```


enc_outputs.shape: 

```python
torch.Size([1, 5, 4])
```


## PositionalEncoding


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入加上位置编码的代码</div>


加上位置编码: 

```python
x = x + self.pe[:x.size(0), :]
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


x: 

```python
tensor([[[-0.9033, -1.7691, -0.0503, -0.9602]],

        [[ 0.4731, -1.6754, -0.2503, -1.5553]],

        [[ 0.3855, -0.1603, -1.3074,  0.1681]],

        [[-1.0159, -0.1112, -1.7430,  0.2556]],

        [[ 0.7371, -0.8480,  1.6767,  0.6005]]], grad_fn=<TransposeBackward0>)
```


x.shape: 

```python
torch.Size([5, 1, 4])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>位置编码</div>


self.pe[:x.size(0), :]: 

```python
tensor([[[ 0.0000,  1.0000,  0.0000,  1.0000]],

        [[ 0.8415,  0.5403,  0.0100,  0.9999]],

        [[ 0.9093, -0.4161,  0.0200,  0.9998]],

        [[ 0.1411, -0.9900,  0.0300,  0.9996]],

        [[-0.7568, -0.6536,  0.0400,  0.9992]]])
```


self.pe[:x.size(0), :].shape: 

```python
torch.Size([5, 1, 4])
```


self.pe.shape: 

```python
torch.Size([5000, 1, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


x: 

```python
tensor([[[-0.9033, -0.7691, -0.0503,  0.0398]],

        [[ 1.3146, -1.1351, -0.2403, -0.5554]],

        [[ 1.2948, -0.5764, -1.2874,  1.1679]],

        [[-0.8748, -1.1012, -1.7130,  1.2552]],

        [[-0.0197, -1.5016,  1.7167,  1.5997]]], grad_fn=<AddBackward0>)
```


x.shape: 

```python
torch.Size([5, 1, 4])
```


## get_attn_pad_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq_q: 

```python
tensor([[1, 2, 3, 4, 0]])
```


seq_q.shape: 

```python
torch.Size([1, 5])
```


seq_k: 

```python
tensor([[1, 2, 3, 4, 0]])
```


seq_k.shape: 

```python
torch.Size([1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>获取对应的大小：len_q,len_k</div>


例如: 

```python
batch_size, len_q = seq_q.size()
```


batch_size: 

```python
1
```


len_q: 

```python
5
```


len_k: 

```python
5
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>操作pad_attn_mask矩阵：pad_attn_mask</div>


: 

```python
pad_attn_mask = seq_k.data.eq(0).unsqueeze(1) 
```


pad_attn_mask: 

```python
tensor([[[False, False, False, False,  True]]])
```


pad_attn_mask.shape: 

```python
torch.Size([1, 1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>扩展pad_attn_mask矩阵：pad_attn_mask.expand</div>


: 

```python
ans = pad_attn_mask.expand(batch_size, len_q, len_k)  
```


ans: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


ans.shape: 

```python
torch.Size([1, 5, 5])
```


# EncoderLayer


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-1.0037, -0.8545, -0.0559,  0.0000],
         [ 1.4607, -1.2613, -0.2670, -0.6171],
         [ 1.4386, -0.6405, -1.4305,  1.2976],
         [-0.9720, -1.2236, -1.9033,  1.3946],
         [-0.0219, -1.6685,  1.9075,  1.7774]]], grad_fn=<TransposeBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_K: 

```python
tensor([[[-1.0037, -0.8545, -0.0559,  0.0000],
         [ 1.4607, -1.2613, -0.2670, -0.6171],
         [ 1.4386, -0.6405, -1.4305,  1.2976],
         [-0.9720, -1.2236, -1.9033,  1.3946],
         [-0.0219, -1.6685,  1.9075,  1.7774]]], grad_fn=<TransposeBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[-1.0037, -0.8545, -0.0559,  0.0000],
         [ 1.4607, -1.2613, -0.2670, -0.6171],
         [ 1.4386, -0.6405, -1.4305,  1.2976],
         [-0.9720, -1.2236, -1.9033,  1.3946],
         [-0.0219, -1.6685,  1.9075,  1.7774]]], grad_fn=<TransposeBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 5, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 0.5486, -0.0024],
          [ 0.3651,  0.7367],
          [ 0.7668, -0.0645],
          [ 1.5571, -0.3391],
          [ 0.3256, -0.6269]],

         [[-0.4436,  0.4987],
          [-0.3974, -0.0523],
          [ 0.5901,  0.8618],
          [ 0.3035,  1.7109],
          [-1.1874,  0.7385]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 5, 2])
```


K: 

```python
tensor([[[[-0.3750,  0.2073],
          [ 0.5386, -0.3521],
          [ 0.3337, -1.1683],
          [-0.6905, -0.6425],
          [ 0.5358, -0.4218]],

         [[-0.2399, -0.2088],
          [ 0.4445, -0.5414],
          [ 0.4398, -0.3704],
          [-0.3306, -0.1365],
          [ 0.7679, -1.7900]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.6400, -0.7188],
          [-0.1696,  0.2414],
          [-0.0791,  0.7242],
          [ 0.6861, -0.5659],
          [ 2.2878, -0.2239]],

         [[-0.4936, -0.2400],
          [ 0.4682,  0.1232],
          [ 0.9266, -0.0937],
          [-0.1753, -0.5173],
          [ 0.3382, -0.3859]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 0.5486, -0.0024],
          [ 0.3651,  0.7367],
          [ 0.7668, -0.0645],
          [ 1.5571, -0.3391],
          [ 0.3256, -0.6269]],

         [[-0.4436,  0.4987],
          [-0.3974, -0.0523],
          [ 0.5901,  0.8618],
          [ 0.3035,  1.7109],
          [-1.1874,  0.7385]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 5, 2])
```


K: 

```python
tensor([[[[-0.3750,  0.2073],
          [ 0.5386, -0.3521],
          [ 0.3337, -1.1683],
          [-0.6905, -0.6425],
          [ 0.5358, -0.4218]],

         [[-0.2399, -0.2088],
          [ 0.4445, -0.5414],
          [ 0.4398, -0.3704],
          [-0.3306, -0.1365],
          [ 0.7679, -1.7900]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.6400, -0.7188],
          [-0.1696,  0.2414],
          [-0.0791,  0.7242],
          [ 0.6861, -0.5659],
          [ 2.2878, -0.2239]],

         [[-0.4936, -0.2400],
          [ 0.4682,  0.1232],
          [ 0.9266, -0.0937],
          [-0.1753, -0.5173],
          [ 0.3382, -0.3859]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[-1.4581e-01,  2.0952e-01,  1.3137e-01, -2.6677e-01,  2.0855e-01],
          [ 1.1154e-02, -4.4375e-02, -5.2246e-01, -5.1298e-01, -8.1395e-02],
          [-2.1279e-01,  3.0811e-01,  2.3423e-01, -3.4507e-01,  3.0978e-01],
          [-4.6259e-01,  6.7745e-01,  6.4747e-01, -6.0620e-01,  6.9109e-01],
          [-1.7821e-01,  2.8009e-01,  5.9468e-01,  1.2585e-01,  3.1033e-01]],

         [[ 1.6135e-03, -3.3033e-01, -2.6857e-01,  5.5569e-02, -8.7209e-01],
          [ 7.5126e-02, -1.0486e-01, -1.0988e-01,  9.7937e-02, -1.4954e-01],
          [-2.2732e-01, -1.4445e-01, -4.2173e-02, -2.2110e-01, -7.7034e-01],
          [-3.0405e-01, -5.5958e-01, -3.5369e-01, -2.3602e-01, -2.0007e+00],
          [ 9.2386e-02, -6.5592e-01, -5.6272e-01,  2.0632e-01, -1.5795e+00]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[-1.4581e-01,  2.0952e-01,  1.3137e-01, -2.6677e-01, -1.0000e+09],
          [ 1.1154e-02, -4.4375e-02, -5.2246e-01, -5.1298e-01, -1.0000e+09],
          [-2.1279e-01,  3.0811e-01,  2.3423e-01, -3.4507e-01, -1.0000e+09],
          [-4.6259e-01,  6.7745e-01,  6.4747e-01, -6.0620e-01, -1.0000e+09],
          [-1.7821e-01,  2.8009e-01,  5.9468e-01,  1.2585e-01, -1.0000e+09]],

         [[ 1.6135e-03, -3.3033e-01, -2.6857e-01,  5.5569e-02, -1.0000e+09],
          [ 7.5126e-02, -1.0486e-01, -1.0988e-01,  9.7937e-02, -1.0000e+09],
          [-2.2732e-01, -1.4445e-01, -4.2173e-02, -2.2110e-01, -1.0000e+09],
          [-3.0405e-01, -5.5958e-01, -3.5369e-01, -2.3602e-01, -1.0000e+09],
          [ 9.2386e-02, -6.5592e-01, -5.6272e-01,  2.0632e-01, -1.0000e+09]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[0.2159, 0.3080, 0.2848, 0.1913, 0.0000],
          [0.3200, 0.3028, 0.1877, 0.1895, 0.0000],
          [0.1952, 0.3286, 0.3052, 0.1710, 0.0000],
          [0.1246, 0.3895, 0.3780, 0.1079, 0.0000],
          [0.1639, 0.2591, 0.3549, 0.2221, 0.0000]],

         [[0.2828, 0.2029, 0.2158, 0.2985, 0.0000],
          [0.2710, 0.2264, 0.2253, 0.2773, 0.0000],
          [0.2328, 0.2529, 0.2801, 0.2342, 0.0000],
          [0.2634, 0.2040, 0.2506, 0.2819, 0.0000],
          [0.3212, 0.1520, 0.1668, 0.3600, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.1946,  0.0172],
          [ 0.2686, -0.1283],
          [ 0.1624,  0.0633],
          [ 0.0578,  0.2172],
          [ 0.1852,  0.0761]],

         [[ 0.1031, -0.2175],
          [ 0.1323, -0.2017],
          [ 0.2220, -0.1721],
          [ 0.1483, -0.2074],
          [ 0.0041, -0.2602]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[0.2159, 0.3080, 0.2848, 0.1913, 0.0000],
          [0.3200, 0.3028, 0.1877, 0.1895, 0.0000],
          [0.1952, 0.3286, 0.3052, 0.1710, 0.0000],
          [0.1246, 0.3895, 0.3780, 0.1079, 0.0000],
          [0.1639, 0.2591, 0.3549, 0.2221, 0.0000]],

         [[0.2828, 0.2029, 0.2158, 0.2985, 0.0000],
          [0.2710, 0.2264, 0.2253, 0.2773, 0.0000],
          [0.2328, 0.2529, 0.2801, 0.2342, 0.0000],
          [0.2634, 0.2040, 0.2506, 0.2819, 0.0000],
          [0.3212, 0.1520, 0.1668, 0.3600, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 5, 5])
```


context: 

```python
tensor([[[[ 0.1946,  0.0172],
          [ 0.2686, -0.1283],
          [ 0.1624,  0.0633],
          [ 0.0578,  0.2172],
          [ 0.1852,  0.0761]],

         [[ 0.1031, -0.2175],
          [ 0.1323, -0.2017],
          [ 0.2220, -0.1721],
          [ 0.1483, -0.2074],
          [ 0.0041, -0.2602]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.1946,  0.0172,  0.1031, -0.2175],
         [ 0.2686, -0.1283,  0.1323, -0.2017],
         [ 0.1624,  0.0633,  0.2220, -0.1721],
         [ 0.0578,  0.2172,  0.1483, -0.2074],
         [ 0.1852,  0.0761,  0.0041, -0.2602]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[ 0.0177, -0.1582, -0.0230, -0.0975],
         [ 0.0430, -0.1818,  0.0259, -0.1288],
         [-0.0325, -0.1687, -0.0135, -0.1458],
         [-0.0571, -0.1270, -0.0775, -0.0848],
         [ 0.0418, -0.1424, -0.0585, -0.0493]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 5, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-1.0037, -0.8545, -0.0559,  0.0000],
         [ 1.4607, -1.2613, -0.2670, -0.6171],
         [ 1.4386, -0.6405, -1.4305,  1.2976],
         [-0.9720, -1.2236, -1.9033,  1.3946],
         [-0.0219, -1.6685,  1.9075,  1.7774]]], grad_fn=<TransposeBackward0>)
```


residual.shape: 

```python
torch.Size([1, 5, 4])
```


output + residual: 

```python
tensor([[[-0.9860, -1.0127, -0.0789, -0.0975],
         [ 1.5036, -1.4431, -0.2411, -0.7458],
         [ 1.4061, -0.8091, -1.4440,  1.1518],
         [-1.0292, -1.3505, -1.9809,  1.3098],
         [ 0.0199, -1.8109,  1.8489,  1.7281]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-0.9704, -1.0290,  1.0200,  0.9793],
         [ 1.5935, -1.1125, -0.0087, -0.4722],
         [ 1.0840, -0.7216, -1.2391,  0.8768],
         [-0.2141, -0.4723, -0.9788,  1.6652],
         [-0.2862, -1.5145,  0.9409,  0.8598]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 5, 4])
```


## PoswiseFeedForwardNet


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


inputs: 

```python
tensor([[[-0.9704, -1.0290,  1.0200,  0.9793],
         [ 1.5935, -1.1125, -0.0087, -0.4722],
         [ 1.0840, -0.7216, -1.2391,  0.8768],
         [-0.2141, -0.4723, -0.9788,  1.6652],
         [-0.2862, -1.5145,  0.9409,  0.8598]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc操作的代码</div>


: 

```python
output = self.fc(inputs)
```


inputs: 

```python
tensor([[[-0.9704, -1.0290,  1.0200,  0.9793],
         [ 1.5935, -1.1125, -0.0087, -0.4722],
         [ 1.0840, -0.7216, -1.2391,  0.8768],
         [-0.2141, -0.4723, -0.9788,  1.6652],
         [-0.2862, -1.5145,  0.9409,  0.8598]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc原来是d_model->d_ff->d_model</div>


self.fc: 

```python
Sequential(
  (0): Linear(in_features=4, out_features=8, bias=False)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=4, bias=False)
)
```


output: 

```python
tensor([[[-3.2820e-04,  2.3777e-02,  4.2785e-02,  2.6195e-02],
         [ 2.4934e-01,  2.9844e-01,  1.1603e-02,  2.4589e-01],
         [ 3.1429e-01,  2.1498e-01,  1.1845e-01,  4.3631e-01],
         [ 7.0957e-02,  1.6719e-01,  8.0164e-02,  1.6070e-01],
         [ 7.5027e-03,  1.4379e-02,  6.8875e-02,  2.8172e-02]]],
       grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 5, 4])
```


## 前馈层后的层归一化和残差


<div style='color:#fe618e;font-weight:800;font-size:23px;'>FeedForward后的层归一化和残差</div>


: 

```python
ans = nn.LayerNorm(d_model).to(device)(output + residual)
```


residual: 

```python
tensor([[[-0.9704, -1.0290,  1.0200,  0.9793],
         [ 1.5935, -1.1125, -0.0087, -0.4722],
         [ 1.0840, -0.7216, -1.2391,  0.8768],
         [-0.2141, -0.4723, -0.9788,  1.6652],
         [-0.2862, -1.5145,  0.9409,  0.8598]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>残差和层归一化之后的结果</div>


ans: 

```python
tensor([[[-0.9827, -1.0168,  1.0281,  0.9714],
         [ 1.6523, -1.0221, -0.1998, -0.4305],
         [ 1.0187, -0.7027, -1.2576,  0.9417],
         [-0.2566, -0.4147, -0.9941,  1.6655],
         [-0.3034, -1.5051,  0.9642,  0.8444]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans.shape: 

```python
torch.Size([1, 5, 4])
```


# EncoderLayer


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-0.9827, -1.0168,  1.0281,  0.9714],
         [ 1.6523, -1.0221, -0.1998, -0.4305],
         [ 1.0187, -0.7027, -1.2576,  0.9417],
         [-0.2566, -0.4147, -0.9941,  1.6655],
         [-0.3034, -1.5051,  0.9642,  0.8444]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_K: 

```python
tensor([[[-0.9827, -1.0168,  1.0281,  0.9714],
         [ 1.6523, -1.0221, -0.1998, -0.4305],
         [ 1.0187, -0.7027, -1.2576,  0.9417],
         [-0.2566, -0.4147, -0.9941,  1.6655],
         [-0.3034, -1.5051,  0.9642,  0.8444]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[-0.9827, -1.0168,  1.0281,  0.9714],
         [ 1.6523, -1.0221, -0.1998, -0.4305],
         [ 1.0187, -0.7027, -1.2576,  0.9417],
         [-0.2566, -0.4147, -0.9941,  1.6655],
         [-0.3034, -1.5051,  0.9642,  0.8444]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 5, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 0.1383,  0.0825],
          [ 0.5772,  0.3264],
          [ 0.1638,  0.0268],
          [-0.1643, -0.1670],
          [ 0.3922,  0.2251]],

         [[ 0.6988, -0.3817],
          [-0.1517,  0.2279],
          [-0.1355, -0.2213],
          [ 0.1592, -0.5242],
          [ 0.6609, -0.3043]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 5, 2])
```


K: 

```python
tensor([[[[-0.0627, -1.0248],
          [-0.4900, -0.0534],
          [ 0.0319,  0.1609],
          [ 0.3518, -0.0886],
          [-0.2730, -1.0870]],

         [[-0.4571, -0.3625],
          [-0.4364,  0.4074],
          [-0.6390,  0.4378],
          [-0.5723,  0.1142],
          [-0.6723, -0.1968]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[-1.2054, -0.8279],
          [ 0.8143,  0.3732],
          [ 0.2203,  0.8104],
          [-0.6669,  0.4239],
          [-0.9051, -0.6896]],

         [[-0.1528, -0.6281],
          [ 0.4623,  1.0743],
          [ 1.2012,  1.3263],
          [ 1.0145,  0.5970],
          [ 0.0578, -0.1748]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 0.1383,  0.0825],
          [ 0.5772,  0.3264],
          [ 0.1638,  0.0268],
          [-0.1643, -0.1670],
          [ 0.3922,  0.2251]],

         [[ 0.6988, -0.3817],
          [-0.1517,  0.2279],
          [-0.1355, -0.2213],
          [ 0.1592, -0.5242],
          [ 0.6609, -0.3043]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 5, 2])
```


K: 

```python
tensor([[[[-0.0627, -1.0248],
          [-0.4900, -0.0534],
          [ 0.0319,  0.1609],
          [ 0.3518, -0.0886],
          [-0.2730, -1.0870]],

         [[-0.4571, -0.3625],
          [-0.4364,  0.4074],
          [-0.6390,  0.4378],
          [-0.5723,  0.1142],
          [-0.6723, -0.1968]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[-1.2054, -0.8279],
          [ 0.8143,  0.3732],
          [ 0.2203,  0.8104],
          [-0.6669,  0.4239],
          [-0.9051, -0.6896]],

         [[-0.1528, -0.6281],
          [ 0.4623,  1.0743],
          [ 1.2012,  1.3263],
          [ 1.0145,  0.5970],
          [ 0.0578, -0.1748]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[-0.0659, -0.0510,  0.0125,  0.0292, -0.0901],
          [-0.2622, -0.2123,  0.0502,  0.1232, -0.3624],
          [-0.0267, -0.0578,  0.0068,  0.0391, -0.0523],
          [ 0.1283,  0.0632, -0.0227, -0.0304,  0.1601],
          [-0.1805, -0.1444,  0.0345,  0.0835, -0.2488]],

         [[-0.1280, -0.3256, -0.4339, -0.3136, -0.2791],
          [-0.0094,  0.1125,  0.1391,  0.0798,  0.0404],
          [ 0.1005, -0.0220, -0.0073,  0.0369,  0.0952],
          [ 0.0829, -0.2001, -0.2342, -0.1068, -0.0027],
          [-0.1356, -0.2916, -0.3928, -0.2920, -0.2718]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[-6.5924e-02, -5.1039e-02,  1.2508e-02,  2.9245e-02, -1.0000e+09],
          [-2.6215e-01, -2.1232e-01,  5.0165e-02,  1.2316e-01, -1.0000e+09],
          [-2.6718e-02, -5.7775e-02,  6.7526e-03,  3.9079e-02, -1.0000e+09],
          [ 1.2830e-01,  6.3229e-02, -2.2706e-02, -3.0413e-02, -1.0000e+09],
          [-1.8054e-01, -1.4438e-01,  3.4464e-02,  8.3471e-02, -1.0000e+09]],

         [[-1.2803e-01, -3.2563e-01, -4.3394e-01, -3.1363e-01, -1.0000e+09],
          [-9.3984e-03,  1.1247e-01,  1.3910e-01,  7.9788e-02, -1.0000e+09],
          [ 1.0053e-01, -2.1964e-02, -7.3153e-03,  3.6941e-02, -1.0000e+09],
          [ 8.2927e-02, -2.0015e-01, -2.3422e-01, -1.0676e-01, -1.0000e+09],
          [-1.3560e-01, -2.9160e-01, -3.9281e-01, -2.9200e-01, -1.0000e+09]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[0.2383, 0.2419, 0.2577, 0.2621, 0.0000],
          [0.2046, 0.2150, 0.2796, 0.3008, 0.0000],
          [0.2456, 0.2381, 0.2540, 0.2623, 0.0000],
          [0.2740, 0.2567, 0.2356, 0.2338, 0.0000],
          [0.2184, 0.2264, 0.2708, 0.2844, 0.0000]],

         [[0.2952, 0.2423, 0.2174, 0.2452, 0.0000],
          [0.2282, 0.2577, 0.2647, 0.2494, 0.0000],
          [0.2688, 0.2378, 0.2413, 0.2522, 0.0000],
          [0.3022, 0.2277, 0.2201, 0.2500, 0.0000],
          [0.2870, 0.2456, 0.2219, 0.2455, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[-0.2083,  0.2130],
          [-0.2105,  0.2650],
          [-0.2212,  0.2025],
          [-0.2252,  0.1590],
          [-0.2089,  0.2437]],

         [[ 0.5767,  0.5096],
          [ 0.6553,  0.6335],
          [ 0.6145,  0.5572],
          [ 0.5771,  0.4960],
          [ 0.5853,  0.5244]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[0.2383, 0.2419, 0.2577, 0.2621, 0.0000],
          [0.2046, 0.2150, 0.2796, 0.3008, 0.0000],
          [0.2456, 0.2381, 0.2540, 0.2623, 0.0000],
          [0.2740, 0.2567, 0.2356, 0.2338, 0.0000],
          [0.2184, 0.2264, 0.2708, 0.2844, 0.0000]],

         [[0.2952, 0.2423, 0.2174, 0.2452, 0.0000],
          [0.2282, 0.2577, 0.2647, 0.2494, 0.0000],
          [0.2688, 0.2378, 0.2413, 0.2522, 0.0000],
          [0.3022, 0.2277, 0.2201, 0.2500, 0.0000],
          [0.2870, 0.2456, 0.2219, 0.2455, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 5, 5])
```


context: 

```python
tensor([[[[-0.2083,  0.2130],
          [-0.2105,  0.2650],
          [-0.2212,  0.2025],
          [-0.2252,  0.1590],
          [-0.2089,  0.2437]],

         [[ 0.5767,  0.5096],
          [ 0.6553,  0.6335],
          [ 0.6145,  0.5572],
          [ 0.5771,  0.4960],
          [ 0.5853,  0.5244]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[-0.2083,  0.2130,  0.5767,  0.5096],
         [-0.2105,  0.2650,  0.6553,  0.6335],
         [-0.2212,  0.2025,  0.6145,  0.5572],
         [-0.2252,  0.1590,  0.5771,  0.4960],
         [-0.2089,  0.2437,  0.5853,  0.5244]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[ 0.0016, -0.2176, -0.2011, -0.3089],
         [-0.0064, -0.2591, -0.2386, -0.3813],
         [-0.0017, -0.2432, -0.2200, -0.3266],
         [ 0.0017, -0.2278, -0.2035, -0.2847],
         [ 0.0013, -0.2155, -0.2038, -0.3246]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 5, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-0.9827, -1.0168,  1.0281,  0.9714],
         [ 1.6523, -1.0221, -0.1998, -0.4305],
         [ 1.0187, -0.7027, -1.2576,  0.9417],
         [-0.2566, -0.4147, -0.9941,  1.6655],
         [-0.3034, -1.5051,  0.9642,  0.8444]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 5, 4])
```


output + residual: 

```python
tensor([[[-0.9811, -1.2344,  0.8269,  0.6625],
         [ 1.6459, -1.2812, -0.4384, -0.8117],
         [ 1.0170, -0.9460, -1.4776,  0.6151],
         [-0.2550, -0.6426, -1.1976,  1.3808],
         [-0.3022, -1.7206,  0.7603,  0.5198]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-0.8576, -1.1292,  1.0816,  0.9052],
         [ 1.6692, -0.9474, -0.1940, -0.5278],
         [ 1.1671, -0.7187, -1.2294,  0.7810],
         [-0.0795, -0.4830, -1.0608,  1.6233],
         [-0.1201, -1.5827,  0.9754,  0.7274]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 5, 4])
```


## PoswiseFeedForwardNet


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


inputs: 

```python
tensor([[[-0.8576, -1.1292,  1.0816,  0.9052],
         [ 1.6692, -0.9474, -0.1940, -0.5278],
         [ 1.1671, -0.7187, -1.2294,  0.7810],
         [-0.0795, -0.4830, -1.0608,  1.6233],
         [-0.1201, -1.5827,  0.9754,  0.7274]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc操作的代码</div>


: 

```python
output = self.fc(inputs)
```


inputs: 

```python
tensor([[[-0.8576, -1.1292,  1.0816,  0.9052],
         [ 1.6692, -0.9474, -0.1940, -0.5278],
         [ 1.1671, -0.7187, -1.2294,  0.7810],
         [-0.0795, -0.4830, -1.0608,  1.6233],
         [-0.1201, -1.5827,  0.9754,  0.7274]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc原来是d_model->d_ff->d_model</div>


self.fc: 

```python
Sequential(
  (0): Linear(in_features=4, out_features=8, bias=False)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=4, bias=False)
)
```


output: 

```python
tensor([[[-0.1120,  0.0350, -0.1126,  0.2166],
         [-0.0139, -0.1885, -0.1416, -0.1473],
         [ 0.0225, -0.1145, -0.0744,  0.0749],
         [-0.0611, -0.0097,  0.0249,  0.3228],
         [-0.1548, -0.0443, -0.1098,  0.0987]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 5, 4])
```


## 前馈层后的层归一化和残差


<div style='color:#fe618e;font-weight:800;font-size:23px;'>FeedForward后的层归一化和残差</div>


: 

```python
ans = nn.LayerNorm(d_model).to(device)(output + residual)
```


residual: 

```python
tensor([[[-0.8576, -1.1292,  1.0816,  0.9052],
         [ 1.6692, -0.9474, -0.1940, -0.5278],
         [ 1.1671, -0.7187, -1.2294,  0.7810],
         [-0.0795, -0.4830, -1.0608,  1.6233],
         [-0.1201, -1.5827,  0.9754,  0.7274]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>残差和层归一化之后的结果</div>


ans: 

```python
tensor([[[-0.9379, -1.0576,  0.9243,  1.0712],
         [ 1.6693, -0.9511, -0.1998, -0.5184],
         [ 1.1381, -0.7606, -1.2024,  0.8249],
         [-0.1857, -0.4975, -0.9783,  1.6616],
         [-0.2185, -1.5470,  0.9021,  0.8633]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans.shape: 

```python
torch.Size([1, 5, 4])
```


# Encoder结束


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


enc_outputs: 

```python
tensor([[[-0.9379, -1.0576,  0.9243,  1.0712],
         [ 1.6693, -0.9511, -0.1998, -0.5184],
         [ 1.1381, -0.7606, -1.2024,  0.8249],
         [-0.1857, -0.4975, -0.9783,  1.6616],
         [-0.2185, -1.5470,  0.9021,  0.8633]]],
       grad_fn=<NativeLayerNormBackward0>)
```


enc_outputs.shape: 

```python
torch.Size([1, 5, 4])
```


enc_self_attns: 

```python
[tensor([[[[0.2159, 0.3080, 0.2848, 0.1913, 0.0000],
          [0.3200, 0.3028, 0.1877, 0.1895, 0.0000],
          [0.1952, 0.3286, 0.3052, 0.1710, 0.0000],
          [0.1246, 0.3895, 0.3780, 0.1079, 0.0000],
          [0.1639, 0.2591, 0.3549, 0.2221, 0.0000]],

         [[0.2828, 0.2029, 0.2158, 0.2985, 0.0000],
          [0.2710, 0.2264, 0.2253, 0.2773, 0.0000],
          [0.2328, 0.2529, 0.2801, 0.2342, 0.0000],
          [0.2634, 0.2040, 0.2506, 0.2819, 0.0000],
          [0.3212, 0.1520, 0.1668, 0.3600, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>), tensor([[[[0.2383, 0.2419, 0.2577, 0.2621, 0.0000],
          [0.2046, 0.2150, 0.2796, 0.3008, 0.0000],
          [0.2456, 0.2381, 0.2540, 0.2623, 0.0000],
          [0.2740, 0.2567, 0.2356, 0.2338, 0.0000],
          [0.2184, 0.2264, 0.2708, 0.2844, 0.0000]],

         [[0.2952, 0.2423, 0.2174, 0.2452, 0.0000],
          [0.2282, 0.2577, 0.2647, 0.2494, 0.0000],
          [0.2688, 0.2378, 0.2413, 0.2522, 0.0000],
          [0.3022, 0.2277, 0.2201, 0.2500, 0.0000],
          [0.2870, 0.2456, 0.2219, 0.2455, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)]
```


# 阶段二：decoder


<div style='color:#fe618e;font-weight:800;font-size:23px;'>decoder得到注意力操作</div>


: 

```python
dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(dec_inputs, enc_inputs, enc_outputs)
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


dec_inputs: 

```python
tensor([[4, 1, 2, 3, 6, 0]])
```


dec_inputs.shape: 

```python
torch.Size([1, 6])
```


enc_inputs: 

```python
tensor([[1, 2, 3, 4, 0]])
```


enc_inputs.shape: 

```python
torch.Size([1, 5])
```


enc_outputs: 

```python
tensor([[[-0.9379, -1.0576,  0.9243,  1.0712],
         [ 1.6693, -0.9511, -0.1998, -0.5184],
         [ 1.1381, -0.7606, -1.2024,  0.8249],
         [-0.1857, -0.4975, -0.9783,  1.6616],
         [-0.2185, -1.5470,  0.9021,  0.8633]]],
       grad_fn=<NativeLayerNormBackward0>)
```


enc_outputs.shape: 

```python
torch.Size([1, 5, 4])
```


# Decoder中


<div style='color:#3296ee;font-weight:800;font-size:23px;'>dec_inputs转换为词向量的结果</div>


: 

```python
dec_outputs = self.tgt_emb(dec_inputs)
```


dec_outputs: 

```python
tensor([[[-0.9147,  1.3995, -0.1676, -0.4466],
         [ 1.3005, -0.2332,  0.4454, -1.3284],
         [ 0.2364,  1.8461, -0.5960, -0.7287],
         [-0.4197,  0.0320, -0.0632, -0.5316],
         [-1.3878, -2.5452,  0.1798, -0.1912],
         [ 0.9457, -1.1349,  0.9356, -0.5307]]], grad_fn=<EmbeddingBackward0>)
```


dec_outputs.shape: 

```python
torch.Size([1, 6, 4])
```


## PositionalEncoding


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入加上位置编码的代码</div>


加上位置编码: 

```python
x = x + self.pe[:x.size(0), :]
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


x: 

```python
tensor([[[-0.9147,  1.3995, -0.1676, -0.4466]],

        [[ 1.3005, -0.2332,  0.4454, -1.3284]],

        [[ 0.2364,  1.8461, -0.5960, -0.7287]],

        [[-0.4197,  0.0320, -0.0632, -0.5316]],

        [[-1.3878, -2.5452,  0.1798, -0.1912]],

        [[ 0.9457, -1.1349,  0.9356, -0.5307]]], grad_fn=<TransposeBackward0>)
```


x.shape: 

```python
torch.Size([6, 1, 4])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>位置编码</div>


self.pe[:x.size(0), :]: 

```python
tensor([[[ 0.0000,  1.0000,  0.0000,  1.0000]],

        [[ 0.8415,  0.5403,  0.0100,  0.9999]],

        [[ 0.9093, -0.4161,  0.0200,  0.9998]],

        [[ 0.1411, -0.9900,  0.0300,  0.9996]],

        [[-0.7568, -0.6536,  0.0400,  0.9992]],

        [[-0.9589,  0.2837,  0.0500,  0.9988]]])
```


self.pe[:x.size(0), :].shape: 

```python
torch.Size([6, 1, 4])
```


self.pe.shape: 

```python
torch.Size([5000, 1, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


x: 

```python
tensor([[[-0.9147,  2.3995, -0.1676,  0.5534]],

        [[ 2.1420,  0.3071,  0.4554, -0.3284]],

        [[ 1.1457,  1.4299, -0.5760,  0.2711]],

        [[-0.2786, -0.9580, -0.0332,  0.4679]],

        [[-2.1446, -3.1989,  0.2198,  0.8080]],

        [[-0.0132, -0.8512,  0.9856,  0.4680]]], grad_fn=<AddBackward0>)
```


x.shape: 

```python
torch.Size([6, 1, 4])
```


## decoder的self_attn的pad_mask


## get_attn_pad_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq_q: 

```python
tensor([[4, 1, 2, 3, 6, 0]])
```


seq_q.shape: 

```python
torch.Size([1, 6])
```


seq_k: 

```python
tensor([[4, 1, 2, 3, 6, 0]])
```


seq_k.shape: 

```python
torch.Size([1, 6])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>获取对应的大小：len_q,len_k</div>


例如: 

```python
batch_size, len_q = seq_q.size()
```


batch_size: 

```python
1
```


len_q: 

```python
6
```


len_k: 

```python
6
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>操作pad_attn_mask矩阵：pad_attn_mask</div>


: 

```python
pad_attn_mask = seq_k.data.eq(0).unsqueeze(1) 
```


pad_attn_mask: 

```python
tensor([[[False, False, False, False, False,  True]]])
```


pad_attn_mask.shape: 

```python
torch.Size([1, 1, 6])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>扩展pad_attn_mask矩阵：pad_attn_mask.expand</div>


: 

```python
ans = pad_attn_mask.expand(batch_size, len_q, len_k)  
```


ans: 

```python
tensor([[[False, False, False, False, False,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True]]])
```


ans.shape: 

```python
torch.Size([1, 6, 6])
```


## get_attn_subsequence_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq: 

```python
tensor([[4, 1, 2, 3, 6, 0]])
```


seq.shape: 

```python
torch.Size([1, 6])
```


<div style='color:#19ce8b;font-weight:800;font-size:23px;'>求attn_shape</div>


: 

```python
attn_shape = [seq.size(0), seq.size(1), seq.size(1)]
```


attn_shape: 

```python
[1, 6, 6]
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>生成一个上三角矩阵</div>


: 

```python
subsequence_mask = np.triu(np.ones(attn_shape), k=1)
```


subsequence_mask: 

```python
[[[0. 1. 1. 1. 1. 1.]
  [0. 0. 1. 1. 1. 1.]
  [0. 0. 0. 1. 1. 1.]
  [0. 0. 0. 0. 1. 1.]
  [0. 0. 0. 0. 0. 1.]
  [0. 0. 0. 0. 0. 0.]]]
```


subsequence_mask.shape: 

```python
(1, 6, 6)
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>生成subsequence_mask</div>


: 

```python
subsequence_mask = torch.from_numpy(subsequence_mask).byte()
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


subsequence_mask: 

```python
tensor([[[0, 1, 1, 1, 1, 1],
         [0, 0, 1, 1, 1, 1],
         [0, 0, 0, 1, 1, 1],
         [0, 0, 0, 0, 1, 1],
         [0, 0, 0, 0, 0, 1],
         [0, 0, 0, 0, 0, 0]]], dtype=torch.uint8)
```


subsequence_mask.shape: 

```python
torch.Size([1, 6, 6])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>两个mask相加</div>


: 

```python
dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequence_mask),0).to(device)
```


dec_self_attn_pad_mask: 

```python
tensor([[[False, False, False, False, False,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True]]])
```


dec_self_attn_pad_mask.shape: 

```python
torch.Size([1, 6, 6])
```


dec_self_attn_subsequence_mask: 

```python
tensor([[[0, 1, 1, 1, 1, 1],
         [0, 0, 1, 1, 1, 1],
         [0, 0, 0, 1, 1, 1],
         [0, 0, 0, 0, 1, 1],
         [0, 0, 0, 0, 0, 1],
         [0, 0, 0, 0, 0, 0]]], dtype=torch.uint8)
```


dec_self_attn_subsequence_mask.shape: 

```python
torch.Size([1, 6, 6])
```


dec_self_attn_mask: 

```python
tensor([[[False,  True,  True,  True,  True,  True],
         [False, False,  True,  True,  True,  True],
         [False, False, False,  True,  True,  True],
         [False, False, False, False,  True,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True]]])
```


dec_self_attn_mask.shape: 

```python
torch.Size([1, 6, 6])
```


## 交互注意力层中的pad_mask


## get_attn_pad_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq_q: 

```python
tensor([[4, 1, 2, 3, 6, 0]])
```


seq_q.shape: 

```python
torch.Size([1, 6])
```


seq_k: 

```python
tensor([[4, 1, 2, 3, 6, 0]])
```


seq_k.shape: 

```python
torch.Size([1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>获取对应的大小：len_q,len_k</div>


例如: 

```python
batch_size, len_q = seq_q.size()
```


batch_size: 

```python
1
```


len_q: 

```python
6
```


len_k: 

```python
5
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>操作pad_attn_mask矩阵：pad_attn_mask</div>


: 

```python
pad_attn_mask = seq_k.data.eq(0).unsqueeze(1) 
```


pad_attn_mask: 

```python
tensor([[[False, False, False, False,  True]]])
```


pad_attn_mask.shape: 

```python
torch.Size([1, 1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>扩展pad_attn_mask矩阵：pad_attn_mask.expand</div>


: 

```python
ans = pad_attn_mask.expand(batch_size, len_q, len_k)  
```


ans: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


ans.shape: 

```python
torch.Size([1, 6, 5])
```


# DecoderLayer


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-1.0163,  2.6661, -0.1862,  0.6148],
         [ 2.3800,  0.3412,  0.5060, -0.3649],
         [ 1.2730,  1.5888, -0.6401,  0.3012],
         [-0.3096, -1.0645, -0.0369,  0.5199],
         [-2.3829, -3.5543,  0.2443,  0.8978],
         [-0.0146, -0.9458,  1.0951,  0.5200]]], grad_fn=<TransposeBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 6, 4])
```


input_K: 

```python
tensor([[[-1.0163,  2.6661, -0.1862,  0.6148],
         [ 2.3800,  0.3412,  0.5060, -0.3649],
         [ 1.2730,  1.5888, -0.6401,  0.3012],
         [-0.3096, -1.0645, -0.0369,  0.5199],
         [-2.3829, -3.5543,  0.2443,  0.8978],
         [-0.0146, -0.9458,  1.0951,  0.5200]]], grad_fn=<TransposeBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 6, 4])
```


input_V: 

```python
tensor([[[-1.0163,  2.6661, -0.1862,  0.6148],
         [ 2.3800,  0.3412,  0.5060, -0.3649],
         [ 1.2730,  1.5888, -0.6401,  0.3012],
         [-0.3096, -1.0645, -0.0369,  0.5199],
         [-2.3829, -3.5543,  0.2443,  0.8978],
         [-0.0146, -0.9458,  1.0951,  0.5200]]], grad_fn=<TransposeBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 6, 4])
```


attn_mask: 

```python
tensor([[[False,  True,  True,  True,  True,  True],
         [False, False,  True,  True,  True,  True],
         [False, False, False,  True,  True,  True],
         [False, False, False, False,  True,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 6, 6])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 1.0907,  0.1451],
          [ 0.0758, -0.2971],
          [ 0.4168,  0.2657],
          [-0.1144, -0.0583],
          [-0.6201, -0.2188],
          [ 0.2940, -0.6122]],

         [[-1.3085, -1.3487],
          [ 0.5620,  0.6993],
          [-0.2347,  0.3494],
          [ 0.0911,  0.4586],
          [ 0.2180,  0.4501],
          [ 0.0157,  0.0386]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 6, 2])
```


K: 

```python
tensor([[[[-0.7863, -0.8953],
          [ 0.6642, -0.1772],
          [ 0.3333, -0.3147],
          [ 0.1765,  0.5449],
          [-0.1070,  1.4186],
          [ 0.0276,  0.2847]],

         [[-1.5235, -0.4687],
          [ 0.1354, -0.3384],
          [-0.4066, -0.7798],
          [ 0.3699,  0.2035],
          [ 1.0605,  1.1383],
          [-0.0163,  0.4426]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 6, 2])
```


V: 

```python
tensor([[[[ 0.6773,  0.8641],
          [ 0.6819, -1.1339],
          [ 0.5646, -0.2493],
          [-0.5885, -0.0681],
          [-1.8649,  0.4203],
          [-0.2335, -0.4282]],

         [[-0.8849,  0.8656],
          [-1.1621, -0.7270],
          [-1.4104,  0.4044],
          [ 0.6006,  0.1954],
          [ 2.7146,  0.2963],
          [ 0.5031, -0.3047]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 6, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False,  True,  True,  True,  True,  True],
          [False, False,  True,  True,  True,  True],
          [False, False, False,  True,  True,  True],
          [False, False, False, False,  True,  True],
          [False, False, False, False, False,  True],
          [False, False, False, False, False,  True]],

         [[False,  True,  True,  True,  True,  True],
          [False, False,  True,  True,  True,  True],
          [False, False, False,  True,  True,  True],
          [False, False, False, False,  True,  True],
          [False, False, False, False, False,  True],
          [False, False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 6, 6])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 1.0907,  0.1451],
          [ 0.0758, -0.2971],
          [ 0.4168,  0.2657],
          [-0.1144, -0.0583],
          [-0.6201, -0.2188],
          [ 0.2940, -0.6122]],

         [[-1.3085, -1.3487],
          [ 0.5620,  0.6993],
          [-0.2347,  0.3494],
          [ 0.0911,  0.4586],
          [ 0.2180,  0.4501],
          [ 0.0157,  0.0386]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 6, 2])
```


K: 

```python
tensor([[[[-0.7863, -0.8953],
          [ 0.6642, -0.1772],
          [ 0.3333, -0.3147],
          [ 0.1765,  0.5449],
          [-0.1070,  1.4186],
          [ 0.0276,  0.2847]],

         [[-1.5235, -0.4687],
          [ 0.1354, -0.3384],
          [-0.4066, -0.7798],
          [ 0.3699,  0.2035],
          [ 1.0605,  1.1383],
          [-0.0163,  0.4426]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 6, 2])
```


V: 

```python
tensor([[[[ 0.6773,  0.8641],
          [ 0.6819, -1.1339],
          [ 0.5646, -0.2493],
          [-0.5885, -0.0681],
          [-1.8649,  0.4203],
          [-0.2335, -0.4282]],

         [[-0.8849,  0.8656],
          [-1.1621, -0.7270],
          [-1.4104,  0.4044],
          [ 0.6006,  0.1954],
          [ 2.7146,  0.2963],
          [ 0.5031, -0.3047]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 6, 2])
```


attn_mask: 

```python
tensor([[[[False,  True,  True,  True,  True,  True],
          [False, False,  True,  True,  True,  True],
          [False, False, False,  True,  True,  True],
          [False, False, False, False,  True,  True],
          [False, False, False, False, False,  True],
          [False, False, False, False, False,  True]],

         [[False,  True,  True,  True,  True,  True],
          [False, False,  True,  True,  True,  True],
          [False, False, False,  True,  True,  True],
          [False, False, False, False,  True,  True],
          [False, False, False, False, False,  True],
          [False, False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 6, 6])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[-0.6983,  0.4940,  0.2247,  0.1920,  0.0630,  0.0505],
          [ 0.1459,  0.0728,  0.0840, -0.1050, -0.3037, -0.0583],
          [-0.3999,  0.1624,  0.0391,  0.1544,  0.2350,  0.0616],
          [ 0.1006, -0.0464, -0.0140, -0.0368, -0.0499, -0.0140],
          [ 0.4833, -0.2638, -0.0974, -0.1617, -0.1725, -0.0561],
          [ 0.2241,  0.2148,  0.2055, -0.1992, -0.6363, -0.1175]],

         [[ 1.8566,  0.1974,  1.1199, -0.5363, -2.0667, -0.4070],
          [-0.8372, -0.1135, -0.5472,  0.2476,  0.9844,  0.2124],
          [ 0.1371, -0.1061, -0.1252, -0.0111,  0.1052,  0.1121],
          [-0.2501, -0.1010, -0.2791,  0.0898,  0.4374,  0.1425],
          [-0.3840, -0.0868, -0.3109,  0.1218,  0.5257,  0.1384],
          [-0.0297, -0.0077, -0.0258,  0.0097,  0.0428,  0.0119]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 6, 6])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[-6.9827e-01, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [ 1.4589e-01,  7.2848e-02, -1.0000e+09, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [-3.9992e-01,  1.6245e-01,  3.9098e-02, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [ 1.0056e-01, -4.6439e-02, -1.3990e-02, -3.6755e-02, -1.0000e+09,
           -1.0000e+09],
          [ 4.8326e-01, -2.6381e-01, -9.7448e-02, -1.6166e-01, -1.7251e-01,
           -1.0000e+09],
          [ 2.2405e-01,  2.1480e-01,  2.0552e-01, -1.9918e-01, -6.3630e-01,
           -1.0000e+09]],

         [[ 1.8566e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [-8.3724e-01, -1.1351e-01, -1.0000e+09, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [ 1.3708e-01, -1.0608e-01, -1.2519e-01, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [-2.5010e-01, -1.0101e-01, -2.7907e-01,  8.9815e-02, -1.0000e+09,
           -1.0000e+09],
          [-3.8401e-01, -8.6823e-02, -3.1087e-01,  1.2179e-01,  5.2575e-01,
           -1.0000e+09],
          [-2.9702e-02, -7.7368e-03, -2.5805e-02,  9.6609e-03,  4.2847e-02,
           -1.0000e+09]]]], grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 6, 6])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5183, 0.4817, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.2322, 0.4075, 0.3602, 0.0000, 0.0000, 0.0000],
          [0.2757, 0.2380, 0.2459, 0.2404, 0.0000, 0.0000],
          [0.3250, 0.1540, 0.1818, 0.1705, 0.1687, 0.0000],
          [0.2469, 0.2446, 0.2424, 0.1617, 0.1044, 0.0000]],

         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3266, 0.6734, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3916, 0.3071, 0.3013, 0.0000, 0.0000, 0.0000],
          [0.2204, 0.2558, 0.2141, 0.3096, 0.0000, 0.0000],
          [0.1322, 0.1780, 0.1422, 0.2192, 0.3284, 0.0000],
          [0.1945, 0.1988, 0.1953, 0.2023, 0.2091, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 6, 6])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.6773,  0.8641],
          [ 0.6795, -0.0984],
          [ 0.6385, -0.3512],
          [ 0.3464, -0.1093],
          [ 0.0128,  0.1202],
          [ 0.1809, -0.0916]],

         [[-0.8849,  0.8656],
          [-1.0715, -0.2069],
          [-1.1283,  0.2376],
          [-0.6084,  0.1519],
          [ 0.4986,  0.1827],
          [ 0.0107,  0.2043]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 6, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5183, 0.4817, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.2322, 0.4075, 0.3602, 0.0000, 0.0000, 0.0000],
          [0.2757, 0.2380, 0.2459, 0.2404, 0.0000, 0.0000],
          [0.3250, 0.1540, 0.1818, 0.1705, 0.1687, 0.0000],
          [0.2469, 0.2446, 0.2424, 0.1617, 0.1044, 0.0000]],

         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3266, 0.6734, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3916, 0.3071, 0.3013, 0.0000, 0.0000, 0.0000],
          [0.2204, 0.2558, 0.2141, 0.3096, 0.0000, 0.0000],
          [0.1322, 0.1780, 0.1422, 0.2192, 0.3284, 0.0000],
          [0.1945, 0.1988, 0.1953, 0.2023, 0.2091, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 6, 6])
```


context: 

```python
tensor([[[[ 0.6773,  0.8641],
          [ 0.6795, -0.0984],
          [ 0.6385, -0.3512],
          [ 0.3464, -0.1093],
          [ 0.0128,  0.1202],
          [ 0.1809, -0.0916]],

         [[-0.8849,  0.8656],
          [-1.0715, -0.2069],
          [-1.1283,  0.2376],
          [-0.6084,  0.1519],
          [ 0.4986,  0.1827],
          [ 0.0107,  0.2043]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 6, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.6773,  0.8641, -0.8849,  0.8656],
         [ 0.6795, -0.0984, -1.0715, -0.2069],
         [ 0.6385, -0.3512, -1.1283,  0.2376],
         [ 0.3464, -0.1093, -0.6084,  0.1519],
         [ 0.0128,  0.1202,  0.4986,  0.1827],
         [ 0.1809, -0.0916,  0.0107,  0.2043]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[ 0.2590,  0.6448,  0.0348,  0.6386],
         [ 0.0989,  0.1353,  0.5615,  0.6193],
         [-0.0511,  0.2576,  0.4973,  0.9165],
         [-0.0066,  0.1602,  0.2504,  0.4749],
         [ 0.0662,  0.0193, -0.3083, -0.1733],
         [ 0.0037,  0.0792, -0.0579,  0.1760]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 6, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-1.0163,  2.6661, -0.1862,  0.6148],
         [ 2.3800,  0.3412,  0.5060, -0.3649],
         [ 1.2730,  1.5888, -0.6401,  0.3012],
         [-0.3096, -1.0645, -0.0369,  0.5199],
         [-2.3829, -3.5543,  0.2443,  0.8978],
         [-0.0146, -0.9458,  1.0951,  0.5200]]], grad_fn=<TransposeBackward0>)
```


residual.shape: 

```python
torch.Size([1, 6, 4])
```


output + residual: 

```python
tensor([[[-0.7573,  3.3110, -0.1514,  1.2535],
         [ 2.4788,  0.4766,  1.0674,  0.2543],
         [ 1.2218,  1.8464, -0.1428,  1.2177],
         [-0.3162, -0.9043,  0.2135,  0.9948],
         [-2.3167, -3.5351, -0.0641,  0.7245],
         [-0.0109, -0.8666,  1.0371,  0.6960]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-1.0683,  1.5323, -0.6810,  0.2170],
         [ 1.6270, -0.6842, -0.0022, -0.9407],
         [ 0.2560,  1.1151, -1.6212,  0.2502],
         [-0.4481, -1.2898,  0.3099,  1.4281],
         [-0.5969, -1.3106,  0.7228,  1.1847],
         [-0.3082, -1.4813,  1.1286,  0.6609]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 6, 4])
```


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-1.0683,  1.5323, -0.6810,  0.2170],
         [ 1.6270, -0.6842, -0.0022, -0.9407],
         [ 0.2560,  1.1151, -1.6212,  0.2502],
         [-0.4481, -1.2898,  0.3099,  1.4281],
         [-0.5969, -1.3106,  0.7228,  1.1847],
         [-0.3082, -1.4813,  1.1286,  0.6609]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 6, 4])
```


input_K: 

```python
tensor([[[-0.9379, -1.0576,  0.9243,  1.0712],
         [ 1.6693, -0.9511, -0.1998, -0.5184],
         [ 1.1381, -0.7606, -1.2024,  0.8249],
         [-0.1857, -0.4975, -0.9783,  1.6616],
         [-0.2185, -1.5470,  0.9021,  0.8633]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[-0.9379, -1.0576,  0.9243,  1.0712],
         [ 1.6693, -0.9511, -0.1998, -0.5184],
         [ 1.1381, -0.7606, -1.2024,  0.8249],
         [-0.1857, -0.4975, -0.9783,  1.6616],
         [-0.2185, -1.5470,  0.9021,  0.8633]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 6, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 1.0731,  0.2057],
          [-1.0929,  0.7958],
          [ 0.5833,  0.8739],
          [ 0.0748, -1.2671],
          [-0.0025, -1.3647],
          [-0.3688, -1.2242]],

         [[-0.6924,  0.2378],
          [ 0.3028,  0.0463],
          [-0.6542,  0.1526],
          [ 0.4845, -0.4940],
          [ 0.5560, -0.4522],
          [ 0.6960, -0.3867]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 6, 2])
```


K: 

```python
tensor([[[[-0.1604,  0.6820],
          [ 0.5074,  0.1739],
          [ 0.5207,  0.3972],
          [ 0.1841,  0.5367],
          [ 0.0610,  0.7912]],

         [[ 1.3372,  0.9378],
          [-0.7306, -0.1483],
          [-0.3631, -0.0779],
          [ 0.5137,  0.2973],
          [ 1.0671,  0.9172]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[-0.0030,  0.6411],
          [ 1.1275, -0.2796],
          [ 0.0127, -0.3533],
          [-0.8188, -0.0146],
          [ 0.5310,  0.5489]],

         [[-0.1578,  0.0251],
          [ 0.4820,  0.5487],
          [-0.0486,  0.6151],
          [-0.4594,  0.3187],
          [ 0.0636,  0.2736]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 6, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 1.0731,  0.2057],
          [-1.0929,  0.7958],
          [ 0.5833,  0.8739],
          [ 0.0748, -1.2671],
          [-0.0025, -1.3647],
          [-0.3688, -1.2242]],

         [[-0.6924,  0.2378],
          [ 0.3028,  0.0463],
          [-0.6542,  0.1526],
          [ 0.4845, -0.4940],
          [ 0.5560, -0.4522],
          [ 0.6960, -0.3867]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 6, 2])
```


K: 

```python
tensor([[[[-0.1604,  0.6820],
          [ 0.5074,  0.1739],
          [ 0.5207,  0.3972],
          [ 0.1841,  0.5367],
          [ 0.0610,  0.7912]],

         [[ 1.3372,  0.9378],
          [-0.7306, -0.1483],
          [-0.3631, -0.0779],
          [ 0.5137,  0.2973],
          [ 1.0671,  0.9172]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[-0.0030,  0.6411],
          [ 1.1275, -0.2796],
          [ 0.0127, -0.3533],
          [-0.8188, -0.0146],
          [ 0.5310,  0.5489]],

         [[-0.1578,  0.0251],
          [ 0.4820,  0.5487],
          [-0.0486,  0.6151],
          [-0.4594,  0.3187],
          [ 0.0636,  0.2736]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 6, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[-0.0225,  0.4103,  0.4529,  0.2177,  0.1614],
          [ 0.5078, -0.2943, -0.1789,  0.1598,  0.3981],
          [ 0.3553,  0.3168,  0.4602,  0.4076,  0.5141],
          [-0.6196, -0.1290, -0.3284, -0.4711, -0.7057],
          [-0.6579, -0.1687, -0.3843, -0.5182, -0.7636],
          [-0.5486, -0.2829, -0.4797, -0.5126, -0.7009]],

         [[-0.4970,  0.3328,  0.1647, -0.2015, -0.3682],
          [ 0.3170, -0.1613, -0.0803,  0.1197,  0.2585],
          [-0.5173,  0.3220,  0.1596, -0.2055, -0.3946],
          [ 0.1305, -0.1985, -0.0972,  0.0721,  0.0452],
          [ 0.2259, -0.2398, -0.1179,  0.1069,  0.1262],
          [ 0.4016, -0.3190, -0.1574,  0.1715,  0.2743]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 6, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[-2.2519e-02,  4.1034e-01,  4.5290e-01,  2.1774e-01, -1.0000e+09],
          [ 5.0778e-01, -2.9429e-01, -1.7888e-01,  1.5977e-01, -1.0000e+09],
          [ 3.5526e-01,  3.1677e-01,  4.6025e-01,  4.0756e-01, -1.0000e+09],
          [-6.1955e-01, -1.2896e-01, -3.2835e-01, -4.7112e-01, -1.0000e+09],
          [-6.5787e-01, -1.6872e-01, -3.8426e-01, -5.1825e-01, -1.0000e+09],
          [-5.4857e-01, -2.8287e-01, -4.7966e-01, -5.1260e-01, -1.0000e+09]],

         [[-4.9699e-01,  3.3277e-01,  1.6469e-01, -2.0150e-01, -1.0000e+09],
          [ 3.1703e-01, -1.6131e-01, -8.0306e-02,  1.1972e-01, -1.0000e+09],
          [-5.1733e-01,  3.2196e-01,  1.5957e-01, -2.0552e-01, -1.0000e+09],
          [ 1.3051e-01, -1.9849e-01, -9.7201e-02,  7.2122e-02, -1.0000e+09],
          [ 2.2586e-01, -2.3982e-01, -1.1787e-01,  1.0689e-01, -1.0000e+09],
          [ 4.0164e-01, -3.1902e-01, -1.5742e-01,  1.7150e-01, -1.0000e+09]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 6, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[0.1844, 0.2843, 0.2967, 0.2345, 0.0000],
          [0.3763, 0.1687, 0.1894, 0.2657, 0.0000],
          [0.2423, 0.2332, 0.2692, 0.2553, 0.0000],
          [0.1949, 0.3183, 0.2608, 0.2261, 0.0000],
          [0.1963, 0.3201, 0.2580, 0.2257, 0.0000],
          [0.2266, 0.2956, 0.2428, 0.2349, 0.0000]],

         [[0.1521, 0.3487, 0.2948, 0.2044, 0.0000],
          [0.3212, 0.1991, 0.2159, 0.2637, 0.0000],
          [0.1504, 0.3482, 0.2960, 0.2054, 0.0000],
          [0.2891, 0.2080, 0.2302, 0.2727, 0.0000],
          [0.3101, 0.1947, 0.2199, 0.2753, 0.0000],
          [0.3506, 0.1705, 0.2004, 0.2785, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 6, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.1318, -0.0695],
          [-0.0260,  0.1233],
          [ 0.0565, -0.0086],
          [ 0.1765, -0.0595],
          [ 0.1788, -0.0581],
          [ 0.1433, -0.0266]],

         [[ 0.0359,  0.4416],
          [-0.0864,  0.3342],
          [ 0.0353,  0.4423],
          [-0.0818,  0.3499],
          [-0.0923,  0.3376],
          [-0.1108,  0.3144]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 6, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[0.1844, 0.2843, 0.2967, 0.2345, 0.0000],
          [0.3763, 0.1687, 0.1894, 0.2657, 0.0000],
          [0.2423, 0.2332, 0.2692, 0.2553, 0.0000],
          [0.1949, 0.3183, 0.2608, 0.2261, 0.0000],
          [0.1963, 0.3201, 0.2580, 0.2257, 0.0000],
          [0.2266, 0.2956, 0.2428, 0.2349, 0.0000]],

         [[0.1521, 0.3487, 0.2948, 0.2044, 0.0000],
          [0.3212, 0.1991, 0.2159, 0.2637, 0.0000],
          [0.1504, 0.3482, 0.2960, 0.2054, 0.0000],
          [0.2891, 0.2080, 0.2302, 0.2727, 0.0000],
          [0.3101, 0.1947, 0.2199, 0.2753, 0.0000],
          [0.3506, 0.1705, 0.2004, 0.2785, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 6, 5])
```


context: 

```python
tensor([[[[ 0.1318, -0.0695],
          [-0.0260,  0.1233],
          [ 0.0565, -0.0086],
          [ 0.1765, -0.0595],
          [ 0.1788, -0.0581],
          [ 0.1433, -0.0266]],

         [[ 0.0359,  0.4416],
          [-0.0864,  0.3342],
          [ 0.0353,  0.4423],
          [-0.0818,  0.3499],
          [-0.0923,  0.3376],
          [-0.1108,  0.3144]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 6, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.1318, -0.0695,  0.0359,  0.4416],
         [-0.0260,  0.1233, -0.0864,  0.3342],
         [ 0.0565, -0.0086,  0.0353,  0.4423],
         [ 0.1765, -0.0595, -0.0818,  0.3499],
         [ 0.1788, -0.0581, -0.0923,  0.3376],
         [ 0.1433, -0.0266, -0.1108,  0.3144]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[-0.1922, -0.0859,  0.1656, -0.1253],
         [-0.1317, -0.0087,  0.1759, -0.1330],
         [-0.1876, -0.0833,  0.1801, -0.1213],
         [-0.1582, -0.0207,  0.1492, -0.1437],
         [-0.1535, -0.0142,  0.1463, -0.1439],
         [-0.1428, -0.0015,  0.1485, -0.1411]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 6, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-1.0683,  1.5323, -0.6810,  0.2170],
         [ 1.6270, -0.6842, -0.0022, -0.9407],
         [ 0.2560,  1.1151, -1.6212,  0.2502],
         [-0.4481, -1.2898,  0.3099,  1.4281],
         [-0.5969, -1.3106,  0.7228,  1.1847],
         [-0.3082, -1.4813,  1.1286,  0.6609]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 6, 4])
```


output + residual: 

```python
tensor([[[-1.2605,  1.4464, -0.5154,  0.0918],
         [ 1.4953, -0.6929,  0.1737, -1.0737],
         [ 0.0684,  1.0318, -1.4412,  0.1289],
         [-0.6063, -1.3105,  0.4591,  1.2844],
         [-0.7504, -1.3249,  0.8691,  1.0409],
         [-0.4510, -1.4828,  1.2771,  0.5198]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-1.2101,  1.5171, -0.4594,  0.1523],
         [ 1.5397, -0.6773,  0.2007, -1.0631],
         [ 0.1368,  1.2221, -1.5639,  0.2050],
         [-0.5674, -1.2771,  0.5064,  1.3381],
         [-0.6961, -1.2601,  0.8938,  1.0624],
         [-0.4020, -1.3974,  1.2649,  0.5345]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 6, 4])
```


## PoswiseFeedForwardNet


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


inputs: 

```python
tensor([[[-1.2101,  1.5171, -0.4594,  0.1523],
         [ 1.5397, -0.6773,  0.2007, -1.0631],
         [ 0.1368,  1.2221, -1.5639,  0.2050],
         [-0.5674, -1.2771,  0.5064,  1.3381],
         [-0.6961, -1.2601,  0.8938,  1.0624],
         [-0.4020, -1.3974,  1.2649,  0.5345]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc操作的代码</div>


: 

```python
output = self.fc(inputs)
```


inputs: 

```python
tensor([[[-1.2101,  1.5171, -0.4594,  0.1523],
         [ 1.5397, -0.6773,  0.2007, -1.0631],
         [ 0.1368,  1.2221, -1.5639,  0.2050],
         [-0.5674, -1.2771,  0.5064,  1.3381],
         [-0.6961, -1.2601,  0.8938,  1.0624],
         [-0.4020, -1.3974,  1.2649,  0.5345]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc原来是d_model->d_ff->d_model</div>


self.fc: 

```python
Sequential(
  (0): Linear(in_features=4, out_features=8, bias=False)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=4, bias=False)
)
```


output: 

```python
tensor([[[ 0.1295, -0.1181, -0.2377,  0.0250],
         [ 0.0197, -0.0523, -0.1317,  0.1850],
         [ 0.1261, -0.3584, -0.3122,  0.1977],
         [ 0.0425, -0.1607,  0.0833,  0.1634],
         [-0.0380,  0.0254,  0.0785,  0.0655],
         [-0.1565,  0.1338,  0.0449,  0.0446]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 6, 4])
```


## 前馈层后的层归一化和残差


<div style='color:#fe618e;font-weight:800;font-size:23px;'>FeedForward后的层归一化和残差</div>


: 

```python
ans = nn.LayerNorm(d_model).to(device)(output + residual)
```


residual: 

```python
tensor([[[-1.2101,  1.5171, -0.4594,  0.1523],
         [ 1.5397, -0.6773,  0.2007, -1.0631],
         [ 0.1368,  1.2221, -1.5639,  0.2050],
         [-0.5674, -1.2771,  0.5064,  1.3381],
         [-0.6961, -1.2601,  0.8938,  1.0624],
         [-0.4020, -1.3974,  1.2649,  0.5345]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>残差和层归一化之后的结果</div>


ans: 

```python
tensor([[[-1.0812,  1.5209, -0.6787,  0.2390],
         [ 1.6074, -0.7600,  0.0660, -0.9134],
         [ 0.3308,  0.8994, -1.6933,  0.4630],
         [-0.5012, -1.3226,  0.5017,  1.3221],
         [-0.7417, -1.2259,  0.9085,  1.0591],
         [-0.5782, -1.2870,  1.2999,  0.5653]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans.shape: 

```python
torch.Size([1, 6, 4])
```


# DecoderLayer


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-1.0812,  1.5209, -0.6787,  0.2390],
         [ 1.6074, -0.7600,  0.0660, -0.9134],
         [ 0.3308,  0.8994, -1.6933,  0.4630],
         [-0.5012, -1.3226,  0.5017,  1.3221],
         [-0.7417, -1.2259,  0.9085,  1.0591],
         [-0.5782, -1.2870,  1.2999,  0.5653]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 6, 4])
```


input_K: 

```python
tensor([[[-1.0812,  1.5209, -0.6787,  0.2390],
         [ 1.6074, -0.7600,  0.0660, -0.9134],
         [ 0.3308,  0.8994, -1.6933,  0.4630],
         [-0.5012, -1.3226,  0.5017,  1.3221],
         [-0.7417, -1.2259,  0.9085,  1.0591],
         [-0.5782, -1.2870,  1.2999,  0.5653]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 6, 4])
```


input_V: 

```python
tensor([[[-1.0812,  1.5209, -0.6787,  0.2390],
         [ 1.6074, -0.7600,  0.0660, -0.9134],
         [ 0.3308,  0.8994, -1.6933,  0.4630],
         [-0.5012, -1.3226,  0.5017,  1.3221],
         [-0.7417, -1.2259,  0.9085,  1.0591],
         [-0.5782, -1.2870,  1.2999,  0.5653]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 6, 4])
```


attn_mask: 

```python
tensor([[[False,  True,  True,  True,  True,  True],
         [False, False,  True,  True,  True,  True],
         [False, False, False,  True,  True,  True],
         [False, False, False, False,  True,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 6, 6])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 0.0589,  1.1356],
          [-0.3805, -0.8583],
          [-0.5083,  0.7650],
          [ 0.3249, -0.4377],
          [ 0.4723, -0.4579],
          [ 0.5151, -0.6717]],

         [[ 0.5013,  0.0138],
          [ 0.2039,  0.0022],
          [ 0.5347, -0.5066],
          [-1.1262, -0.2536],
          [-1.0995, -0.0506],
          [-1.0024,  0.1477]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 6, 2])
```


K: 

```python
tensor([[[[ 0.4400, -0.0557],
          [ 0.2184,  0.2923],
          [ 1.0246,  0.8203],
          [-0.8141, -0.0401],
          [-0.9990, -0.3246],
          [-1.1059, -0.5245]],

         [[ 0.0541, -0.6348],
          [-0.1992,  0.0586],
          [ 0.1793, -1.3433],
          [ 0.3188,  0.5800],
          [ 0.2317,  0.8664],
          [ 0.0952,  1.1401]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 6, 2])
```


V: 

```python
tensor([[[[ 0.4011, -0.1666],
          [-0.2655, -0.5350],
          [-0.0734, -0.6932],
          [-0.3712,  0.9654],
          [-0.2374,  1.0671],
          [-0.1657,  1.0166]],

         [[ 0.5198, -0.6115],
          [-0.5194,  0.3893],
          [ 0.4819, -0.3065],
          [ 0.0786,  0.4095],
          [-0.0063,  0.3653],
          [-0.2117,  0.4072]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 6, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False,  True,  True,  True,  True,  True],
          [False, False,  True,  True,  True,  True],
          [False, False, False,  True,  True,  True],
          [False, False, False, False,  True,  True],
          [False, False, False, False, False,  True],
          [False, False, False, False, False,  True]],

         [[False,  True,  True,  True,  True,  True],
          [False, False,  True,  True,  True,  True],
          [False, False, False,  True,  True,  True],
          [False, False, False, False,  True,  True],
          [False, False, False, False, False,  True],
          [False, False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 6, 6])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 0.0589,  1.1356],
          [-0.3805, -0.8583],
          [-0.5083,  0.7650],
          [ 0.3249, -0.4377],
          [ 0.4723, -0.4579],
          [ 0.5151, -0.6717]],

         [[ 0.5013,  0.0138],
          [ 0.2039,  0.0022],
          [ 0.5347, -0.5066],
          [-1.1262, -0.2536],
          [-1.0995, -0.0506],
          [-1.0024,  0.1477]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 6, 2])
```


K: 

```python
tensor([[[[ 0.4400, -0.0557],
          [ 0.2184,  0.2923],
          [ 1.0246,  0.8203],
          [-0.8141, -0.0401],
          [-0.9990, -0.3246],
          [-1.1059, -0.5245]],

         [[ 0.0541, -0.6348],
          [-0.1992,  0.0586],
          [ 0.1793, -1.3433],
          [ 0.3188,  0.5800],
          [ 0.2317,  0.8664],
          [ 0.0952,  1.1401]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 6, 2])
```


V: 

```python
tensor([[[[ 0.4011, -0.1666],
          [-0.2655, -0.5350],
          [-0.0734, -0.6932],
          [-0.3712,  0.9654],
          [-0.2374,  1.0671],
          [-0.1657,  1.0166]],

         [[ 0.5198, -0.6115],
          [-0.5194,  0.3893],
          [ 0.4819, -0.3065],
          [ 0.0786,  0.4095],
          [-0.0063,  0.3653],
          [-0.2117,  0.4072]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 6, 2])
```


attn_mask: 

```python
tensor([[[[False,  True,  True,  True,  True,  True],
          [False, False,  True,  True,  True,  True],
          [False, False, False,  True,  True,  True],
          [False, False, False, False,  True,  True],
          [False, False, False, False, False,  True],
          [False, False, False, False, False,  True]],

         [[False,  True,  True,  True,  True,  True],
          [False, False,  True,  True,  True,  True],
          [False, False, False,  True,  True,  True],
          [False, False, False, False,  True,  True],
          [False, False, False, False, False,  True],
          [False, False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 6, 6])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[-0.0264,  0.2438,  0.7013, -0.0661, -0.3022, -0.4672],
          [-0.0846, -0.2361, -0.7735,  0.2434,  0.4658,  0.6159],
          [-0.1883,  0.0796,  0.0754,  0.2709,  0.1835,  0.1138],
          [ 0.1183, -0.0403, -0.0185, -0.1746, -0.1290, -0.0917],
          [ 0.1650, -0.0217,  0.0766, -0.2589, -0.2285, -0.1995],
          [ 0.1867, -0.0593, -0.0164, -0.2775, -0.2097, -0.1537]],

         [[ 0.0130, -0.0701,  0.0504,  0.1187,  0.0906,  0.0449],
          [ 0.0068, -0.0286,  0.0237,  0.0469,  0.0348,  0.0155],
          [ 0.2478, -0.0963,  0.5490, -0.0872, -0.2227, -0.3724],
          [ 0.0708,  0.1482,  0.0981, -0.3579, -0.3399, -0.2802],
          [-0.0193,  0.1528, -0.0913, -0.2686, -0.2112, -0.1149],
          [-0.1046,  0.1473, -0.2674, -0.1654, -0.0738,  0.0516]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 6, 6])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[-2.6416e-02, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [-8.4581e-02, -2.3613e-01, -1.0000e+09, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [-1.8829e-01,  7.9592e-02,  7.5446e-02, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [ 1.1832e-01, -4.0279e-02, -1.8495e-02, -1.7462e-01, -1.0000e+09,
           -1.0000e+09],
          [ 1.6497e-01, -2.1701e-02,  7.6554e-02, -2.5888e-01, -2.2852e-01,
           -1.0000e+09],
          [ 1.8673e-01, -5.9259e-02, -1.6394e-02, -2.7750e-01, -2.0973e-01,
           -1.0000e+09]],

         [[ 1.2971e-02, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [ 6.8027e-03, -2.8633e-02, -1.0000e+09, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [ 2.4784e-01, -9.6334e-02,  5.4899e-01, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [ 7.0756e-02,  1.4815e-01,  9.8060e-02, -3.5787e-01, -1.0000e+09,
           -1.0000e+09],
          [-1.9300e-02,  1.5280e-01, -9.1282e-02, -2.6862e-01, -2.1118e-01,
           -1.0000e+09],
          [-1.0462e-01,  1.4734e-01, -2.6737e-01, -1.6538e-01, -7.3760e-02,
           -1.0000e+09]]]], grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 6, 6])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5378, 0.4622, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.2771, 0.3622, 0.3607, 0.0000, 0.0000, 0.0000],
          [0.2881, 0.2458, 0.2512, 0.2149, 0.0000, 0.0000],
          [0.2454, 0.2036, 0.2247, 0.1606, 0.1656, 0.0000],
          [0.2564, 0.2005, 0.2093, 0.1612, 0.1725, 0.0000]],

         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5089, 0.4911, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3268, 0.2316, 0.4416, 0.0000, 0.0000, 0.0000],
          [0.2660, 0.2874, 0.2734, 0.1733, 0.0000, 0.0000],
          [0.2117, 0.2515, 0.1970, 0.1650, 0.1748, 0.0000],
          [0.1957, 0.2518, 0.1663, 0.1842, 0.2019, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 6, 6])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.4011, -0.1666],
          [ 0.0930, -0.3368],
          [-0.0115, -0.4900],
          [-0.0479, -0.1462],
          [-0.0710,  0.0262],
          [-0.0665,  0.0446]],

         [[ 0.5198, -0.6115],
          [ 0.0094, -0.1200],
          [ 0.2624, -0.2450],
          [ 0.1343, -0.0636],
          [ 0.0862,  0.0395],
          [ 0.0643,  0.0765]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 6, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5378, 0.4622, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.2771, 0.3622, 0.3607, 0.0000, 0.0000, 0.0000],
          [0.2881, 0.2458, 0.2512, 0.2149, 0.0000, 0.0000],
          [0.2454, 0.2036, 0.2247, 0.1606, 0.1656, 0.0000],
          [0.2564, 0.2005, 0.2093, 0.1612, 0.1725, 0.0000]],

         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5089, 0.4911, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3268, 0.2316, 0.4416, 0.0000, 0.0000, 0.0000],
          [0.2660, 0.2874, 0.2734, 0.1733, 0.0000, 0.0000],
          [0.2117, 0.2515, 0.1970, 0.1650, 0.1748, 0.0000],
          [0.1957, 0.2518, 0.1663, 0.1842, 0.2019, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 6, 6])
```


context: 

```python
tensor([[[[ 0.4011, -0.1666],
          [ 0.0930, -0.3368],
          [-0.0115, -0.4900],
          [-0.0479, -0.1462],
          [-0.0710,  0.0262],
          [-0.0665,  0.0446]],

         [[ 0.5198, -0.6115],
          [ 0.0094, -0.1200],
          [ 0.2624, -0.2450],
          [ 0.1343, -0.0636],
          [ 0.0862,  0.0395],
          [ 0.0643,  0.0765]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 6, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.4011, -0.1666,  0.5198, -0.6115],
         [ 0.0930, -0.3368,  0.0094, -0.1200],
         [-0.0115, -0.4900,  0.2624, -0.2450],
         [-0.0479, -0.1462,  0.1343, -0.0636],
         [-0.0710,  0.0262,  0.0862,  0.0395],
         [-0.0665,  0.0446,  0.0643,  0.0765]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[-0.0252,  0.2717, -0.0596,  0.2155],
         [ 0.1586, -0.0138, -0.0718, -0.1282],
         [ 0.2228,  0.0003, -0.1591, -0.0357],
         [ 0.0629, -0.0011, -0.0552,  0.0168],
         [-0.0218, -0.0007,  0.0005,  0.0451],
         [-0.0333, -0.0049,  0.0163,  0.0305]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 6, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-1.0812,  1.5209, -0.6787,  0.2390],
         [ 1.6074, -0.7600,  0.0660, -0.9134],
         [ 0.3308,  0.8994, -1.6933,  0.4630],
         [-0.5012, -1.3226,  0.5017,  1.3221],
         [-0.7417, -1.2259,  0.9085,  1.0591],
         [-0.5782, -1.2870,  1.2999,  0.5653]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 6, 4])
```


output + residual: 

```python
tensor([[[-1.1063,  1.7926, -0.7384,  0.4544],
         [ 1.7660, -0.7738, -0.0058, -1.0416],
         [ 0.5536,  0.8997, -1.8524,  0.4273],
         [-0.4383, -1.3237,  0.4465,  1.3389],
         [-0.7635, -1.2266,  0.9090,  1.1041],
         [-0.6116, -1.2919,  1.3162,  0.5958]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-1.0638,  1.4914, -0.7395,  0.3119],
         [ 1.6244, -0.6936,  0.0073, -0.9381],
         [ 0.5026,  0.8209, -1.7100,  0.3865],
         [-0.4477, -1.3403,  0.4442,  1.3438],
         [-0.7568, -1.2124,  0.8886,  1.0806],
         [-0.6039, -1.2734,  1.2931,  0.5842]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 6, 4])
```


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-1.0638,  1.4914, -0.7395,  0.3119],
         [ 1.6244, -0.6936,  0.0073, -0.9381],
         [ 0.5026,  0.8209, -1.7100,  0.3865],
         [-0.4477, -1.3403,  0.4442,  1.3438],
         [-0.7568, -1.2124,  0.8886,  1.0806],
         [-0.6039, -1.2734,  1.2931,  0.5842]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 6, 4])
```


input_K: 

```python
tensor([[[-0.9379, -1.0576,  0.9243,  1.0712],
         [ 1.6693, -0.9511, -0.1998, -0.5184],
         [ 1.1381, -0.7606, -1.2024,  0.8249],
         [-0.1857, -0.4975, -0.9783,  1.6616],
         [-0.2185, -1.5470,  0.9021,  0.8633]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[-0.9379, -1.0576,  0.9243,  1.0712],
         [ 1.6693, -0.9511, -0.1998, -0.5184],
         [ 1.1381, -0.7606, -1.2024,  0.8249],
         [-0.1857, -0.4975, -0.9783,  1.6616],
         [-0.2185, -1.5470,  0.9021,  0.8633]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 6, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 0.1355,  0.3142],
          [ 0.1935, -0.7251],
          [-0.2359, -0.6365],
          [-0.8044,  0.2728],
          [-0.5899,  0.5253],
          [-0.3388,  0.5611]],

         [[ 0.0071,  0.1762],
          [-0.1536, -0.4865],
          [-0.3530, -0.9123],
          [ 0.0420, -0.0599],
          [ 0.1675,  0.3136],
          [ 0.2409,  0.5248]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 6, 2])
```


K: 

```python
tensor([[[[-0.2900,  0.0676],
          [ 0.3265, -0.0128],
          [-0.2579,  0.3678],
          [-0.6276,  0.4579],
          [-0.1448,  0.0573]],

         [[-0.1496,  0.3475],
          [ 1.0561, -0.4988],
          [ 0.5246,  0.0619],
          [-0.2133,  0.5436],
          [ 0.3324,  0.1276]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.1722, -0.0310],
          [ 1.1388, -0.3230],
          [-0.0734, -0.1163],
          [-0.8754,  0.0939],
          [ 0.7224, -0.1832]],

         [[ 0.5400, -0.0304],
          [-0.4842, -0.3807],
          [-0.5721, -0.7408],
          [-0.1484, -0.5906],
          [ 0.3501, -0.1970]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 6, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 0.1355,  0.3142],
          [ 0.1935, -0.7251],
          [-0.2359, -0.6365],
          [-0.8044,  0.2728],
          [-0.5899,  0.5253],
          [-0.3388,  0.5611]],

         [[ 0.0071,  0.1762],
          [-0.1536, -0.4865],
          [-0.3530, -0.9123],
          [ 0.0420, -0.0599],
          [ 0.1675,  0.3136],
          [ 0.2409,  0.5248]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 6, 2])
```


K: 

```python
tensor([[[[-0.2900,  0.0676],
          [ 0.3265, -0.0128],
          [-0.2579,  0.3678],
          [-0.6276,  0.4579],
          [-0.1448,  0.0573]],

         [[-0.1496,  0.3475],
          [ 1.0561, -0.4988],
          [ 0.5246,  0.0619],
          [-0.2133,  0.5436],
          [ 0.3324,  0.1276]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.1722, -0.0310],
          [ 1.1388, -0.3230],
          [-0.0734, -0.1163],
          [-0.8754,  0.0939],
          [ 0.7224, -0.1832]],

         [[ 0.5400, -0.0304],
          [-0.4842, -0.3807],
          [-0.5721, -0.7408],
          [-0.1484, -0.5906],
          [ 0.3501, -0.1970]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 6, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[-0.0128,  0.0284,  0.0570,  0.0416, -0.0011],
          [-0.0743,  0.0512, -0.2239, -0.3207, -0.0492],
          [ 0.0180, -0.0487, -0.1225, -0.1014, -0.0016],
          [ 0.1780, -0.1881,  0.2177,  0.4453,  0.0934],
          [ 0.1461, -0.1409,  0.2442,  0.4319,  0.0817],
          [ 0.0963, -0.0833,  0.2077,  0.3320,  0.0574]],

         [[ 0.0425, -0.0569,  0.0103,  0.0667,  0.0176],
          [-0.1033,  0.0569, -0.0783, -0.1639, -0.0800],
          [-0.1868,  0.0581, -0.1709, -0.2974, -0.1653],
          [-0.0191,  0.0524,  0.0129, -0.0293,  0.0045],
          [ 0.0593,  0.0145,  0.0759,  0.0953,  0.0677],
          [ 0.1035, -0.0052,  0.1123,  0.1654,  0.1040]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 6, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[-1.2773e-02,  2.8440e-02,  5.7014e-02,  4.1606e-02, -1.0000e+09],
          [-7.4325e-02,  5.1218e-02, -2.2390e-01, -3.2065e-01, -1.0000e+09],
          [ 1.7963e-02, -4.8705e-02, -1.2254e-01, -1.0141e-01, -1.0000e+09],
          [ 1.7798e-01, -1.8814e-01,  2.1766e-01,  4.4527e-01, -1.0000e+09],
          [ 1.4606e-01, -1.4091e-01,  2.4423e-01,  4.3187e-01, -1.0000e+09],
          [ 9.6291e-02, -8.3285e-02,  2.0774e-01,  3.3204e-01, -1.0000e+09]],

         [[ 4.2545e-02, -5.6857e-02,  1.0340e-02,  6.6662e-02, -1.0000e+09],
          [-1.0330e-01,  5.6913e-02, -7.8271e-02, -1.6386e-01, -1.0000e+09],
          [-1.8682e-01,  5.8143e-02, -1.7089e-01, -2.9743e-01, -1.0000e+09],
          [-1.9149e-02,  5.2444e-02,  1.2941e-02, -2.9343e-02, -1.0000e+09],
          [ 5.9345e-02,  1.4497e-02,  7.5887e-02,  9.5295e-02, -1.0000e+09],
          [ 1.0347e-01, -5.2017e-03,  1.1234e-01,  1.6539e-01, -1.0000e+09]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 6, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[0.2398, 0.2499, 0.2571, 0.2532, 0.0000],
          [0.2648, 0.3002, 0.2280, 0.2070, 0.0000],
          [0.2709, 0.2534, 0.2354, 0.2404, 0.0000],
          [0.2475, 0.1716, 0.2575, 0.3233, 0.0000],
          [0.2390, 0.1794, 0.2636, 0.3180, 0.0000],
          [0.2370, 0.1980, 0.2649, 0.3000, 0.0000]],

         [[0.2565, 0.2323, 0.2484, 0.2628, 0.0000],
          [0.2415, 0.2835, 0.2476, 0.2273, 0.0000],
          [0.2387, 0.3050, 0.2426, 0.2137, 0.0000],
          [0.2441, 0.2622, 0.2521, 0.2416, 0.0000],
          [0.2494, 0.2385, 0.2536, 0.2585, 0.0000],
          [0.2519, 0.2260, 0.2541, 0.2680, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 6, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.0853, -0.0943],
          [ 0.1895, -0.1123],
          [ 0.1075, -0.0950],
          [-0.0639, -0.0627],
          [-0.0524, -0.0661],
          [-0.0157, -0.0740]],

         [[-0.1551, -0.4355],
          [-0.1823, -0.4330],
          [-0.1893, -0.4293],
          [-0.1752, -0.4367],
          [-0.1642, -0.4389],
          [-0.1586, -0.4402]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 6, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[0.2398, 0.2499, 0.2571, 0.2532, 0.0000],
          [0.2648, 0.3002, 0.2280, 0.2070, 0.0000],
          [0.2709, 0.2534, 0.2354, 0.2404, 0.0000],
          [0.2475, 0.1716, 0.2575, 0.3233, 0.0000],
          [0.2390, 0.1794, 0.2636, 0.3180, 0.0000],
          [0.2370, 0.1980, 0.2649, 0.3000, 0.0000]],

         [[0.2565, 0.2323, 0.2484, 0.2628, 0.0000],
          [0.2415, 0.2835, 0.2476, 0.2273, 0.0000],
          [0.2387, 0.3050, 0.2426, 0.2137, 0.0000],
          [0.2441, 0.2622, 0.2521, 0.2416, 0.0000],
          [0.2494, 0.2385, 0.2536, 0.2585, 0.0000],
          [0.2519, 0.2260, 0.2541, 0.2680, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 6, 5])
```


context: 

```python
tensor([[[[ 0.0853, -0.0943],
          [ 0.1895, -0.1123],
          [ 0.1075, -0.0950],
          [-0.0639, -0.0627],
          [-0.0524, -0.0661],
          [-0.0157, -0.0740]],

         [[-0.1551, -0.4355],
          [-0.1823, -0.4330],
          [-0.1893, -0.4293],
          [-0.1752, -0.4367],
          [-0.1642, -0.4389],
          [-0.1586, -0.4402]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 6, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.0853, -0.0943, -0.1551, -0.4355],
         [ 0.1895, -0.1123, -0.1823, -0.4330],
         [ 0.1075, -0.0950, -0.1893, -0.4293],
         [-0.0639, -0.0627, -0.1752, -0.4367],
         [-0.0524, -0.0661, -0.1642, -0.4389],
         [-0.0157, -0.0740, -0.1586, -0.4402]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[ 0.0924,  0.1458, -0.0776, -0.0936],
         [ 0.0707,  0.1642, -0.0527, -0.0716],
         [ 0.0995,  0.1547, -0.0800, -0.0893],
         [ 0.1488,  0.1324, -0.1308, -0.1280],
         [ 0.1405,  0.1319, -0.1242, -0.1254],
         [ 0.1265,  0.1355, -0.1112, -0.1172]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 6, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-1.0638,  1.4914, -0.7395,  0.3119],
         [ 1.6244, -0.6936,  0.0073, -0.9381],
         [ 0.5026,  0.8209, -1.7100,  0.3865],
         [-0.4477, -1.3403,  0.4442,  1.3438],
         [-0.7568, -1.2124,  0.8886,  1.0806],
         [-0.6039, -1.2734,  1.2931,  0.5842]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 6, 4])
```


output + residual: 

```python
tensor([[[-0.9714,  1.6372, -0.8171,  0.2182],
         [ 1.6951, -0.5294, -0.0454, -1.0096],
         [ 0.6021,  0.9756, -1.7900,  0.2972],
         [-0.2990, -1.2079,  0.3134,  1.2158],
         [-0.6163, -1.0805,  0.7644,  0.9552],
         [-0.4774, -1.1380,  1.1819,  0.4670]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-0.9489,  1.5560, -0.8007,  0.1935],
         [ 1.6327, -0.5455, -0.0715, -1.0157],
         [ 0.5414,  0.8894, -1.6881,  0.2572],
         [-0.3446, -1.3730,  0.3482,  1.3693],
         [-0.7130, -1.2451,  0.8697,  1.0885],
         [-0.5485, -1.2943,  1.3250,  0.5178]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 6, 4])
```


## PoswiseFeedForwardNet


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


inputs: 

```python
tensor([[[-0.9489,  1.5560, -0.8007,  0.1935],
         [ 1.6327, -0.5455, -0.0715, -1.0157],
         [ 0.5414,  0.8894, -1.6881,  0.2572],
         [-0.3446, -1.3730,  0.3482,  1.3693],
         [-0.7130, -1.2451,  0.8697,  1.0885],
         [-0.5485, -1.2943,  1.3250,  0.5178]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc操作的代码</div>


: 

```python
output = self.fc(inputs)
```


inputs: 

```python
tensor([[[-0.9489,  1.5560, -0.8007,  0.1935],
         [ 1.6327, -0.5455, -0.0715, -1.0157],
         [ 0.5414,  0.8894, -1.6881,  0.2572],
         [-0.3446, -1.3730,  0.3482,  1.3693],
         [-0.7130, -1.2451,  0.8697,  1.0885],
         [-0.5485, -1.2943,  1.3250,  0.5178]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc原来是d_model->d_ff->d_model</div>


self.fc: 

```python
Sequential(
  (0): Linear(in_features=4, out_features=8, bias=False)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=4, bias=False)
)
```


output: 

```python
tensor([[[-0.0769,  0.1542,  0.0305, -0.0489],
         [-0.2902, -0.0021, -0.4609,  0.0092],
         [-0.0260,  0.0397, -0.1936, -0.1861],
         [-0.1942,  0.1225, -0.1841,  0.0274],
         [-0.1836,  0.1535, -0.0957,  0.0754],
         [-0.1860,  0.2555, -0.0938,  0.0191]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 6, 4])
```


## 前馈层后的层归一化和残差


<div style='color:#fe618e;font-weight:800;font-size:23px;'>FeedForward后的层归一化和残差</div>


: 

```python
ans = nn.LayerNorm(d_model).to(device)(output + residual)
```


residual: 

```python
tensor([[[-0.9489,  1.5560, -0.8007,  0.1935],
         [ 1.6327, -0.5455, -0.0715, -1.0157],
         [ 0.5414,  0.8894, -1.6881,  0.2572],
         [-0.3446, -1.3730,  0.3482,  1.3693],
         [-0.7130, -1.2451,  0.8697,  1.0885],
         [-0.5485, -1.2943,  1.3250,  0.5178]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>残差和层归一化之后的结果</div>


ans: 

```python
tensor([[[-0.9713,  1.5827, -0.7327,  0.1213],
         [ 1.6930, -0.4005, -0.3837, -0.9088],
         [ 0.5634,  0.9475, -1.6619,  0.1510],
         [-0.4929, -1.2214,  0.2264,  1.4879],
         [-0.8898, -1.0860,  0.7917,  1.1841],
         [-0.7926, -1.1216,  1.3324,  0.5819]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans.shape: 

```python
torch.Size([1, 6, 4])
```


# Decoder结束


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


dec_outputs: 

```python
tensor([[[-0.9713,  1.5827, -0.7327,  0.1213],
         [ 1.6930, -0.4005, -0.3837, -0.9088],
         [ 0.5634,  0.9475, -1.6619,  0.1510],
         [-0.4929, -1.2214,  0.2264,  1.4879],
         [-0.8898, -1.0860,  0.7917,  1.1841],
         [-0.7926, -1.1216,  1.3324,  0.5819]]],
       grad_fn=<NativeLayerNormBackward0>)
```


dec_outputs.shape: 

```python
torch.Size([1, 6, 4])
```


dec_self_attns: 

```python
[tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5183, 0.4817, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.2322, 0.4075, 0.3602, 0.0000, 0.0000, 0.0000],
          [0.2757, 0.2380, 0.2459, 0.2404, 0.0000, 0.0000],
          [0.3250, 0.1540, 0.1818, 0.1705, 0.1687, 0.0000],
          [0.2469, 0.2446, 0.2424, 0.1617, 0.1044, 0.0000]],

         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3266, 0.6734, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3916, 0.3071, 0.3013, 0.0000, 0.0000, 0.0000],
          [0.2204, 0.2558, 0.2141, 0.3096, 0.0000, 0.0000],
          [0.1322, 0.1780, 0.1422, 0.2192, 0.3284, 0.0000],
          [0.1945, 0.1988, 0.1953, 0.2023, 0.2091, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>), tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5378, 0.4622, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.2771, 0.3622, 0.3607, 0.0000, 0.0000, 0.0000],
          [0.2881, 0.2458, 0.2512, 0.2149, 0.0000, 0.0000],
          [0.2454, 0.2036, 0.2247, 0.1606, 0.1656, 0.0000],
          [0.2564, 0.2005, 0.2093, 0.1612, 0.1725, 0.0000]],

         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5089, 0.4911, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3268, 0.2316, 0.4416, 0.0000, 0.0000, 0.0000],
          [0.2660, 0.2874, 0.2734, 0.1733, 0.0000, 0.0000],
          [0.2117, 0.2515, 0.1970, 0.1650, 0.1748, 0.0000],
          [0.1957, 0.2518, 0.1663, 0.1842, 0.2019, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)]
```


dec_enc_attns: 

```python
[tensor([[[[0.1844, 0.2843, 0.2967, 0.2345, 0.0000],
          [0.3763, 0.1687, 0.1894, 0.2657, 0.0000],
          [0.2423, 0.2332, 0.2692, 0.2553, 0.0000],
          [0.1949, 0.3183, 0.2608, 0.2261, 0.0000],
          [0.1963, 0.3201, 0.2580, 0.2257, 0.0000],
          [0.2266, 0.2956, 0.2428, 0.2349, 0.0000]],

         [[0.1521, 0.3487, 0.2948, 0.2044, 0.0000],
          [0.3212, 0.1991, 0.2159, 0.2637, 0.0000],
          [0.1504, 0.3482, 0.2960, 0.2054, 0.0000],
          [0.2891, 0.2080, 0.2302, 0.2727, 0.0000],
          [0.3101, 0.1947, 0.2199, 0.2753, 0.0000],
          [0.3506, 0.1705, 0.2004, 0.2785, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>), tensor([[[[0.2398, 0.2499, 0.2571, 0.2532, 0.0000],
          [0.2648, 0.3002, 0.2280, 0.2070, 0.0000],
          [0.2709, 0.2534, 0.2354, 0.2404, 0.0000],
          [0.2475, 0.1716, 0.2575, 0.3233, 0.0000],
          [0.2390, 0.1794, 0.2636, 0.3180, 0.0000],
          [0.2370, 0.1980, 0.2649, 0.3000, 0.0000]],

         [[0.2565, 0.2323, 0.2484, 0.2628, 0.0000],
          [0.2415, 0.2835, 0.2476, 0.2273, 0.0000],
          [0.2387, 0.3050, 0.2426, 0.2137, 0.0000],
          [0.2441, 0.2622, 0.2521, 0.2416, 0.0000],
          [0.2494, 0.2385, 0.2536, 0.2585, 0.0000],
          [0.2519, 0.2260, 0.2541, 0.2680, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)]
```


# 阶段三：projection


<div style='color:#fe618e;font-weight:800;font-size:23px;'>projection操作代码</div>


: 

```python
dec_logits = self.projection(dec_outputs)
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


dec_outputs: 

```python
tensor([[[-0.9713,  1.5827, -0.7327,  0.1213],
         [ 1.6930, -0.4005, -0.3837, -0.9088],
         [ 0.5634,  0.9475, -1.6619,  0.1510],
         [-0.4929, -1.2214,  0.2264,  1.4879],
         [-0.8898, -1.0860,  0.7917,  1.1841],
         [-0.7926, -1.1216,  1.3324,  0.5819]]],
       grad_fn=<NativeLayerNormBackward0>)
```


dec_outputs.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


dec_logits: 

```python
tensor([[[-0.4638,  1.3585, -0.2884,  0.0428, -0.0247, -1.5156, -0.7101],
         [ 0.2904, -0.6716,  0.5848, -0.4651,  0.1458,  1.0834,  0.3051],
         [ 0.2469,  1.0834,  0.2417, -0.5803,  0.0038, -1.0583, -0.0596],
         [ 0.6245, -0.2001, -0.2069,  0.0931, -0.1990, -0.1855,  0.7255],
         [ 0.2942, -0.3584, -0.3486,  0.3561, -0.1715, -0.0070,  0.4638],
         [ 0.0359, -0.7853, -0.3222,  0.5081, -0.0979,  0.5682,  0.2954]]],
       grad_fn=<UnsafeViewBackward0>)
```


dec_logits.shape: 

```python
torch.Size([1, 6, 7])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>dec_logits的view操作</div>


: 

```python
ans = dec_logits.view(-1, dec_logits.size(-1)), enc_self_attns, dec_self_attns, dec_enc_attns
```


ans: 

```python
(tensor([[-0.4638,  1.3585, -0.2884,  0.0428, -0.0247, -1.5156, -0.7101],
        [ 0.2904, -0.6716,  0.5848, -0.4651,  0.1458,  1.0834,  0.3051],
        [ 0.2469,  1.0834,  0.2417, -0.5803,  0.0038, -1.0583, -0.0596],
        [ 0.6245, -0.2001, -0.2069,  0.0931, -0.1990, -0.1855,  0.7255],
        [ 0.2942, -0.3584, -0.3486,  0.3561, -0.1715, -0.0070,  0.4638],
        [ 0.0359, -0.7853, -0.3222,  0.5081, -0.0979,  0.5682,  0.2954]],
       grad_fn=<ViewBackward0>), [tensor([[[[0.2159, 0.3080, 0.2848, 0.1913, 0.0000],
          [0.3200, 0.3028, 0.1877, 0.1895, 0.0000],
          [0.1952, 0.3286, 0.3052, 0.1710, 0.0000],
          [0.1246, 0.3895, 0.3780, 0.1079, 0.0000],
          [0.1639, 0.2591, 0.3549, 0.2221, 0.0000]],

         [[0.2828, 0.2029, 0.2158, 0.2985, 0.0000],
          [0.2710, 0.2264, 0.2253, 0.2773, 0.0000],
          [0.2328, 0.2529, 0.2801, 0.2342, 0.0000],
          [0.2634, 0.2040, 0.2506, 0.2819, 0.0000],
          [0.3212, 0.1520, 0.1668, 0.3600, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>), tensor([[[[0.2383, 0.2419, 0.2577, 0.2621, 0.0000],
          [0.2046, 0.2150, 0.2796, 0.3008, 0.0000],
          [0.2456, 0.2381, 0.2540, 0.2623, 0.0000],
          [0.2740, 0.2567, 0.2356, 0.2338, 0.0000],
          [0.2184, 0.2264, 0.2708, 0.2844, 0.0000]],

         [[0.2952, 0.2423, 0.2174, 0.2452, 0.0000],
          [0.2282, 0.2577, 0.2647, 0.2494, 0.0000],
          [0.2688, 0.2378, 0.2413, 0.2522, 0.0000],
          [0.3022, 0.2277, 0.2201, 0.2500, 0.0000],
          [0.2870, 0.2456, 0.2219, 0.2455, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)], [tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5183, 0.4817, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.2322, 0.4075, 0.3602, 0.0000, 0.0000, 0.0000],
          [0.2757, 0.2380, 0.2459, 0.2404, 0.0000, 0.0000],
          [0.3250, 0.1540, 0.1818, 0.1705, 0.1687, 0.0000],
          [0.2469, 0.2446, 0.2424, 0.1617, 0.1044, 0.0000]],

         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3266, 0.6734, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3916, 0.3071, 0.3013, 0.0000, 0.0000, 0.0000],
          [0.2204, 0.2558, 0.2141, 0.3096, 0.0000, 0.0000],
          [0.1322, 0.1780, 0.1422, 0.2192, 0.3284, 0.0000],
          [0.1945, 0.1988, 0.1953, 0.2023, 0.2091, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>), tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5378, 0.4622, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.2771, 0.3622, 0.3607, 0.0000, 0.0000, 0.0000],
          [0.2881, 0.2458, 0.2512, 0.2149, 0.0000, 0.0000],
          [0.2454, 0.2036, 0.2247, 0.1606, 0.1656, 0.0000],
          [0.2564, 0.2005, 0.2093, 0.1612, 0.1725, 0.0000]],

         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5089, 0.4911, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3268, 0.2316, 0.4416, 0.0000, 0.0000, 0.0000],
          [0.2660, 0.2874, 0.2734, 0.1733, 0.0000, 0.0000],
          [0.2117, 0.2515, 0.1970, 0.1650, 0.1748, 0.0000],
          [0.1957, 0.2518, 0.1663, 0.1842, 0.2019, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)], [tensor([[[[0.1844, 0.2843, 0.2967, 0.2345, 0.0000],
          [0.3763, 0.1687, 0.1894, 0.2657, 0.0000],
          [0.2423, 0.2332, 0.2692, 0.2553, 0.0000],
          [0.1949, 0.3183, 0.2608, 0.2261, 0.0000],
          [0.1963, 0.3201, 0.2580, 0.2257, 0.0000],
          [0.2266, 0.2956, 0.2428, 0.2349, 0.0000]],

         [[0.1521, 0.3487, 0.2948, 0.2044, 0.0000],
          [0.3212, 0.1991, 0.2159, 0.2637, 0.0000],
          [0.1504, 0.3482, 0.2960, 0.2054, 0.0000],
          [0.2891, 0.2080, 0.2302, 0.2727, 0.0000],
          [0.3101, 0.1947, 0.2199, 0.2753, 0.0000],
          [0.3506, 0.1705, 0.2004, 0.2785, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>), tensor([[[[0.2398, 0.2499, 0.2571, 0.2532, 0.0000],
          [0.2648, 0.3002, 0.2280, 0.2070, 0.0000],
          [0.2709, 0.2534, 0.2354, 0.2404, 0.0000],
          [0.2475, 0.1716, 0.2575, 0.3233, 0.0000],
          [0.2390, 0.1794, 0.2636, 0.3180, 0.0000],
          [0.2370, 0.1980, 0.2649, 0.3000, 0.0000]],

         [[0.2565, 0.2323, 0.2484, 0.2628, 0.0000],
          [0.2415, 0.2835, 0.2476, 0.2273, 0.0000],
          [0.2387, 0.3050, 0.2426, 0.2137, 0.0000],
          [0.2441, 0.2622, 0.2521, 0.2416, 0.0000],
          [0.2494, 0.2385, 0.2536, 0.2585, 0.0000],
          [0.2519, 0.2260, 0.2541, 0.2680, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)])
```


# 计算损失


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>预测值</div>


outputs: 

```python
tensor([[-0.4638,  1.3585, -0.2884,  0.0428, -0.0247, -1.5156, -0.7101],
        [ 0.2904, -0.6716,  0.5848, -0.4651,  0.1458,  1.0834,  0.3051],
        [ 0.2469,  1.0834,  0.2417, -0.5803,  0.0038, -1.0583, -0.0596],
        [ 0.6245, -0.2001, -0.2069,  0.0931, -0.1990, -0.1855,  0.7255],
        [ 0.2942, -0.3584, -0.3486,  0.3561, -0.1715, -0.0070,  0.4638],
        [ 0.0359, -0.7853, -0.3222,  0.5081, -0.0979,  0.5682,  0.2954]],
       grad_fn=<ViewBackward0>)
```


outputs.shape: 

```python
torch.Size([6, 7])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>真实值</div>


dec_outputs: 

```python
tensor([[1, 2, 3, 6, 5, 0]])
```


dec_outputs.shape: 

```python
torch.Size([1, 6])
```


dec_outputs.view(-1): 

```python
tensor([1, 2, 3, 6, 5, 0])
```


dec_outputs.view(-1).shape: 

```python
torch.Size([6])
```


<div style='color:#19ce8b;font-weight:800;font-size:23px;'>损失</div>


loss: 

```python
tensor(1.7087, grad_fn=<NllLossBackward0>)
```

Epoch: 0001 loss = 1.708675
Epoch: 0002 loss = 1.655830
Epoch: 0003 loss = 1.706199
Epoch: 0004 loss = 1.913226
Epoch: 0005 loss = 1.713156
Epoch: 0006 loss = 1.706922
Epoch: 0007 loss = 1.649527
Epoch: 0008 loss = 1.619642
Epoch: 0009 loss = 1.689334
Epoch: 0010 loss = 1.681051
Epoch: 0011 loss = 1.687449
Epoch: 0012 loss = 1.591328
Epoch: 0013 loss = 1.817263
Epoch: 0014 loss = 1.648421
Epoch: 0015 loss = 1.811880
Epoch: 0016 loss = 1.538745
Epoch: 0017 loss = 1.625313
Epoch: 0018 loss = 1.484280
Epoch: 0019 loss = 1.487645
Epoch: 0020 loss = 1.707490
Epoch: 0021 loss = 1.533877
Epoch: 0022 loss = 1.600633
Epoch: 0023 loss = 1.533605
Epoch: 0024 loss = 1.590580
Epoch: 0025 loss = 1.533324
Epoch: 0026 loss = 1.488305
Epoch: 0027 loss = 1.466543
Epoch: 0028 loss = 1.468655
Epoch: 0029 loss = 1.520055
Epoch: 0030 loss = 1.429921
Epoch: 0031 loss = 1.514200
Epoch: 0032 loss = 1.501956
Epoch: 0033 loss = 1.383000
Epoch: 0034 loss = 1.301067
Epoch: 0035 loss = 1.375256
Epoch: 0036 loss = 1.606236
Epoch: 0037 loss = 1.321108
Epoch: 0038 loss = 1.238932
Epoch: 0039 loss = 1.454670
Epoch: 0040 loss = 1.225789
Epoch: 0041 loss = 1.261798
Epoch: 0042 loss = 1.235908
Epoch: 0043 loss = 1.510940
Epoch: 0044 loss = 1.302819
Epoch: 0045 loss = 1.174150
Epoch: 0046 loss = 1.146936
Epoch: 0047 loss = 1.361544
Epoch: 0048 loss = 1.434202
Epoch: 0049 loss = 1.235973
Epoch: 0050 loss = 1.207506
Epoch: 0051 loss = 1.176084
Epoch: 0052 loss = 1.287042
Epoch: 0053 loss = 1.046428
Epoch: 0054 loss = 1.113267
Epoch: 0055 loss = 1.026969
Epoch: 0056 loss = 1.342315
Epoch: 0057 loss = 1.024236
Epoch: 0058 loss = 0.996546
Epoch: 0059 loss = 1.023512
Epoch: 0060 loss = 1.236366
Epoch: 0061 loss = 1.056293
Epoch: 0062 loss = 1.237459
Epoch: 0063 loss = 0.907287
Epoch: 0064 loss = 0.960385
Epoch: 0065 loss = 1.001500
Epoch: 0066 loss = 0.891473
Epoch: 0067 loss = 1.000785
Epoch: 0068 loss = 0.875094
Epoch: 0069 loss = 0.833904
Epoch: 0070 loss = 0.897655
Epoch: 0071 loss = 1.307880
Epoch: 0072 loss = 1.070475
Epoch: 0073 loss = 0.806412
Epoch: 0074 loss = 0.839027
Epoch: 0075 loss = 0.899120
Epoch: 0076 loss = 0.797728
Epoch: 0077 loss = 0.748954
Epoch: 0078 loss = 1.025165
Epoch: 0079 loss = 0.843472
Epoch: 0080 loss = 0.938302
Epoch: 0081 loss = 1.038429
Epoch: 0082 loss = 1.023836
Epoch: 0083 loss = 0.843053
Epoch: 0084 loss = 0.848602
Epoch: 0085 loss = 0.692885
Epoch: 0086 loss = 0.658603
Epoch: 0087 loss = 0.678975
Epoch: 0088 loss = 0.711539
Epoch: 0089 loss = 0.681730
Epoch: 0090 loss = 0.693841
Epoch: 0091 loss = 0.681009
Epoch: 0092 loss = 0.782855
Epoch: 0093 loss = 0.874786
Epoch: 0094 loss = 0.672197
Epoch: 0095 loss = 0.633733
Epoch: 0096 loss = 0.556728
Epoch: 0097 loss = 0.831323
Epoch: 0098 loss = 0.558681
Epoch: 0099 loss = 0.533441
Epoch: 0100 loss = 0.590111
Epoch: 0101 loss = 0.643299
Epoch: 0102 loss = 0.605565
Epoch: 0103 loss = 0.591993
Epoch: 0104 loss = 0.520707
Epoch: 0105 loss = 0.483253
Epoch: 0106 loss = 0.712508
Epoch: 0107 loss = 0.571707
Epoch: 0108 loss = 1.169423
Epoch: 0109 loss = 0.535332
Epoch: 0110 loss = 0.453589
Epoch: 0111 loss = 0.446560
Epoch: 0112 loss = 0.426477
Epoch: 0113 loss = 0.493104
Epoch: 0114 loss = 0.509590
Epoch: 0115 loss = 0.579829
Epoch: 0116 loss = 0.608740
Epoch: 0117 loss = 0.711096
Epoch: 0118 loss = 0.380994
Epoch: 0119 loss = 0.460077
Epoch: 0120 loss = 0.368121
Epoch: 0121 loss = 0.373412
Epoch: 0122 loss = 0.536381
Epoch: 0123 loss = 0.676862
Epoch: 0124 loss = 0.349716
Epoch: 0125 loss = 0.355957
Epoch: 0126 loss = 0.344182
Epoch: 0127 loss = 0.330639
Epoch: 0128 loss = 0.324074
Epoch: 0129 loss = 0.372293
Epoch: 0130 loss = 0.331763
Epoch: 0131 loss = 0.381932
Epoch: 0132 loss = 0.399452
Epoch: 0133 loss = 0.329681
Epoch: 0134 loss = 0.348422
Epoch: 0135 loss = 0.270047
Epoch: 0136 loss = 0.263128
Epoch: 0137 loss = 0.859267
Epoch: 0138 loss = 0.355453
Epoch: 0139 loss = 0.368301
Epoch: 0140 loss = 0.336994
Epoch: 0141 loss = 0.234687
Epoch: 0142 loss = 0.262411
Epoch: 0143 loss = 0.371318
Epoch: 0144 loss = 0.351419
Epoch: 0145 loss = 0.299207
Epoch: 0146 loss = 0.517518
Epoch: 0147 loss = 0.460913
Epoch: 0148 loss = 0.344867
Epoch: 0149 loss = 0.199342
Epoch: 0150 loss = 0.205287
Epoch: 0151 loss = 0.262834
Epoch: 0152 loss = 0.220459
Epoch: 0153 loss = 0.180993
Epoch: 0154 loss = 0.209213
Epoch: 0155 loss = 0.227413
Epoch: 0156 loss = 0.269258
Epoch: 0157 loss = 0.591394
Epoch: 0158 loss = 0.261003
Epoch: 0159 loss = 0.324858
Epoch: 0160 loss = 0.158121
Epoch: 0161 loss = 0.276058
Epoch: 0162 loss = 0.213697
Epoch: 0163 loss = 0.525186
Epoch: 0164 loss = 0.235756
Epoch: 0165 loss = 0.154653
Epoch: 0166 loss = 0.507320
Epoch: 0167 loss = 0.162138
Epoch: 0168 loss = 0.575264
Epoch: 0169 loss = 0.230388
Epoch: 0170 loss = 0.452536
Epoch: 0171 loss = 0.158406
Epoch: 0172 loss = 0.173370
Epoch: 0173 loss = 0.223438
Epoch: 0174 loss = 0.155896
Epoch: 0175 loss = 0.186039
Epoch: 0176 loss = 0.185827
Epoch: 0177 loss = 0.115934
Epoch: 0178 loss = 0.146922
Epoch: 0179 loss = 0.114881
Epoch: 0180 loss = 0.262710
Epoch: 0181 loss = 0.212661
Epoch: 0182 loss = 0.175950
Epoch: 0183 loss = 0.292528
Epoch: 0184 loss = 0.103780
Epoch: 0185 loss = 0.139636
Epoch: 0186 loss = 0.155410
Epoch: 0187 loss = 0.100161
Epoch: 0188 loss = 0.100273
Epoch: 0189 loss = 0.108895
Epoch: 0190 loss = 0.113401
Epoch: 0191 loss = 0.115439
Epoch: 0192 loss = 0.278598
Epoch: 0193 loss = 0.103555
Epoch: 0194 loss = 0.115570
Epoch: 0195 loss = 0.237133
Epoch: 0196 loss = 0.089641
Epoch: 0197 loss = 0.107708
Epoch: 0198 loss = 0.104051
Epoch: 0199 loss = 0.087422

# ----------------------


# ----------------------


# -------训练epoch：200


# 训练每一个loader中的数据：1


# Transformer


# 阶段一：encoder


<div style='color:#fe618e;font-weight:800;font-size:23px;'>encoder得到注意力操作</div>


: 

```python
enc_outputs, enc_self_attns = self.encoder(enc_inputs)
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


enc_inputs: 

```python
tensor([[1, 2, 3, 4, 0]])
```


enc_inputs.shape: 

```python
torch.Size([1, 5])
```


# Encoder中


<div style='color:#3296ee;font-weight:800;font-size:23px;'>enc_inputs转换为词向量的结果</div>


: 

```python
enc_outputs = self.src_emb(enc_inputs)
```


enc_outputs: 

```python
tensor([[[-0.9265, -1.7498, -0.0642, -0.8934],
         [ 0.4777, -1.6670, -0.2535, -1.5648],
         [ 0.3815, -0.1522, -1.3199,  0.1646],
         [-1.0256, -0.0970, -1.7463,  0.2517],
         [ 0.7371, -0.8480,  1.6767,  0.6005]]], grad_fn=<EmbeddingBackward0>)
```


enc_outputs.shape: 

```python
torch.Size([1, 5, 4])
```


## PositionalEncoding


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入加上位置编码的代码</div>


加上位置编码: 

```python
x = x + self.pe[:x.size(0), :]
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


x: 

```python
tensor([[[-0.9265, -1.7498, -0.0642, -0.8934]],

        [[ 0.4777, -1.6670, -0.2535, -1.5648]],

        [[ 0.3815, -0.1522, -1.3199,  0.1646]],

        [[-1.0256, -0.0970, -1.7463,  0.2517]],

        [[ 0.7371, -0.8480,  1.6767,  0.6005]]], grad_fn=<TransposeBackward0>)
```


x.shape: 

```python
torch.Size([5, 1, 4])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>位置编码</div>


self.pe[:x.size(0), :]: 

```python
tensor([[[ 0.0000,  1.0000,  0.0000,  1.0000]],

        [[ 0.8415,  0.5403,  0.0100,  0.9999]],

        [[ 0.9093, -0.4161,  0.0200,  0.9998]],

        [[ 0.1411, -0.9900,  0.0300,  0.9996]],

        [[-0.7568, -0.6536,  0.0400,  0.9992]]])
```


self.pe[:x.size(0), :].shape: 

```python
torch.Size([5, 1, 4])
```


self.pe.shape: 

```python
torch.Size([5000, 1, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


x: 

```python
tensor([[[-0.9265, -0.7498, -0.0642,  0.1066]],

        [[ 1.3192, -1.1267, -0.2435, -0.5649]],

        [[ 1.2908, -0.5683, -1.2999,  1.1644]],

        [[-0.8845, -1.0870, -1.7163,  1.2513]],

        [[-0.0197, -1.5016,  1.7167,  1.5997]]], grad_fn=<AddBackward0>)
```


x.shape: 

```python
torch.Size([5, 1, 4])
```


## get_attn_pad_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq_q: 

```python
tensor([[1, 2, 3, 4, 0]])
```


seq_q.shape: 

```python
torch.Size([1, 5])
```


seq_k: 

```python
tensor([[1, 2, 3, 4, 0]])
```


seq_k.shape: 

```python
torch.Size([1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>获取对应的大小：len_q,len_k</div>


例如: 

```python
batch_size, len_q = seq_q.size()
```


batch_size: 

```python
1
```


len_q: 

```python
5
```


len_k: 

```python
5
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>操作pad_attn_mask矩阵：pad_attn_mask</div>


: 

```python
pad_attn_mask = seq_k.data.eq(0).unsqueeze(1) 
```


pad_attn_mask: 

```python
tensor([[[False, False, False, False,  True]]])
```


pad_attn_mask.shape: 

```python
torch.Size([1, 1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>扩展pad_attn_mask矩阵：pad_attn_mask.expand</div>


: 

```python
ans = pad_attn_mask.expand(batch_size, len_q, len_k)  
```


ans: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


ans.shape: 

```python
torch.Size([1, 5, 5])
```


# EncoderLayer


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-1.0294, -0.8332, -0.0714,  0.1185],
         [ 1.4658, -0.0000, -0.2705, -0.6276],
         [ 1.4342, -0.6315, -1.4443,  0.0000],
         [-0.9828, -1.2078, -1.9070,  1.3903],
         [-0.0219, -1.6685,  1.9075,  1.7774]]], grad_fn=<TransposeBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_K: 

```python
tensor([[[-1.0294, -0.8332, -0.0714,  0.1185],
         [ 1.4658, -0.0000, -0.2705, -0.6276],
         [ 1.4342, -0.6315, -1.4443,  0.0000],
         [-0.9828, -1.2078, -1.9070,  1.3903],
         [-0.0219, -1.6685,  1.9075,  1.7774]]], grad_fn=<TransposeBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[-1.0294, -0.8332, -0.0714,  0.1185],
         [ 1.4658, -0.0000, -0.2705, -0.6276],
         [ 1.4342, -0.6315, -1.4443,  0.0000],
         [-0.9828, -1.2078, -1.9070,  1.3903],
         [-0.0219, -1.6685,  1.9075,  1.7774]]], grad_fn=<TransposeBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 5, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 0.5675, -0.0593],
          [-0.2044,  0.5195],
          [ 0.5917,  0.4729],
          [ 1.5626, -0.3462],
          [ 0.3272, -0.6270]],

         [[-0.4124,  0.5488],
          [ 0.1483, -0.4728],
          [ 0.4090,  0.3320],
          [ 0.3116,  1.7053],
          [-1.1859,  0.7374]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 5, 2])
```


K: 

```python
tensor([[[[-0.3913,  0.1724],
          [ 0.5025, -0.2470],
          [ 0.2843, -0.7140],
          [-0.7052, -0.6367],
          [ 0.5308, -0.4228]],

         [[-0.2346, -0.2209],
          [ 0.3168,  0.0221],
          [ 0.2458, -0.0367],
          [-0.3342, -0.1285],
          [ 0.7675, -1.7886]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.6658, -0.7068],
          [-0.8024,  0.5980],
          [-0.7983,  0.5152],
          [ 0.5048, -0.5693],
          [ 2.2647, -0.2287]],

         [[-0.4747, -0.2547],
          [ 0.5160,  0.2706],
          [ 0.6061,  0.0667],
          [-0.1976, -0.5268],
          [ 0.3451, -0.3833]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 0.5675, -0.0593],
          [-0.2044,  0.5195],
          [ 0.5917,  0.4729],
          [ 1.5626, -0.3462],
          [ 0.3272, -0.6270]],

         [[-0.4124,  0.5488],
          [ 0.1483, -0.4728],
          [ 0.4090,  0.3320],
          [ 0.3116,  1.7053],
          [-1.1859,  0.7374]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 5, 2])
```


K: 

```python
tensor([[[[-0.3913,  0.1724],
          [ 0.5025, -0.2470],
          [ 0.2843, -0.7140],
          [-0.7052, -0.6367],
          [ 0.5308, -0.4228]],

         [[-0.2346, -0.2209],
          [ 0.3168,  0.0221],
          [ 0.2458, -0.0367],
          [-0.3342, -0.1285],
          [ 0.7675, -1.7886]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.6658, -0.7068],
          [-0.8024,  0.5980],
          [-0.7983,  0.5152],
          [ 0.5048, -0.5693],
          [ 2.2647, -0.2287]],

         [[-0.4747, -0.2547],
          [ 0.5160,  0.2706],
          [ 0.6061,  0.0667],
          [-0.1976, -0.5268],
          [ 0.3451, -0.3833]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[-0.1643,  0.2120,  0.1441, -0.2563,  0.2307],
          [ 0.1199, -0.1633, -0.3034, -0.1320, -0.2320],
          [-0.1061,  0.1276, -0.1198, -0.5080,  0.0807],
          [-0.4745,  0.6156,  0.4889, -0.6233,  0.6900],
          [-0.1669,  0.2258,  0.3823,  0.1191,  0.3103]],

         [[-0.0173, -0.0838, -0.0859,  0.0476, -0.9179],
          [ 0.0492,  0.0258,  0.0380,  0.0079,  0.6785],
          [-0.1197,  0.0968,  0.0625, -0.1268, -0.1979],
          [-0.3180,  0.0965,  0.0099, -0.2286, -1.9877],
          [ 0.0815, -0.2541, -0.2253,  0.2133, -1.5762]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[-1.6426e-01,  2.1200e-01,  1.4405e-01, -2.5629e-01, -1.0000e+09],
          [ 1.1986e-01, -1.6335e-01, -3.0340e-01, -1.3202e-01, -1.0000e+09],
          [-1.0608e-01,  1.2763e-01, -1.1980e-01, -5.0797e-01, -1.0000e+09],
          [-4.7454e-01,  6.1564e-01,  4.8892e-01, -6.2334e-01, -1.0000e+09],
          [-1.6695e-01,  2.2576e-01,  3.8235e-01,  1.1915e-01, -1.0000e+09]],

         [[-1.7307e-02, -8.3788e-02, -8.5918e-02,  4.7606e-02, -1.0000e+09],
          [ 4.9242e-02,  2.5823e-02,  3.8047e-02,  7.8986e-03, -1.0000e+09],
          [-1.1968e-01,  9.6819e-02,  6.2481e-02, -1.2681e-01, -1.0000e+09],
          [-3.1800e-01,  9.6510e-02,  9.9350e-03, -2.2855e-01, -1.0000e+09],
          [ 8.1545e-02, -2.5412e-01, -2.2527e-01,  2.1329e-01, -1.0000e+09]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[0.2114, 0.3080, 0.2878, 0.1928, 0.0000],
          [0.3139, 0.2365, 0.2056, 0.2440, 0.0000],
          [0.2552, 0.3224, 0.2517, 0.1707, 0.0000],
          [0.1341, 0.3989, 0.3514, 0.1156, 0.0000],
          [0.1804, 0.2671, 0.3124, 0.2401, 0.0000]],

         [[0.2540, 0.2377, 0.2372, 0.2711, 0.0000],
          [0.2548, 0.2489, 0.2519, 0.2444, 0.0000],
          [0.2255, 0.2800, 0.2706, 0.2239, 0.0000],
          [0.2002, 0.3030, 0.2779, 0.2189, 0.0000],
          [0.2784, 0.1990, 0.2049, 0.3176, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[-0.2388,  0.0732],
          [-0.0217, -0.1134],
          [-0.2035,  0.0449],
          [-0.4530,  0.2591],
          [-0.2224,  0.0565]],

         [[ 0.0923, -0.1274],
          [ 0.1119, -0.1095],
          [ 0.1572, -0.0816],
          [ 0.1865, -0.0658],
          [ 0.0319, -0.1708]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[0.2114, 0.3080, 0.2878, 0.1928, 0.0000],
          [0.3139, 0.2365, 0.2056, 0.2440, 0.0000],
          [0.2552, 0.3224, 0.2517, 0.1707, 0.0000],
          [0.1341, 0.3989, 0.3514, 0.1156, 0.0000],
          [0.1804, 0.2671, 0.3124, 0.2401, 0.0000]],

         [[0.2540, 0.2377, 0.2372, 0.2711, 0.0000],
          [0.2548, 0.2489, 0.2519, 0.2444, 0.0000],
          [0.2255, 0.2800, 0.2706, 0.2239, 0.0000],
          [0.2002, 0.3030, 0.2779, 0.2189, 0.0000],
          [0.2784, 0.1990, 0.2049, 0.3176, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 5, 5])
```


context: 

```python
tensor([[[[-0.2388,  0.0732],
          [-0.0217, -0.1134],
          [-0.2035,  0.0449],
          [-0.4530,  0.2591],
          [-0.2224,  0.0565]],

         [[ 0.0923, -0.1274],
          [ 0.1119, -0.1095],
          [ 0.1572, -0.0816],
          [ 0.1865, -0.0658],
          [ 0.0319, -0.1708]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[-0.2388,  0.0732,  0.0923, -0.1274],
         [-0.0217, -0.1134,  0.1119, -0.1095],
         [-0.2035,  0.0449,  0.1572, -0.0816],
         [-0.4530,  0.2591,  0.1865, -0.0658],
         [-0.2224,  0.0565,  0.0319, -0.1708]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[-0.1467,  0.0307, -0.0663,  0.0286],
         [-0.0589, -0.0426,  0.0080, -0.0373],
         [-0.1494,  0.0128, -0.0379, -0.0109],
         [-0.2645,  0.0922, -0.1091,  0.0408],
         [-0.1233,  0.0307, -0.0772,  0.0526]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 5, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-1.0294, -0.8332, -0.0714,  0.1185],
         [ 1.4658, -0.0000, -0.2705, -0.6276],
         [ 1.4342, -0.6315, -1.4443,  0.0000],
         [-0.9828, -1.2078, -1.9070,  1.3903],
         [-0.0219, -1.6685,  1.9075,  1.7774]]], grad_fn=<TransposeBackward0>)
```


residual.shape: 

```python
torch.Size([1, 5, 4])
```


output + residual: 

```python
tensor([[[-1.1761, -0.8025, -0.1377,  0.1471],
         [ 1.4069, -0.0426, -0.2625, -0.6650],
         [ 1.2848, -0.6187, -1.4823, -0.0109],
         [-1.2473, -1.1156, -2.0161,  1.4311],
         [-0.1452, -1.6378,  1.8302,  1.8300]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-1.3049, -0.5920,  0.6767,  1.2201],
         [ 1.6600, -0.1942, -0.4755, -0.9903],
         [ 1.4805, -0.4089, -1.2661,  0.1944],
         [-0.3931, -0.2916, -0.9854,  1.6701],
         [-0.4210, -1.4437,  0.9324,  0.9323]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 5, 4])
```


## PoswiseFeedForwardNet


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


inputs: 

```python
tensor([[[-1.3049, -0.5920,  0.6767,  1.2201],
         [ 1.6600, -0.1942, -0.4755, -0.9903],
         [ 1.4805, -0.4089, -1.2661,  0.1944],
         [-0.3931, -0.2916, -0.9854,  1.6701],
         [-0.4210, -1.4437,  0.9324,  0.9323]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc操作的代码</div>


: 

```python
output = self.fc(inputs)
```


inputs: 

```python
tensor([[[-1.3049, -0.5920,  0.6767,  1.2201],
         [ 1.6600, -0.1942, -0.4755, -0.9903],
         [ 1.4805, -0.4089, -1.2661,  0.1944],
         [-0.3931, -0.2916, -0.9854,  1.6701],
         [-0.4210, -1.4437,  0.9324,  0.9323]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc原来是d_model->d_ff->d_model</div>


self.fc: 

```python
Sequential(
  (0): Linear(in_features=4, out_features=8, bias=False)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=4, bias=False)
)
```


output: 

```python
tensor([[[-1.1600e-01,  1.4376e-01, -5.7554e-02,  5.1051e-02],
         [ 4.3983e-01,  4.4043e-01, -5.0585e-02,  4.5022e-01],
         [ 3.7638e-01,  3.2391e-01,  5.7916e-02,  5.7656e-01],
         [-2.8286e-02,  2.2630e-01,  3.4646e-02,  1.6165e-01],
         [ 1.2441e-04,  2.0643e-02,  7.8832e-02,  3.2690e-02]]],
       grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 5, 4])
```


## 前馈层后的层归一化和残差


<div style='color:#fe618e;font-weight:800;font-size:23px;'>FeedForward后的层归一化和残差</div>


: 

```python
ans = nn.LayerNorm(d_model).to(device)(output + residual)
```


residual: 

```python
tensor([[[-1.3049, -0.5920,  0.6767,  1.2201],
         [ 1.6600, -0.1942, -0.4755, -0.9903],
         [ 1.4805, -0.4089, -1.2661,  0.1944],
         [-0.3931, -0.2916, -0.9854,  1.6701],
         [-0.4210, -1.4437,  0.9324,  0.9323]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>残差和层归一化之后的结果</div>


ans: 

```python
tensor([[[-1.3887, -0.4416,  0.5977,  1.2326],
         [ 1.6545, -0.0686, -0.7865, -0.7995],
         [ 1.3538, -0.3721, -1.3703,  0.3886],
         [-0.4956, -0.1562, -1.0002,  1.6521],
         [-0.4456, -1.4293,  0.9602,  0.9147]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans.shape: 

```python
torch.Size([1, 5, 4])
```


# EncoderLayer


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-1.3887, -0.4416,  0.5977,  1.2326],
         [ 1.6545, -0.0686, -0.7865, -0.7995],
         [ 1.3538, -0.3721, -1.3703,  0.3886],
         [-0.4956, -0.1562, -1.0002,  1.6521],
         [-0.4456, -1.4293,  0.9602,  0.9147]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_K: 

```python
tensor([[[-1.3887, -0.4416,  0.5977,  1.2326],
         [ 1.6545, -0.0686, -0.7865, -0.7995],
         [ 1.3538, -0.3721, -1.3703,  0.3886],
         [-0.4956, -0.1562, -1.0002,  1.6521],
         [-0.4456, -1.4293,  0.9602,  0.9147]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[-1.3887, -0.4416,  0.5977,  1.2326],
         [ 1.6545, -0.0686, -0.7865, -0.7995],
         [ 1.3538, -0.3721, -1.3703,  0.3886],
         [-0.4956, -0.1562, -1.0002,  1.6521],
         [-0.4456, -1.4293,  0.9602,  0.9147]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 5, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[-0.1535, -0.0996],
          [ 0.2855,  0.1537],
          [ 0.1639,  0.0344],
          [-0.2742, -0.2299],
          [ 0.3406,  0.1928]],

         [[ 0.5975, -0.4794],
          [-0.5126,  0.3577],
          [-0.3536, -0.0276],
          [ 0.1421, -0.5359],
          [ 0.6773, -0.3364]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 5, 2])
```


K: 

```python
tensor([[[[ 0.2185, -0.7392],
          [-0.2686,  0.5775],
          [-0.0203,  0.4520],
          [ 0.4379, -0.0150],
          [-0.2235, -1.0836]],

         [[-0.2912, -0.3925],
          [-0.0324,  0.4902],
          [-0.4264,  0.5265],
          [-0.4532,  0.0602],
          [-0.6468, -0.2305]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[-1.3276, -0.6445],
          [ 1.2277,  0.7569],
          [ 0.6675,  0.9688],
          [-0.7359,  0.3974],
          [-0.9914, -0.7110]],

         [[-0.0689, -0.7294],
          [ 0.4301,  1.0981],
          [ 1.0598,  1.4043],
          [ 0.8981,  0.4176],
          [ 0.0242, -0.2578]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[-0.1535, -0.0996],
          [ 0.2855,  0.1537],
          [ 0.1639,  0.0344],
          [-0.2742, -0.2299],
          [ 0.3406,  0.1928]],

         [[ 0.5975, -0.4794],
          [-0.5126,  0.3577],
          [-0.3536, -0.0276],
          [ 0.1421, -0.5359],
          [ 0.6773, -0.3364]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 5, 2])
```


K: 

```python
tensor([[[[ 0.2185, -0.7392],
          [-0.2686,  0.5775],
          [-0.0203,  0.4520],
          [ 0.4379, -0.0150],
          [-0.2235, -1.0836]],

         [[-0.2912, -0.3925],
          [-0.0324,  0.4902],
          [-0.4264,  0.5265],
          [-0.4532,  0.0602],
          [-0.6468, -0.2305]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[-1.3276, -0.6445],
          [ 1.2277,  0.7569],
          [ 0.6675,  0.9688],
          [-0.7359,  0.3974],
          [-0.9914, -0.7110]],

         [[-0.0689, -0.7294],
          [ 0.4301,  1.0981],
          [ 1.0598,  1.4043],
          [ 0.8981,  0.4176],
          [ 0.0242, -0.2578]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[ 0.0283, -0.0115, -0.0296, -0.0465,  0.1006],
          [-0.0363,  0.0086,  0.0450,  0.0868, -0.1629],
          [ 0.0073, -0.0171,  0.0086,  0.0504, -0.0523],
          [ 0.0778, -0.0418, -0.0695, -0.0825,  0.2195],
          [-0.0482,  0.0141,  0.0567,  0.1034, -0.2016]],

         [[ 0.0100, -0.1799, -0.3586, -0.2119, -0.1951],
          [ 0.0063,  0.1357,  0.2877,  0.1795,  0.1761],
          [ 0.0805, -0.0015,  0.0963,  0.1122,  0.1662],
          [ 0.1195, -0.1890, -0.2423, -0.0683,  0.0224],
          [-0.0461, -0.1321, -0.3294, -0.2314, -0.2549]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[ 2.8322e-02, -1.1497e-02, -2.9609e-02, -4.6490e-02, -1.0000e+09],
          [-3.6253e-02,  8.5584e-03,  4.5020e-02,  8.6769e-02, -1.0000e+09],
          [ 7.3430e-03, -1.7086e-02,  8.6344e-03,  5.0396e-02, -1.0000e+09],
          [ 7.7814e-02, -4.1807e-02, -6.9531e-02, -8.2482e-02, -1.0000e+09],
          [-4.8178e-02,  1.4061e-02,  5.6722e-02,  1.0341e-01, -1.0000e+09]],

         [[ 1.0006e-02, -1.7985e-01, -3.5862e-01, -2.1189e-01, -1.0000e+09],
          [ 6.2947e-03,  1.3573e-01,  2.8772e-01,  1.7951e-01, -1.0000e+09],
          [ 8.0483e-02, -1.4646e-03,  9.6339e-02,  1.1215e-01, -1.0000e+09],
          [ 1.1947e-01, -1.8899e-01, -2.4234e-01, -6.8344e-02, -1.0000e+09],
          [-4.6121e-02, -1.3211e-01, -3.2942e-01, -2.3137e-01, -1.0000e+09]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[0.2609, 0.2507, 0.2462, 0.2421, 0.0000],
          [0.2347, 0.2454, 0.2545, 0.2654, 0.0000],
          [0.2487, 0.2427, 0.2490, 0.2596, 0.0000],
          [0.2776, 0.2463, 0.2396, 0.2365, 0.0000],
          [0.2305, 0.2453, 0.2560, 0.2682, 0.0000]],

         [[0.3012, 0.2491, 0.2084, 0.2413, 0.0000],
          [0.2149, 0.2446, 0.2848, 0.2556, 0.0000],
          [0.2519, 0.2321, 0.2559, 0.2600, 0.0000],
          [0.3068, 0.2253, 0.2136, 0.2542, 0.0000],
          [0.2856, 0.2620, 0.2151, 0.2373, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[-0.0524,  0.3564],
          [-0.0356,  0.3866],
          [-0.0571,  0.3678],
          [-0.0803,  0.3336],
          [-0.0314,  0.3917]],

         [[ 0.5239,  0.4472],
          [ 0.6218,  0.6185],
          [ 0.5873,  0.5391],
          [ 0.5305,  0.4299],
          [ 0.5341,  0.4806]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[0.2609, 0.2507, 0.2462, 0.2421, 0.0000],
          [0.2347, 0.2454, 0.2545, 0.2654, 0.0000],
          [0.2487, 0.2427, 0.2490, 0.2596, 0.0000],
          [0.2776, 0.2463, 0.2396, 0.2365, 0.0000],
          [0.2305, 0.2453, 0.2560, 0.2682, 0.0000]],

         [[0.3012, 0.2491, 0.2084, 0.2413, 0.0000],
          [0.2149, 0.2446, 0.2848, 0.2556, 0.0000],
          [0.2519, 0.2321, 0.2559, 0.2600, 0.0000],
          [0.3068, 0.2253, 0.2136, 0.2542, 0.0000],
          [0.2856, 0.2620, 0.2151, 0.2373, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 5, 5])
```


context: 

```python
tensor([[[[-0.0524,  0.3564],
          [-0.0356,  0.3866],
          [-0.0571,  0.3678],
          [-0.0803,  0.3336],
          [-0.0314,  0.3917]],

         [[ 0.5239,  0.4472],
          [ 0.6218,  0.6185],
          [ 0.5873,  0.5391],
          [ 0.5305,  0.4299],
          [ 0.5341,  0.4806]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[-0.0524,  0.3564,  0.5239,  0.4472],
         [-0.0356,  0.3866,  0.6218,  0.6185],
         [-0.0571,  0.3678,  0.5873,  0.5391],
         [-0.0803,  0.3336,  0.5305,  0.4299],
         [-0.0314,  0.3917,  0.5341,  0.4806]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[-0.0030, -0.1418, -0.1467, -0.3502],
         [-0.0209, -0.2068, -0.1976, -0.4386],
         [-0.0118, -0.1796, -0.1770, -0.3954],
         [-0.0005, -0.1431, -0.1478, -0.3329],
         [-0.0062, -0.1451, -0.1514, -0.3783]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 5, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-1.3887, -0.4416,  0.5977,  1.2326],
         [ 1.6545, -0.0686, -0.7865, -0.7995],
         [ 1.3538, -0.3721, -1.3703,  0.3886],
         [-0.4956, -0.1562, -1.0002,  1.6521],
         [-0.4456, -1.4293,  0.9602,  0.9147]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 5, 4])
```


output + residual: 

```python
tensor([[[-1.3917, -0.5834,  0.4510,  0.8824],
         [ 1.6336, -0.2753, -0.9841, -1.2381],
         [ 1.3420, -0.5517, -1.5473, -0.0067],
         [-0.4962, -0.2993, -1.1480,  1.3192],
         [-0.4518, -1.5743,  0.8088,  0.5364]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-1.3861, -0.4761,  0.6883,  1.1739],
         [ 1.6446, -0.0528, -0.6830, -0.9088],
         [ 1.4693, -0.3458, -1.3001,  0.1766],
         [-0.3746, -0.1578, -1.0926,  1.6251],
         [-0.3007, -1.4992,  1.0453,  0.7545]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 5, 4])
```


## PoswiseFeedForwardNet


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


inputs: 

```python
tensor([[[-1.3861, -0.4761,  0.6883,  1.1739],
         [ 1.6446, -0.0528, -0.6830, -0.9088],
         [ 1.4693, -0.3458, -1.3001,  0.1766],
         [-0.3746, -0.1578, -1.0926,  1.6251],
         [-0.3007, -1.4992,  1.0453,  0.7545]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc操作的代码</div>


: 

```python
output = self.fc(inputs)
```


inputs: 

```python
tensor([[[-1.3861, -0.4761,  0.6883,  1.1739],
         [ 1.6446, -0.0528, -0.6830, -0.9088],
         [ 1.4693, -0.3458, -1.3001,  0.1766],
         [-0.3746, -0.1578, -1.0926,  1.6251],
         [-0.3007, -1.4992,  1.0453,  0.7545]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc原来是d_model->d_ff->d_model</div>


self.fc: 

```python
Sequential(
  (0): Linear(in_features=4, out_features=8, bias=False)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=4, bias=False)
)
```


output: 

```python
tensor([[[-0.0456,  0.1558, -0.0439,  0.3698],
         [ 0.0917, -0.0472, -0.1261,  0.0028],
         [ 0.0421, -0.0779, -0.1528,  0.0036],
         [-0.1097,  0.0754,  0.0198,  0.3882],
         [-0.1565, -0.0131, -0.1161,  0.1445]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 5, 4])
```


## 前馈层后的层归一化和残差


<div style='color:#fe618e;font-weight:800;font-size:23px;'>FeedForward后的层归一化和残差</div>


: 

```python
ans = nn.LayerNorm(d_model).to(device)(output + residual)
```


residual: 

```python
tensor([[[-1.3861, -0.4761,  0.6883,  1.1739],
         [ 1.6446, -0.0528, -0.6830, -0.9088],
         [ 1.4693, -0.3458, -1.3001,  0.1766],
         [-0.3746, -0.1578, -1.0926,  1.6251],
         [-0.3007, -1.4992,  1.0453,  0.7545]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>残差和层归一化之后的结果</div>


ans: 

```python
tensor([[[-1.3916, -0.3878,  0.4836,  1.2958],
         [ 1.6558, -0.0757, -0.7443, -0.8358],
         [ 1.4527, -0.3520, -1.3119,  0.2112],
         [-0.4968, -0.1511, -1.0028,  1.6507],
         [-0.4135, -1.4478,  0.9455,  0.9159]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans.shape: 

```python
torch.Size([1, 5, 4])
```


# Encoder结束


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


enc_outputs: 

```python
tensor([[[-1.3916, -0.3878,  0.4836,  1.2958],
         [ 1.6558, -0.0757, -0.7443, -0.8358],
         [ 1.4527, -0.3520, -1.3119,  0.2112],
         [-0.4968, -0.1511, -1.0028,  1.6507],
         [-0.4135, -1.4478,  0.9455,  0.9159]]],
       grad_fn=<NativeLayerNormBackward0>)
```


enc_outputs.shape: 

```python
torch.Size([1, 5, 4])
```


enc_self_attns: 

```python
[tensor([[[[0.2114, 0.3080, 0.2878, 0.1928, 0.0000],
          [0.3139, 0.2365, 0.2056, 0.2440, 0.0000],
          [0.2552, 0.3224, 0.2517, 0.1707, 0.0000],
          [0.1341, 0.3989, 0.3514, 0.1156, 0.0000],
          [0.1804, 0.2671, 0.3124, 0.2401, 0.0000]],

         [[0.2540, 0.2377, 0.2372, 0.2711, 0.0000],
          [0.2548, 0.2489, 0.2519, 0.2444, 0.0000],
          [0.2255, 0.2800, 0.2706, 0.2239, 0.0000],
          [0.2002, 0.3030, 0.2779, 0.2189, 0.0000],
          [0.2784, 0.1990, 0.2049, 0.3176, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>), tensor([[[[0.2609, 0.2507, 0.2462, 0.2421, 0.0000],
          [0.2347, 0.2454, 0.2545, 0.2654, 0.0000],
          [0.2487, 0.2427, 0.2490, 0.2596, 0.0000],
          [0.2776, 0.2463, 0.2396, 0.2365, 0.0000],
          [0.2305, 0.2453, 0.2560, 0.2682, 0.0000]],

         [[0.3012, 0.2491, 0.2084, 0.2413, 0.0000],
          [0.2149, 0.2446, 0.2848, 0.2556, 0.0000],
          [0.2519, 0.2321, 0.2559, 0.2600, 0.0000],
          [0.3068, 0.2253, 0.2136, 0.2542, 0.0000],
          [0.2856, 0.2620, 0.2151, 0.2373, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)]
```


# 阶段二：decoder


<div style='color:#fe618e;font-weight:800;font-size:23px;'>decoder得到注意力操作</div>


: 

```python
dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(dec_inputs, enc_inputs, enc_outputs)
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


dec_inputs: 

```python
tensor([[4, 1, 2, 3, 6, 0]])
```


dec_inputs.shape: 

```python
torch.Size([1, 6])
```


enc_inputs: 

```python
tensor([[1, 2, 3, 4, 0]])
```


enc_inputs.shape: 

```python
torch.Size([1, 5])
```


enc_outputs: 

```python
tensor([[[-1.3916, -0.3878,  0.4836,  1.2958],
         [ 1.6558, -0.0757, -0.7443, -0.8358],
         [ 1.4527, -0.3520, -1.3119,  0.2112],
         [-0.4968, -0.1511, -1.0028,  1.6507],
         [-0.4135, -1.4478,  0.9455,  0.9159]]],
       grad_fn=<NativeLayerNormBackward0>)
```


enc_outputs.shape: 

```python
torch.Size([1, 5, 4])
```


# Decoder中


<div style='color:#3296ee;font-weight:800;font-size:23px;'>dec_inputs转换为词向量的结果</div>


: 

```python
dec_outputs = self.tgt_emb(dec_inputs)
```


dec_outputs: 

```python
tensor([[[-1.0390,  1.3077, -0.2705, -0.4490],
         [ 1.2833, -0.4229,  0.4534, -1.6019],
         [ 0.1517,  1.9329, -0.6784, -0.9481],
         [-0.2252,  0.3250, -0.5726, -0.1818],
         [-1.2790, -2.6761,  0.6498, -0.5427],
         [ 0.9457, -1.1349,  0.9356, -0.5307]]], grad_fn=<EmbeddingBackward0>)
```


dec_outputs.shape: 

```python
torch.Size([1, 6, 4])
```


## PositionalEncoding


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入加上位置编码的代码</div>


加上位置编码: 

```python
x = x + self.pe[:x.size(0), :]
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


x: 

```python
tensor([[[-1.0390,  1.3077, -0.2705, -0.4490]],

        [[ 1.2833, -0.4229,  0.4534, -1.6019]],

        [[ 0.1517,  1.9329, -0.6784, -0.9481]],

        [[-0.2252,  0.3250, -0.5726, -0.1818]],

        [[-1.2790, -2.6761,  0.6498, -0.5427]],

        [[ 0.9457, -1.1349,  0.9356, -0.5307]]], grad_fn=<TransposeBackward0>)
```


x.shape: 

```python
torch.Size([6, 1, 4])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>位置编码</div>


self.pe[:x.size(0), :]: 

```python
tensor([[[ 0.0000,  1.0000,  0.0000,  1.0000]],

        [[ 0.8415,  0.5403,  0.0100,  0.9999]],

        [[ 0.9093, -0.4161,  0.0200,  0.9998]],

        [[ 0.1411, -0.9900,  0.0300,  0.9996]],

        [[-0.7568, -0.6536,  0.0400,  0.9992]],

        [[-0.9589,  0.2837,  0.0500,  0.9988]]])
```


self.pe[:x.size(0), :].shape: 

```python
torch.Size([6, 1, 4])
```


self.pe.shape: 

```python
torch.Size([5000, 1, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


x: 

```python
tensor([[[-1.0390,  2.3077, -0.2705,  0.5510]],

        [[ 2.1248,  0.1174,  0.4634, -0.6019]],

        [[ 1.0610,  1.5168, -0.6584,  0.0517]],

        [[-0.0840, -0.6650, -0.5426,  0.8178]],

        [[-2.0358, -3.3298,  0.6898,  0.4565]],

        [[-0.0132, -0.8512,  0.9856,  0.4680]]], grad_fn=<AddBackward0>)
```


x.shape: 

```python
torch.Size([6, 1, 4])
```


## decoder的self_attn的pad_mask


## get_attn_pad_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq_q: 

```python
tensor([[4, 1, 2, 3, 6, 0]])
```


seq_q.shape: 

```python
torch.Size([1, 6])
```


seq_k: 

```python
tensor([[4, 1, 2, 3, 6, 0]])
```


seq_k.shape: 

```python
torch.Size([1, 6])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>获取对应的大小：len_q,len_k</div>


例如: 

```python
batch_size, len_q = seq_q.size()
```


batch_size: 

```python
1
```


len_q: 

```python
6
```


len_k: 

```python
6
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>操作pad_attn_mask矩阵：pad_attn_mask</div>


: 

```python
pad_attn_mask = seq_k.data.eq(0).unsqueeze(1) 
```


pad_attn_mask: 

```python
tensor([[[False, False, False, False, False,  True]]])
```


pad_attn_mask.shape: 

```python
torch.Size([1, 1, 6])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>扩展pad_attn_mask矩阵：pad_attn_mask.expand</div>


: 

```python
ans = pad_attn_mask.expand(batch_size, len_q, len_k)  
```


ans: 

```python
tensor([[[False, False, False, False, False,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True]]])
```


ans.shape: 

```python
torch.Size([1, 6, 6])
```


## get_attn_subsequence_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq: 

```python
tensor([[4, 1, 2, 3, 6, 0]])
```


seq.shape: 

```python
torch.Size([1, 6])
```


<div style='color:#19ce8b;font-weight:800;font-size:23px;'>求attn_shape</div>


: 

```python
attn_shape = [seq.size(0), seq.size(1), seq.size(1)]
```


attn_shape: 

```python
[1, 6, 6]
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>生成一个上三角矩阵</div>


: 

```python
subsequence_mask = np.triu(np.ones(attn_shape), k=1)
```


subsequence_mask: 

```python
[[[0. 1. 1. 1. 1. 1.]
  [0. 0. 1. 1. 1. 1.]
  [0. 0. 0. 1. 1. 1.]
  [0. 0. 0. 0. 1. 1.]
  [0. 0. 0. 0. 0. 1.]
  [0. 0. 0. 0. 0. 0.]]]
```


subsequence_mask.shape: 

```python
(1, 6, 6)
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>生成subsequence_mask</div>


: 

```python
subsequence_mask = torch.from_numpy(subsequence_mask).byte()
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


subsequence_mask: 

```python
tensor([[[0, 1, 1, 1, 1, 1],
         [0, 0, 1, 1, 1, 1],
         [0, 0, 0, 1, 1, 1],
         [0, 0, 0, 0, 1, 1],
         [0, 0, 0, 0, 0, 1],
         [0, 0, 0, 0, 0, 0]]], dtype=torch.uint8)
```


subsequence_mask.shape: 

```python
torch.Size([1, 6, 6])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>两个mask相加</div>


: 

```python
dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequence_mask),0).to(device)
```


dec_self_attn_pad_mask: 

```python
tensor([[[False, False, False, False, False,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True]]])
```


dec_self_attn_pad_mask.shape: 

```python
torch.Size([1, 6, 6])
```


dec_self_attn_subsequence_mask: 

```python
tensor([[[0, 1, 1, 1, 1, 1],
         [0, 0, 1, 1, 1, 1],
         [0, 0, 0, 1, 1, 1],
         [0, 0, 0, 0, 1, 1],
         [0, 0, 0, 0, 0, 1],
         [0, 0, 0, 0, 0, 0]]], dtype=torch.uint8)
```


dec_self_attn_subsequence_mask.shape: 

```python
torch.Size([1, 6, 6])
```


dec_self_attn_mask: 

```python
tensor([[[False,  True,  True,  True,  True,  True],
         [False, False,  True,  True,  True,  True],
         [False, False, False,  True,  True,  True],
         [False, False, False, False,  True,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True]]])
```


dec_self_attn_mask.shape: 

```python
torch.Size([1, 6, 6])
```


## 交互注意力层中的pad_mask


## get_attn_pad_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq_q: 

```python
tensor([[4, 1, 2, 3, 6, 0]])
```


seq_q.shape: 

```python
torch.Size([1, 6])
```


seq_k: 

```python
tensor([[4, 1, 2, 3, 6, 0]])
```


seq_k.shape: 

```python
torch.Size([1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>获取对应的大小：len_q,len_k</div>


例如: 

```python
batch_size, len_q = seq_q.size()
```


batch_size: 

```python
1
```


len_q: 

```python
6
```


len_k: 

```python
5
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>操作pad_attn_mask矩阵：pad_attn_mask</div>


: 

```python
pad_attn_mask = seq_k.data.eq(0).unsqueeze(1) 
```


pad_attn_mask: 

```python
tensor([[[False, False, False, False,  True]]])
```


pad_attn_mask.shape: 

```python
torch.Size([1, 1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>扩展pad_attn_mask矩阵：pad_attn_mask.expand</div>


: 

```python
ans = pad_attn_mask.expand(batch_size, len_q, len_k)  
```


ans: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


ans.shape: 

```python
torch.Size([1, 6, 5])
```


# DecoderLayer


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-1.1544,  2.5641, -0.3006,  0.6122],
         [ 2.3609,  0.1305,  0.5149, -0.0000],
         [ 1.1788,  1.6853, -0.7315,  0.0575],
         [-0.0934, -0.7389, -0.6029,  0.9086],
         [-0.0000, -3.6997,  0.0000,  0.5073],
         [-0.0146, -0.9458,  1.0951,  0.5200]]], grad_fn=<TransposeBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 6, 4])
```


input_K: 

```python
tensor([[[-1.1544,  2.5641, -0.3006,  0.6122],
         [ 2.3609,  0.1305,  0.5149, -0.0000],
         [ 1.1788,  1.6853, -0.7315,  0.0575],
         [-0.0934, -0.7389, -0.6029,  0.9086],
         [-0.0000, -3.6997,  0.0000,  0.5073],
         [-0.0146, -0.9458,  1.0951,  0.5200]]], grad_fn=<TransposeBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 6, 4])
```


input_V: 

```python
tensor([[[-1.1544,  2.5641, -0.3006,  0.6122],
         [ 2.3609,  0.1305,  0.5149, -0.0000],
         [ 1.1788,  1.6853, -0.7315,  0.0575],
         [-0.0934, -0.7389, -0.6029,  0.9086],
         [-0.0000, -3.6997,  0.0000,  0.5073],
         [-0.0146, -0.9458,  1.0951,  0.5200]]], grad_fn=<TransposeBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 6, 4])
```


attn_mask: 

```python
tensor([[[False,  True,  True,  True,  True,  True],
         [False, False,  True,  True,  True,  True],
         [False, False, False,  True,  True,  True],
         [False, False, False, False,  True,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 6, 6])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 0.9401, -0.0801],
          [ 0.0670, -0.6184],
          [ 0.1674, -0.0735],
          [ 0.0215,  0.3257],
          [-0.7655,  0.4650],
          [ 0.3488, -0.4190]],

         [[-1.2250, -1.3382],
          [ 0.3868,  0.8094],
          [-0.2869,  0.1561],
          [-0.0749,  0.8109],
          [ 0.9825,  1.7565],
          [ 0.0586,  0.0690]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 6, 2])
```


K: 

```python
tensor([[[[-0.5556, -0.8592],
          [ 0.7478,  0.0573],
          [ 0.4251, -0.3739],
          [ 0.3107,  0.6422],
          [ 0.4779,  1.5526],
          [-0.0726,  0.2767]],

         [[-1.2788, -0.0487],
          [ 0.0476, -0.5358],
          [-0.3568, -0.6776],
          [ 0.3499, -0.1213],
          [ 1.5306,  0.3201],
          [-0.0648,  0.3338]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 6, 2])
```


V: 

```python
tensor([[[[ 0.6521,  1.1081],
          [ 0.6247, -1.0081],
          [ 0.7730,  0.0717],
          [-0.7315, -0.1468],
          [-1.7483, -1.0009],
          [-0.3089, -0.4763]],

         [[-0.3382,  0.7580],
          [-0.9381, -0.0682],
          [-1.0392,  0.7499],
          [ 0.0892,  0.5590],
          [ 0.9845, -0.3984],
          [ 0.3461, -0.4775]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 6, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False,  True,  True,  True,  True,  True],
          [False, False,  True,  True,  True,  True],
          [False, False, False,  True,  True,  True],
          [False, False, False, False,  True,  True],
          [False, False, False, False, False,  True],
          [False, False, False, False, False,  True]],

         [[False,  True,  True,  True,  True,  True],
          [False, False,  True,  True,  True,  True],
          [False, False, False,  True,  True,  True],
          [False, False, False, False,  True,  True],
          [False, False, False, False, False,  True],
          [False, False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 6, 6])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 0.9401, -0.0801],
          [ 0.0670, -0.6184],
          [ 0.1674, -0.0735],
          [ 0.0215,  0.3257],
          [-0.7655,  0.4650],
          [ 0.3488, -0.4190]],

         [[-1.2250, -1.3382],
          [ 0.3868,  0.8094],
          [-0.2869,  0.1561],
          [-0.0749,  0.8109],
          [ 0.9825,  1.7565],
          [ 0.0586,  0.0690]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 6, 2])
```


K: 

```python
tensor([[[[-0.5556, -0.8592],
          [ 0.7478,  0.0573],
          [ 0.4251, -0.3739],
          [ 0.3107,  0.6422],
          [ 0.4779,  1.5526],
          [-0.0726,  0.2767]],

         [[-1.2788, -0.0487],
          [ 0.0476, -0.5358],
          [-0.3568, -0.6776],
          [ 0.3499, -0.1213],
          [ 1.5306,  0.3201],
          [-0.0648,  0.3338]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 6, 2])
```


V: 

```python
tensor([[[[ 0.6521,  1.1081],
          [ 0.6247, -1.0081],
          [ 0.7730,  0.0717],
          [-0.7315, -0.1468],
          [-1.7483, -1.0009],
          [-0.3089, -0.4763]],

         [[-0.3382,  0.7580],
          [-0.9381, -0.0682],
          [-1.0392,  0.7499],
          [ 0.0892,  0.5590],
          [ 0.9845, -0.3984],
          [ 0.3461, -0.4775]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 6, 2])
```


attn_mask: 

```python
tensor([[[[False,  True,  True,  True,  True,  True],
          [False, False,  True,  True,  True,  True],
          [False, False, False,  True,  True,  True],
          [False, False, False, False,  True,  True],
          [False, False, False, False, False,  True],
          [False, False, False, False, False,  True]],

         [[False,  True,  True,  True,  True,  True],
          [False, False,  True,  True,  True,  True],
          [False, False, False,  True,  True,  True],
          [False, False, False, False,  True,  True],
          [False, False, False, False, False,  True],
          [False, False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 6, 6])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[-0.3207,  0.4939,  0.3037,  0.1701,  0.2298, -0.0639],
          [ 0.3494,  0.0104,  0.1836, -0.2661, -0.6563, -0.1244],
          [-0.0211,  0.0855,  0.0697,  0.0034, -0.0241, -0.0230],
          [-0.2063,  0.0246, -0.0797,  0.1526,  0.3649,  0.0626],
          [ 0.0183, -0.3859, -0.3530,  0.0430,  0.2518,  0.1302],
          [ 0.1175,  0.1674,  0.2156, -0.1137, -0.3422, -0.0999]],

         [[ 1.1537,  0.4658,  0.9502, -0.1883, -1.6287, -0.2597],
          [-0.3776, -0.2936, -0.4854,  0.0263,  0.6019,  0.1733],
          [ 0.2541, -0.0688, -0.0024, -0.0844, -0.2752,  0.0500],
          [ 0.0398, -0.3097, -0.3697, -0.0881,  0.1025,  0.1948],
          [-0.9489, -0.6324, -1.0895,  0.0924,  1.4610,  0.3696],
          [-0.0553, -0.0242, -0.0479,  0.0086,  0.0790,  0.0136]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 6, 6])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[-3.2069e-01, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [ 3.4940e-01,  1.0355e-02, -1.0000e+09, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [-2.1089e-02,  8.5514e-02,  6.9736e-02, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [-2.0632e-01,  2.4562e-02, -7.9654e-02,  1.5263e-01, -1.0000e+09,
           -1.0000e+09],
          [ 1.8274e-02, -3.8593e-01, -3.5301e-01,  4.2988e-02,  2.5176e-01,
           -1.0000e+09],
          [ 1.1754e-01,  1.6745e-01,  2.1561e-01, -1.1367e-01, -3.4217e-01,
           -1.0000e+09]],

         [[ 1.1537e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [-3.7764e-01, -2.9363e-01, -1.0000e+09, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [ 2.5409e-01, -6.8778e-02, -2.4051e-03, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [ 3.9787e-02, -3.0972e-01, -3.6968e-01, -8.8093e-02, -1.0000e+09,
           -1.0000e+09],
          [-9.4891e-01, -6.3239e-01, -1.0895e+00,  9.2411e-02,  1.4610e+00,
           -1.0000e+09],
          [-5.5336e-02, -2.4185e-02, -4.7855e-02,  8.5684e-03,  7.9017e-02,
           -1.0000e+09]]]], grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 6, 6])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5840, 0.4160, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3118, 0.3468, 0.3414, 0.0000, 0.0000, 0.0000],
          [0.2072, 0.2610, 0.2352, 0.2967, 0.0000, 0.0000],
          [0.2153, 0.1437, 0.1485, 0.2207, 0.2719, 0.0000],
          [0.2184, 0.2296, 0.2409, 0.1733, 0.1379, 0.0000]],

         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.4790, 0.5210, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.4003, 0.2899, 0.3098, 0.0000, 0.0000, 0.0000],
          [0.3078, 0.2170, 0.2044, 0.2708, 0.0000, 0.0000],
          [0.0581, 0.0798, 0.0505, 0.1646, 0.6470, 0.0000],
          [0.1905, 0.1965, 0.1919, 0.2031, 0.2179, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 6, 6])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.6521,  1.1081],
          [ 0.6407,  0.2277],
          [ 0.6839,  0.0203],
          [ 0.2629, -0.0602],
          [-0.2918, -0.2002],
          [ 0.1042, -0.1356]],

         [[-0.3382,  0.7580],
          [-0.6507,  0.3276],
          [-0.7293,  0.5160],
          [-0.4959,  0.5232],
          [ 0.5047, -0.0892],
          [-0.2156,  0.3017]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 6, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5840, 0.4160, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3118, 0.3468, 0.3414, 0.0000, 0.0000, 0.0000],
          [0.2072, 0.2610, 0.2352, 0.2967, 0.0000, 0.0000],
          [0.2153, 0.1437, 0.1485, 0.2207, 0.2719, 0.0000],
          [0.2184, 0.2296, 0.2409, 0.1733, 0.1379, 0.0000]],

         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.4790, 0.5210, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.4003, 0.2899, 0.3098, 0.0000, 0.0000, 0.0000],
          [0.3078, 0.2170, 0.2044, 0.2708, 0.0000, 0.0000],
          [0.0581, 0.0798, 0.0505, 0.1646, 0.6470, 0.0000],
          [0.1905, 0.1965, 0.1919, 0.2031, 0.2179, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 6, 6])
```


context: 

```python
tensor([[[[ 0.6521,  1.1081],
          [ 0.6407,  0.2277],
          [ 0.6839,  0.0203],
          [ 0.2629, -0.0602],
          [-0.2918, -0.2002],
          [ 0.1042, -0.1356]],

         [[-0.3382,  0.7580],
          [-0.6507,  0.3276],
          [-0.7293,  0.5160],
          [-0.4959,  0.5232],
          [ 0.5047, -0.0892],
          [-0.2156,  0.3017]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 6, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.6521,  1.1081, -0.3382,  0.7580],
         [ 0.6407,  0.2277, -0.6507,  0.3276],
         [ 0.6839,  0.0203, -0.7293,  0.5160],
         [ 0.2629, -0.0602, -0.4959,  0.5232],
         [-0.2918, -0.2002,  0.5047, -0.0892],
         [ 0.1042, -0.1356, -0.2156,  0.3017]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[ 0.6548,  0.1628, -0.2646,  0.4402],
         [ 0.3886,  0.1229, -0.0186,  0.6797],
         [ 0.3300,  0.1763, -0.0393,  0.8930],
         [ 0.0915,  0.1663, -0.0514,  0.6429],
         [-0.2212, -0.0657, -0.0424, -0.3709],
         [-0.0069,  0.0912, -0.0326,  0.3450]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 6, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-1.1544,  2.5641, -0.3006,  0.6122],
         [ 2.3609,  0.1305,  0.5149, -0.0000],
         [ 1.1788,  1.6853, -0.7315,  0.0575],
         [-0.0934, -0.7389, -0.6029,  0.9086],
         [-0.0000, -3.6997,  0.0000,  0.5073],
         [-0.0146, -0.9458,  1.0951,  0.5200]]], grad_fn=<TransposeBackward0>)
```


residual.shape: 

```python
torch.Size([1, 6, 4])
```


output + residual: 

```python
tensor([[[-4.9963e-01,  2.7269e+00, -5.6515e-01,  1.0524e+00],
         [ 2.7495e+00,  2.5333e-01,  4.9627e-01,  6.7966e-01],
         [ 1.5089e+00,  1.8616e+00, -7.7084e-01,  9.5045e-01],
         [-1.8670e-03, -5.7257e-01, -6.5426e-01,  1.5515e+00],
         [-2.2122e-01, -3.7654e+00, -4.2356e-02,  1.3634e-01],
         [-2.1529e-02, -8.5461e-01,  1.0624e+00,  8.6497e-01]]],
       grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-0.8740,  1.5193, -0.9226,  0.2773],
         [ 1.7120, -0.7947, -0.5507, -0.3666],
         [ 0.6145,  0.9634, -1.6402,  0.0622],
         [-0.0932, -0.7377, -0.8299,  1.6608],
         [ 0.4650, -1.7267,  0.5756,  0.6861],
         [-0.3724, -1.4636,  1.0473,  0.7887]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 6, 4])
```


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-0.8740,  1.5193, -0.9226,  0.2773],
         [ 1.7120, -0.7947, -0.5507, -0.3666],
         [ 0.6145,  0.9634, -1.6402,  0.0622],
         [-0.0932, -0.7377, -0.8299,  1.6608],
         [ 0.4650, -1.7267,  0.5756,  0.6861],
         [-0.3724, -1.4636,  1.0473,  0.7887]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 6, 4])
```


input_K: 

```python
tensor([[[-1.3916, -0.3878,  0.4836,  1.2958],
         [ 1.6558, -0.0757, -0.7443, -0.8358],
         [ 1.4527, -0.3520, -1.3119,  0.2112],
         [-0.4968, -0.1511, -1.0028,  1.6507],
         [-0.4135, -1.4478,  0.9455,  0.9159]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[-1.3916, -0.3878,  0.4836,  1.2958],
         [ 1.6558, -0.0757, -0.7443, -0.8358],
         [ 1.4527, -0.3520, -1.3119,  0.2112],
         [-0.4968, -0.1511, -1.0028,  1.6507],
         [-0.4135, -1.4478,  0.9455,  0.9159]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 6, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 1.0456,  0.3376],
          [-0.9163,  0.7295],
          [ 0.3576,  1.0504],
          [ 0.3534, -0.6771],
          [-0.6553, -0.8395],
          [-0.2999, -1.2710]],

         [[-0.7485,  0.2138],
          [ 0.3065, -0.0588],
          [-0.5695,  0.1679],
          [ 0.1110, -0.4372],
          [ 0.7333, -0.4313],
          [ 0.6614, -0.4110]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 6, 2])
```


K: 

```python
tensor([[[[-2.4182e-01,  4.5698e-01],
          [ 4.1288e-01, -1.9502e-01],
          [ 5.4010e-01,  1.2592e-01],
          [ 1.4578e-01,  4.0114e-01],
          [-1.7941e-04,  7.6146e-01]],

         [[ 1.3232e+00,  7.4697e-01],
          [-1.2293e+00, -6.1627e-01],
          [-8.5388e-01, -4.1521e-01],
          [ 5.6531e-01,  2.3314e-01],
          [ 1.1611e+00,  9.3967e-01]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[-0.7010,  0.5195],
          [ 0.6817, -0.5419],
          [ 0.0723, -0.5484],
          [-1.1695, -0.0465],
          [ 0.3677,  0.5871]],

         [[-0.4754, -0.0329],
          [ 0.3978,  0.3903],
          [ 0.0359,  0.7360],
          [-0.6344,  0.4225],
          [-0.0776,  0.4176]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 6, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 1.0456,  0.3376],
          [-0.9163,  0.7295],
          [ 0.3576,  1.0504],
          [ 0.3534, -0.6771],
          [-0.6553, -0.8395],
          [-0.2999, -1.2710]],

         [[-0.7485,  0.2138],
          [ 0.3065, -0.0588],
          [-0.5695,  0.1679],
          [ 0.1110, -0.4372],
          [ 0.7333, -0.4313],
          [ 0.6614, -0.4110]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 6, 2])
```


K: 

```python
tensor([[[[-2.4182e-01,  4.5698e-01],
          [ 4.1288e-01, -1.9502e-01],
          [ 5.4010e-01,  1.2592e-01],
          [ 1.4578e-01,  4.0114e-01],
          [-1.7941e-04,  7.6146e-01]],

         [[ 1.3232e+00,  7.4697e-01],
          [-1.2293e+00, -6.1627e-01],
          [-8.5388e-01, -4.1521e-01],
          [ 5.6531e-01,  2.3314e-01],
          [ 1.1611e+00,  9.3967e-01]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[-0.7010,  0.5195],
          [ 0.6817, -0.5419],
          [ 0.0723, -0.5484],
          [-1.1695, -0.0465],
          [ 0.3677,  0.5871]],

         [[-0.4754, -0.0329],
          [ 0.3978,  0.3903],
          [ 0.0359,  0.7360],
          [-0.6344,  0.4225],
          [-0.0776,  0.4176]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 6, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[-0.0697,  0.2587,  0.4294,  0.2035,  0.1816],
          [ 0.3924, -0.3681, -0.2850,  0.1125,  0.3929],
          [ 0.2783, -0.0405,  0.2301,  0.3348,  0.5655],
          [-0.2792,  0.1965,  0.0747, -0.1556, -0.3646],
          [-0.1592, -0.0755, -0.3250, -0.3057, -0.4519],
          [-0.3594,  0.0877, -0.2277, -0.3914, -0.6843]],

         [[-0.5874,  0.5575,  0.3892, -0.2640, -0.4725],
          [ 0.2557, -0.2407, -0.1678,  0.1128,  0.2125],
          [-0.4442,  0.4219,  0.2946, -0.2000, -0.3560],
          [-0.1270,  0.0940,  0.0613, -0.0277, -0.1993],
          [ 0.4584, -0.4495, -0.3162,  0.2220,  0.3155],
          [ 0.4018, -0.3958, -0.2787,  0.1966,  0.2699]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 6, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[-6.9711e-02,  2.5872e-01,  4.2938e-01,  2.0354e-01, -1.0000e+09],
          [ 3.9242e-01, -3.6812e-01, -2.8499e-01,  1.1247e-01, -1.0000e+09],
          [ 2.7828e-01, -4.0456e-02,  2.3009e-01,  3.3481e-01, -1.0000e+09],
          [-2.7922e-01,  1.9654e-01,  7.4668e-02, -1.5563e-01, -1.0000e+09],
          [-1.5922e-01, -7.5545e-02, -3.2500e-01, -3.0566e-01, -1.0000e+09],
          [-3.5942e-01,  8.7715e-02, -2.2769e-01, -3.9142e-01, -1.0000e+09]],

         [[-5.8743e-01,  5.5748e-01,  3.8916e-01, -2.6395e-01, -1.0000e+09],
          [ 2.5566e-01, -2.4075e-01, -1.6776e-01,  1.1280e-01, -1.0000e+09],
          [-4.4417e-01,  4.2188e-01,  2.9455e-01, -1.9997e-01, -1.0000e+09],
          [-1.2704e-01,  9.4010e-02,  6.1328e-02, -2.7696e-02, -1.0000e+09],
          [ 4.5837e-01, -4.4953e-01, -3.1615e-01,  2.2204e-01, -1.0000e+09],
          [ 4.0178e-01, -3.9585e-01, -2.7868e-01,  1.9663e-01, -1.0000e+09]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 6, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[0.1869, 0.2596, 0.3079, 0.2456, 0.0000],
          [0.3661, 0.1711, 0.1860, 0.2767, 0.0000],
          [0.2675, 0.1945, 0.2549, 0.2831, 0.0000],
          [0.1936, 0.3115, 0.2758, 0.2191, 0.0000],
          [0.2633, 0.2863, 0.2231, 0.2274, 0.0000],
          [0.2140, 0.3346, 0.2441, 0.2072, 0.0000]],

         [[0.1223, 0.3842, 0.3246, 0.1690, 0.0000],
          [0.3194, 0.1945, 0.2092, 0.2769, 0.0000],
          [0.1482, 0.3524, 0.3102, 0.1892, 0.0000],
          [0.2193, 0.2736, 0.2648, 0.2423, 0.0000],
          [0.3768, 0.1520, 0.1737, 0.2975, 0.0000],
          [0.3608, 0.1625, 0.1827, 0.2939, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 6, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[-0.2191, -0.2238],
          [-0.4502, -0.0174],
          [-0.3676, -0.1194],
          [-0.1596, -0.2297],
          [-0.2393, -0.1513],
          [-0.1466, -0.2137]],

         [[-0.0008,  0.4562],
          [-0.2427,  0.3363],
          [-0.0392,  0.4409],
          [-0.1396,  0.3968],
          [-0.3012,  0.3005],
          [-0.2868,  0.3102]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 6, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[0.1869, 0.2596, 0.3079, 0.2456, 0.0000],
          [0.3661, 0.1711, 0.1860, 0.2767, 0.0000],
          [0.2675, 0.1945, 0.2549, 0.2831, 0.0000],
          [0.1936, 0.3115, 0.2758, 0.2191, 0.0000],
          [0.2633, 0.2863, 0.2231, 0.2274, 0.0000],
          [0.2140, 0.3346, 0.2441, 0.2072, 0.0000]],

         [[0.1223, 0.3842, 0.3246, 0.1690, 0.0000],
          [0.3194, 0.1945, 0.2092, 0.2769, 0.0000],
          [0.1482, 0.3524, 0.3102, 0.1892, 0.0000],
          [0.2193, 0.2736, 0.2648, 0.2423, 0.0000],
          [0.3768, 0.1520, 0.1737, 0.2975, 0.0000],
          [0.3608, 0.1625, 0.1827, 0.2939, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 6, 5])
```


context: 

```python
tensor([[[[-0.2191, -0.2238],
          [-0.4502, -0.0174],
          [-0.3676, -0.1194],
          [-0.1596, -0.2297],
          [-0.2393, -0.1513],
          [-0.1466, -0.2137]],

         [[-0.0008,  0.4562],
          [-0.2427,  0.3363],
          [-0.0392,  0.4409],
          [-0.1396,  0.3968],
          [-0.3012,  0.3005],
          [-0.2868,  0.3102]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 6, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[-0.2191, -0.2238, -0.0008,  0.4562],
         [-0.4502, -0.0174, -0.2427,  0.3363],
         [-0.3676, -0.1194, -0.0392,  0.4409],
         [-0.1596, -0.2297, -0.1396,  0.3968],
         [-0.2393, -0.1513, -0.3012,  0.3005],
         [-0.1466, -0.2137, -0.2868,  0.3102]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[-0.3177, -0.1355,  0.4014, -0.0226],
         [-0.2989,  0.0020,  0.4693, -0.0255],
         [-0.3198, -0.1089,  0.4364, -0.0088],
         [-0.3052, -0.0693,  0.4081, -0.0528],
         [-0.2872,  0.0225,  0.4323, -0.0581],
         [-0.2868,  0.0095,  0.4141, -0.0695]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 6, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-0.8740,  1.5193, -0.9226,  0.2773],
         [ 1.7120, -0.7947, -0.5507, -0.3666],
         [ 0.6145,  0.9634, -1.6402,  0.0622],
         [-0.0932, -0.7377, -0.8299,  1.6608],
         [ 0.4650, -1.7267,  0.5756,  0.6861],
         [-0.3724, -1.4636,  1.0473,  0.7887]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 6, 4])
```


output + residual: 

```python
tensor([[[-1.1917,  1.3838, -0.5212,  0.2547],
         [ 1.4131, -0.7927, -0.0814, -0.3921],
         [ 0.2948,  0.8545, -1.2038,  0.0534],
         [-0.3984, -0.8070, -0.4218,  1.6080],
         [ 0.1778, -1.7043,  1.0079,  0.6280],
         [-0.6592, -1.4542,  1.4615,  0.7192]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-1.2246,  1.4641, -0.5247,  0.2853],
         [ 1.6509, -0.9949, -0.1417, -0.5144],
         [ 0.3917,  1.1349, -1.5979,  0.0713],
         [-0.4165, -0.8487, -0.4412,  1.7063],
         [ 0.1444, -1.6618,  0.9410,  0.5764],
         [-0.5929, -1.2900,  1.2669,  0.6159]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 6, 4])
```


## PoswiseFeedForwardNet


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


inputs: 

```python
tensor([[[-1.2246,  1.4641, -0.5247,  0.2853],
         [ 1.6509, -0.9949, -0.1417, -0.5144],
         [ 0.3917,  1.1349, -1.5979,  0.0713],
         [-0.4165, -0.8487, -0.4412,  1.7063],
         [ 0.1444, -1.6618,  0.9410,  0.5764],
         [-0.5929, -1.2900,  1.2669,  0.6159]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc操作的代码</div>


: 

```python
output = self.fc(inputs)
```


inputs: 

```python
tensor([[[-1.2246,  1.4641, -0.5247,  0.2853],
         [ 1.6509, -0.9949, -0.1417, -0.5144],
         [ 0.3917,  1.1349, -1.5979,  0.0713],
         [-0.4165, -0.8487, -0.4412,  1.7063],
         [ 0.1444, -1.6618,  0.9410,  0.5764],
         [-0.5929, -1.2900,  1.2669,  0.6159]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc原来是d_model->d_ff->d_model</div>


self.fc: 

```python
Sequential(
  (0): Linear(in_features=4, out_features=8, bias=False)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=4, bias=False)
)
```


output: 

```python
tensor([[[ 0.0282, -0.1878, -0.1874,  0.1961],
         [-0.0387, -0.0911, -0.1748,  0.2358],
         [ 0.0442, -0.2658, -0.2828,  0.2856],
         [ 0.0214, -0.4527, -0.1346,  0.4751],
         [-0.0118, -0.1583,  0.1337,  0.0320],
         [ 0.0543, -0.0599,  0.3438, -0.2657]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 6, 4])
```


## 前馈层后的层归一化和残差


<div style='color:#fe618e;font-weight:800;font-size:23px;'>FeedForward后的层归一化和残差</div>


: 

```python
ans = nn.LayerNorm(d_model).to(device)(output + residual)
```


residual: 

```python
tensor([[[-1.2246,  1.4641, -0.5247,  0.2853],
         [ 1.6509, -0.9949, -0.1417, -0.5144],
         [ 0.3917,  1.1349, -1.5979,  0.0713],
         [-0.4165, -0.8487, -0.4412,  1.7063],
         [ 0.1444, -1.6618,  0.9410,  0.5764],
         [-0.5929, -1.2900,  1.2669,  0.6159]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>残差和层归一化之后的结果</div>


ans: 

```python
tensor([[[-1.1898,  1.3493, -0.6925,  0.5331],
         [ 1.6386, -1.0748, -0.3009, -0.2628],
         [ 0.4576,  0.8616, -1.7032,  0.3839],
         [-0.2828, -0.9709, -0.4200,  1.6736],
         [ 0.1213, -1.6510,  0.9764,  0.5532],
         [-0.5067, -1.2452,  1.4496,  0.3023]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans.shape: 

```python
torch.Size([1, 6, 4])
```


# DecoderLayer


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-1.1898,  1.3493, -0.6925,  0.5331],
         [ 1.6386, -1.0748, -0.3009, -0.2628],
         [ 0.4576,  0.8616, -1.7032,  0.3839],
         [-0.2828, -0.9709, -0.4200,  1.6736],
         [ 0.1213, -1.6510,  0.9764,  0.5532],
         [-0.5067, -1.2452,  1.4496,  0.3023]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 6, 4])
```


input_K: 

```python
tensor([[[-1.1898,  1.3493, -0.6925,  0.5331],
         [ 1.6386, -1.0748, -0.3009, -0.2628],
         [ 0.4576,  0.8616, -1.7032,  0.3839],
         [-0.2828, -0.9709, -0.4200,  1.6736],
         [ 0.1213, -1.6510,  0.9764,  0.5532],
         [-0.5067, -1.2452,  1.4496,  0.3023]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 6, 4])
```


input_V: 

```python
tensor([[[-1.1898,  1.3493, -0.6925,  0.5331],
         [ 1.6386, -1.0748, -0.3009, -0.2628],
         [ 0.4576,  0.8616, -1.7032,  0.3839],
         [-0.2828, -0.9709, -0.4200,  1.6736],
         [ 0.1213, -1.6510,  0.9764,  0.5532],
         [-0.5067, -1.2452,  1.4496,  0.3023]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 6, 4])
```


attn_mask: 

```python
tensor([[[False,  True,  True,  True,  True,  True],
         [False, False,  True,  True,  True,  True],
         [False, False, False,  True,  True,  True],
         [False, False, False, False,  True,  True],
         [False, False, False, False, False,  True],
         [False, False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 6, 6])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 0.0673,  1.1161],
          [-0.5331, -0.8876],
          [-0.7485,  0.6306],
          [ 0.2263,  0.0096],
          [ 0.5071, -0.8361],
          [ 0.7921, -0.6231]],

         [[ 0.3075, -0.0710],
          [-0.0605, -0.3626],
          [ 0.5592, -0.6555],
          [-0.8882, -0.4941],
          [-0.9696,  0.0891],
          [-0.8949,  0.4168]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 6, 2])
```


K: 

```python
tensor([[[[ 0.4046, -0.1254],
          [ 0.2446,  0.6456],
          [ 1.1683,  0.7463],
          [-0.3693,  0.4924],
          [-1.0307, -0.0505],
          [-1.2590, -0.4965]],

         [[ 0.2677, -0.6682],
          [-0.0988, -0.1079],
          [ 0.2945, -1.3825],
          [ 0.3697, -0.1209],
          [-0.0581,  0.9718],
          [-0.1348,  1.2694]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 6, 2])
```


V: 

```python
tensor([[[[ 0.3131,  0.2374],
          [-0.3839, -0.6055],
          [-0.0158, -0.5866],
          [-0.2077,  0.5576],
          [-0.2566,  0.5413],
          [-0.0793,  0.7693]],

         [[ 0.6710, -0.5640],
          [-0.4146,  0.5048],
          [ 0.5364, -0.2836],
          [ 0.3143,  0.5199],
          [-0.4029,  0.7171],
          [-0.3969,  0.4949]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 6, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False,  True,  True,  True,  True,  True],
          [False, False,  True,  True,  True,  True],
          [False, False, False,  True,  True,  True],
          [False, False, False, False,  True,  True],
          [False, False, False, False, False,  True],
          [False, False, False, False, False,  True]],

         [[False,  True,  True,  True,  True,  True],
          [False, False,  True,  True,  True,  True],
          [False, False, False,  True,  True,  True],
          [False, False, False, False,  True,  True],
          [False, False, False, False, False,  True],
          [False, False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 6, 6])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 0.0673,  1.1161],
          [-0.5331, -0.8876],
          [-0.7485,  0.6306],
          [ 0.2263,  0.0096],
          [ 0.5071, -0.8361],
          [ 0.7921, -0.6231]],

         [[ 0.3075, -0.0710],
          [-0.0605, -0.3626],
          [ 0.5592, -0.6555],
          [-0.8882, -0.4941],
          [-0.9696,  0.0891],
          [-0.8949,  0.4168]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 6, 2])
```


K: 

```python
tensor([[[[ 0.4046, -0.1254],
          [ 0.2446,  0.6456],
          [ 1.1683,  0.7463],
          [-0.3693,  0.4924],
          [-1.0307, -0.0505],
          [-1.2590, -0.4965]],

         [[ 0.2677, -0.6682],
          [-0.0988, -0.1079],
          [ 0.2945, -1.3825],
          [ 0.3697, -0.1209],
          [-0.0581,  0.9718],
          [-0.1348,  1.2694]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 6, 2])
```


V: 

```python
tensor([[[[ 0.3131,  0.2374],
          [-0.3839, -0.6055],
          [-0.0158, -0.5866],
          [-0.2077,  0.5576],
          [-0.2566,  0.5413],
          [-0.0793,  0.7693]],

         [[ 0.6710, -0.5640],
          [-0.4146,  0.5048],
          [ 0.5364, -0.2836],
          [ 0.3143,  0.5199],
          [-0.4029,  0.7171],
          [-0.3969,  0.4949]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 6, 2])
```


attn_mask: 

```python
tensor([[[[False,  True,  True,  True,  True,  True],
          [False, False,  True,  True,  True,  True],
          [False, False, False,  True,  True,  True],
          [False, False, False, False,  True,  True],
          [False, False, False, False, False,  True],
          [False, False, False, False, False,  True]],

         [[False,  True,  True,  True,  True,  True],
          [False, False,  True,  True,  True,  True],
          [False, False, False,  True,  True,  True],
          [False, False, False, False,  True,  True],
          [False, False, False, False, False,  True],
          [False, False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 6, 6])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[-0.0797,  0.5211,  0.6446,  0.3710, -0.0889, -0.4517],
          [-0.0738, -0.4974, -0.9088, -0.1698,  0.4202,  0.7862],
          [-0.2700,  0.1584, -0.2856,  0.4150,  0.5230,  0.4450],
          [ 0.0639,  0.0435,  0.1920, -0.0558, -0.1653, -0.2048],
          [ 0.2192, -0.2940, -0.0223, -0.4235, -0.3398, -0.1579],
          [ 0.2818, -0.1474,  0.3256, -0.4238, -0.5551, -0.4864]],

         [[ 0.0917, -0.0161,  0.1334,  0.0864, -0.0614, -0.0930],
          [ 0.1599,  0.0319,  0.3419,  0.0152, -0.2467, -0.3197],
          [ 0.4155,  0.0110,  0.7573,  0.2022, -0.4734, -0.6417],
          [ 0.0653,  0.0997,  0.2980, -0.1900, -0.3030, -0.3588],
          [-0.2256,  0.0609, -0.2891, -0.2611,  0.1010,  0.1724],
          [-0.3663,  0.0307, -0.5939, -0.2696,  0.3232,  0.4594]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 6, 6])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[-7.9678e-02, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [-7.3842e-02, -4.9737e-01, -1.0000e+09, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [-2.7002e-01,  1.5839e-01, -2.8559e-01, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [ 6.3886e-02,  4.3499e-02,  1.9198e-01, -5.5767e-02, -1.0000e+09,
           -1.0000e+09],
          [ 2.1917e-01, -2.9395e-01, -2.2303e-02, -4.2352e-01, -3.3975e-01,
           -1.0000e+09],
          [ 2.8183e-01, -1.4742e-01,  3.2559e-01, -4.2379e-01, -5.5510e-01,
           -1.0000e+09]],

         [[ 9.1722e-02, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [ 1.5989e-01,  3.1888e-02, -1.0000e+09, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [ 4.1553e-01,  1.0953e-02,  7.5727e-01, -1.0000e+09, -1.0000e+09,
           -1.0000e+09],
          [ 6.5311e-02,  9.9726e-02,  2.9800e-01, -1.8997e-01, -1.0000e+09,
           -1.0000e+09],
          [-2.2562e-01,  6.0920e-02, -2.8906e-01, -2.6109e-01,  1.0105e-01,
           -1.0000e+09],
          [-3.6631e-01,  3.0706e-02, -5.9387e-01, -2.6958e-01,  3.2317e-01,
           -1.0000e+09]]]], grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 6, 6])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.6043, 0.3957, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.2841, 0.4361, 0.2798, 0.0000, 0.0000, 0.0000],
          [0.2498, 0.2447, 0.2839, 0.2216, 0.0000, 0.0000],
          [0.2872, 0.1719, 0.2256, 0.1510, 0.1642, 0.0000],
          [0.2760, 0.1797, 0.2884, 0.1363, 0.1195, 0.0000]],

         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5320, 0.4680, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3252, 0.2170, 0.4577, 0.0000, 0.0000, 0.0000],
          [0.2456, 0.2542, 0.3099, 0.1903, 0.0000, 0.0000],
          [0.1779, 0.2369, 0.1669, 0.1717, 0.2466, 0.0000],
          [0.1568, 0.2332, 0.1249, 0.1727, 0.3124, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 6, 6])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.3131,  0.2374],
          [ 0.0373, -0.0961],
          [-0.0829, -0.3607],
          [-0.0663, -0.1319],
          [-0.0532,  0.0049],
          [-0.0461, -0.0717]],

         [[ 0.6710, -0.5640],
          [ 0.1629, -0.0637],
          [ 0.3738, -0.2037],
          [ 0.2854,  0.0008],
          [ 0.0653,  0.2380],
          [ 0.0039,  0.3077]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 6, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.6043, 0.3957, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.2841, 0.4361, 0.2798, 0.0000, 0.0000, 0.0000],
          [0.2498, 0.2447, 0.2839, 0.2216, 0.0000, 0.0000],
          [0.2872, 0.1719, 0.2256, 0.1510, 0.1642, 0.0000],
          [0.2760, 0.1797, 0.2884, 0.1363, 0.1195, 0.0000]],

         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5320, 0.4680, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3252, 0.2170, 0.4577, 0.0000, 0.0000, 0.0000],
          [0.2456, 0.2542, 0.3099, 0.1903, 0.0000, 0.0000],
          [0.1779, 0.2369, 0.1669, 0.1717, 0.2466, 0.0000],
          [0.1568, 0.2332, 0.1249, 0.1727, 0.3124, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 6, 6])
```


context: 

```python
tensor([[[[ 0.3131,  0.2374],
          [ 0.0373, -0.0961],
          [-0.0829, -0.3607],
          [-0.0663, -0.1319],
          [-0.0532,  0.0049],
          [-0.0461, -0.0717]],

         [[ 0.6710, -0.5640],
          [ 0.1629, -0.0637],
          [ 0.3738, -0.2037],
          [ 0.2854,  0.0008],
          [ 0.0653,  0.2380],
          [ 0.0039,  0.3077]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 6, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.3131,  0.2374,  0.6710, -0.5640],
         [ 0.0373, -0.0961,  0.1629, -0.0637],
         [-0.0829, -0.3607,  0.3738, -0.2037],
         [-0.0663, -0.1319,  0.2854,  0.0008],
         [-0.0532,  0.0049,  0.0653,  0.2380],
         [-0.0461, -0.0717,  0.0039,  0.3077]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[-2.7122e-01,  2.5438e-01,  5.2819e-02,  5.3308e-01],
         [ 3.5111e-03,  1.4989e-02,  2.2648e-04,  4.1928e-02],
         [ 1.2531e-01, -4.0899e-02, -9.5597e-02,  1.0531e-01],
         [ 4.0226e-03,  5.7754e-03, -4.8666e-03,  6.2043e-02],
         [-4.4691e-02,  3.8255e-03,  6.4717e-02, -7.8676e-02],
         [-6.3314e-03, -2.4607e-02,  6.9994e-02, -1.6552e-01]]],
       grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 6, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-1.1898,  1.3493, -0.6925,  0.5331],
         [ 1.6386, -1.0748, -0.3009, -0.2628],
         [ 0.4576,  0.8616, -1.7032,  0.3839],
         [-0.2828, -0.9709, -0.4200,  1.6736],
         [ 0.1213, -1.6510,  0.9764,  0.5532],
         [-0.5067, -1.2452,  1.4496,  0.3023]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 6, 4])
```


output + residual: 

```python
tensor([[[-1.4610,  1.6037, -0.6397,  1.0661],
         [ 1.6421, -1.0598, -0.3007, -0.2209],
         [ 0.5830,  0.8207, -1.7988,  0.4892],
         [-0.2787, -0.9651, -0.4248,  1.7357],
         [ 0.0766, -1.6472,  1.0412,  0.4745],
         [-0.5130, -1.2698,  1.5196,  0.1367]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-1.2908,  1.1765, -0.6295,  0.7438],
         [ 1.6355, -1.0807, -0.3175, -0.2373],
         [ 0.5282,  0.7528, -1.7207,  0.4397],
         [-0.2883, -0.9581, -0.4309,  1.6773],
         [ 0.0900, -1.6279,  1.0513,  0.4866],
         [-0.4698, -1.2084,  1.5139,  0.1643]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 6, 4])
```


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-1.2908,  1.1765, -0.6295,  0.7438],
         [ 1.6355, -1.0807, -0.3175, -0.2373],
         [ 0.5282,  0.7528, -1.7207,  0.4397],
         [-0.2883, -0.9581, -0.4309,  1.6773],
         [ 0.0900, -1.6279,  1.0513,  0.4866],
         [-0.4698, -1.2084,  1.5139,  0.1643]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 6, 4])
```


input_K: 

```python
tensor([[[-1.3916, -0.3878,  0.4836,  1.2958],
         [ 1.6558, -0.0757, -0.7443, -0.8358],
         [ 1.4527, -0.3520, -1.3119,  0.2112],
         [-0.4968, -0.1511, -1.0028,  1.6507],
         [-0.4135, -1.4478,  0.9455,  0.9159]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[-1.3916, -0.3878,  0.4836,  1.2958],
         [ 1.6558, -0.0757, -0.7443, -0.8358],
         [ 1.4527, -0.3520, -1.3119,  0.2112],
         [-0.4968, -0.1511, -1.0028,  1.6507],
         [-0.4135, -1.4478,  0.9455,  0.9159]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 6, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[-0.0664,  0.4169],
          [-0.2466, -0.8226],
          [-0.2257, -0.6798],
          [-0.9752, -0.0172],
          [-0.4707,  0.2069],
          [-0.1630,  0.5864]],

         [[-0.0128,  0.2036],
          [-0.2171, -0.8265],
          [-0.3761, -0.9362],
          [-0.1491, -0.5100],
          [ 0.1360,  0.1385],
          [ 0.2959,  0.6570]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 6, 2])
```


K: 

```python
tensor([[[[-0.4401,  0.1672],
          [ 0.3087, -0.0250],
          [-0.0768,  0.2718],
          [-0.6426,  0.4779],
          [-0.1632,  0.0499]],

         [[-0.6094,  0.5661],
          [ 0.7843, -0.4988],
          [ 0.6038, -0.1474],
          [-0.4543,  0.6123],
          [ 0.2138,  0.1785]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[-0.5598,  0.0688],
          [ 0.5551, -0.2443],
          [-0.0449, -0.3338],
          [-1.1760, -0.0474],
          [ 0.5726, -0.3118]],

         [[ 0.6164,  0.1058],
          [-0.6423, -0.2825],
          [-0.5716, -0.4873],
          [ 0.1058, -0.2874],
          [ 0.5304, -0.0223]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 6, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[-0.0664,  0.4169],
          [-0.2466, -0.8226],
          [-0.2257, -0.6798],
          [-0.9752, -0.0172],
          [-0.4707,  0.2069],
          [-0.1630,  0.5864]],

         [[-0.0128,  0.2036],
          [-0.2171, -0.8265],
          [-0.3761, -0.9362],
          [-0.1491, -0.5100],
          [ 0.1360,  0.1385],
          [ 0.2959,  0.6570]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 6, 2])
```


K: 

```python
tensor([[[[-0.4401,  0.1672],
          [ 0.3087, -0.0250],
          [-0.0768,  0.2718],
          [-0.6426,  0.4779],
          [-0.1632,  0.0499]],

         [[-0.6094,  0.5661],
          [ 0.7843, -0.4988],
          [ 0.6038, -0.1474],
          [-0.4543,  0.6123],
          [ 0.2138,  0.1785]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[-0.5598,  0.0688],
          [ 0.5551, -0.2443],
          [-0.0449, -0.3338],
          [-1.1760, -0.0474],
          [ 0.5726, -0.3118]],

         [[ 0.6164,  0.1058],
          [-0.6423, -0.2825],
          [-0.5716, -0.4873],
          [ 0.1058, -0.2874],
          [ 0.5304, -0.0223]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 6, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[ 0.0700, -0.0218,  0.0837,  0.1711,  0.0224],
          [-0.0205, -0.0393, -0.1447, -0.1659, -0.0006],
          [-0.0102, -0.0373, -0.1184, -0.1272,  0.0021],
          [ 0.3014, -0.2126,  0.0497,  0.4373,  0.1120],
          [ 0.1709, -0.1064,  0.0653,  0.2838,  0.0616],
          [ 0.1201, -0.0459,  0.1216,  0.2722,  0.0395]],

         [[ 0.0870, -0.0789, -0.0267,  0.0923,  0.0238],
          [-0.2373,  0.1711, -0.0065, -0.2881, -0.1372],
          [-0.2127,  0.1217, -0.0630, -0.2845, -0.1750],
          [-0.1399,  0.0972, -0.0105, -0.1729, -0.0869],
          [-0.0032,  0.0266,  0.0436,  0.0163,  0.0380],
          [ 0.1354, -0.0676,  0.0579,  0.1894,  0.1277]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 6, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[ 6.9962e-02, -2.1847e-02,  8.3737e-02,  1.7106e-01, -1.0000e+09],
          [-2.0547e-02, -3.9312e-02, -1.4471e-01, -1.6594e-01, -1.0000e+09],
          [-1.0152e-02, -3.7281e-02, -1.1840e-01, -1.2717e-01, -1.0000e+09],
          [ 3.0142e-01, -2.1257e-01,  4.9654e-02,  4.3731e-01, -1.0000e+09],
          [ 1.7093e-01, -1.0640e-01,  6.5324e-02,  2.8380e-01, -1.0000e+09],
          [ 1.2007e-01, -4.5927e-02,  1.2156e-01,  2.7225e-01, -1.0000e+09]],

         [[ 8.7038e-02, -7.8937e-02, -2.6708e-02,  9.2287e-02, -1.0000e+09],
          [-2.3728e-01,  1.7112e-01, -6.5256e-03, -2.8810e-01, -1.0000e+09],
          [-2.1269e-01,  1.2166e-01, -6.2967e-02, -2.8454e-01, -1.0000e+09],
          [-1.3991e-01,  9.7212e-02, -1.0480e-02, -1.7293e-01, -1.0000e+09],
          [-3.1724e-03,  2.6575e-02,  4.3630e-02,  1.6271e-02, -1.0000e+09],
          [ 1.3545e-01, -6.7606e-02,  5.7865e-02,  1.8938e-01, -1.0000e+09]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 6, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[0.2480, 0.2262, 0.2514, 0.2744, 0.0000],
          [0.2681, 0.2632, 0.2368, 0.2319, 0.0000],
          [0.2659, 0.2588, 0.2387, 0.2366, 0.0000],
          [0.2840, 0.1699, 0.2208, 0.3253, 0.0000],
          [0.2648, 0.2006, 0.2382, 0.2964, 0.0000],
          [0.2492, 0.2111, 0.2496, 0.2902, 0.0000]],

         [[0.2670, 0.2262, 0.2383, 0.2684, 0.0000],
          [0.2121, 0.3191, 0.2672, 0.2016, 0.0000],
          [0.2228, 0.3112, 0.2587, 0.2073, 0.0000],
          [0.2287, 0.2898, 0.2603, 0.2212, 0.0000],
          [0.2440, 0.2514, 0.2557, 0.2488, 0.0000],
          [0.2634, 0.2150, 0.2437, 0.2780, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 6, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[-0.3472, -0.1351],
          [-0.2873, -0.1359],
          [-0.2941, -0.1358],
          [-0.4572, -0.1111],
          [-0.3961, -0.1244],
          [-0.3748, -0.1315]],

         [[-0.0885, -0.2290],
          [-0.2056, -0.2559],
          [-0.1885, -0.2500],
          [-0.1706, -0.2481],
          [-0.1309, -0.2414],
          [-0.0856, -0.2315]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 6, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[0.2480, 0.2262, 0.2514, 0.2744, 0.0000],
          [0.2681, 0.2632, 0.2368, 0.2319, 0.0000],
          [0.2659, 0.2588, 0.2387, 0.2366, 0.0000],
          [0.2840, 0.1699, 0.2208, 0.3253, 0.0000],
          [0.2648, 0.2006, 0.2382, 0.2964, 0.0000],
          [0.2492, 0.2111, 0.2496, 0.2902, 0.0000]],

         [[0.2670, 0.2262, 0.2383, 0.2684, 0.0000],
          [0.2121, 0.3191, 0.2672, 0.2016, 0.0000],
          [0.2228, 0.3112, 0.2587, 0.2073, 0.0000],
          [0.2287, 0.2898, 0.2603, 0.2212, 0.0000],
          [0.2440, 0.2514, 0.2557, 0.2488, 0.0000],
          [0.2634, 0.2150, 0.2437, 0.2780, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 6, 5])
```


context: 

```python
tensor([[[[-0.3472, -0.1351],
          [-0.2873, -0.1359],
          [-0.2941, -0.1358],
          [-0.4572, -0.1111],
          [-0.3961, -0.1244],
          [-0.3748, -0.1315]],

         [[-0.0885, -0.2290],
          [-0.2056, -0.2559],
          [-0.1885, -0.2500],
          [-0.1706, -0.2481],
          [-0.1309, -0.2414],
          [-0.0856, -0.2315]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 6, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[-0.3472, -0.1351, -0.0885, -0.2290],
         [-0.2873, -0.1359, -0.2056, -0.2559],
         [-0.2941, -0.1358, -0.1885, -0.2500],
         [-0.4572, -0.1111, -0.1706, -0.2481],
         [-0.3961, -0.1244, -0.1309, -0.2414],
         [-0.3748, -0.1315, -0.0856, -0.2315]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[ 0.2009, -0.0582, -0.0970, -0.1585],
         [ 0.2382, -0.0207, -0.1090, -0.1653],
         [ 0.2320, -0.0261, -0.1067, -0.1634],
         [ 0.2712, -0.0558, -0.1486, -0.1926],
         [ 0.2353, -0.0554, -0.1214, -0.1753],
         [ 0.2080, -0.0629, -0.1041, -0.1643]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 6, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-1.2908,  1.1765, -0.6295,  0.7438],
         [ 1.6355, -1.0807, -0.3175, -0.2373],
         [ 0.5282,  0.7528, -1.7207,  0.4397],
         [-0.2883, -0.9581, -0.4309,  1.6773],
         [ 0.0900, -1.6279,  1.0513,  0.4866],
         [-0.4698, -1.2084,  1.5139,  0.1643]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 6, 4])
```


output + residual: 

```python
tensor([[[-1.0899e+00,  1.1183e+00, -7.2652e-01,  5.8528e-01],
         [ 1.8738e+00, -1.1014e+00, -4.2652e-01, -4.0259e-01],
         [ 7.6020e-01,  7.2666e-01, -1.8274e+00,  2.7634e-01],
         [-1.7087e-02, -1.0139e+00, -5.7950e-01,  1.4847e+00],
         [ 3.2532e-01, -1.6833e+00,  9.2988e-01,  3.1124e-01],
         [-2.6178e-01, -1.2713e+00,  1.4098e+00, -1.7017e-05]]],
       grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-1.1679,  1.2612, -0.7682,  0.6748],
         [ 1.6774, -0.9659, -0.3663, -0.3451],
         [ 0.7302,  0.6986, -1.7038,  0.2750],
         [ 0.0152, -1.0407, -0.5806,  1.6061],
         [ 0.3592, -1.6757,  0.9716,  0.3449],
         [-0.2412, -1.2953,  1.5043,  0.0321]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 6, 4])
```


## PoswiseFeedForwardNet


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


inputs: 

```python
tensor([[[-1.1679,  1.2612, -0.7682,  0.6748],
         [ 1.6774, -0.9659, -0.3663, -0.3451],
         [ 0.7302,  0.6986, -1.7038,  0.2750],
         [ 0.0152, -1.0407, -0.5806,  1.6061],
         [ 0.3592, -1.6757,  0.9716,  0.3449],
         [-0.2412, -1.2953,  1.5043,  0.0321]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc操作的代码</div>


: 

```python
output = self.fc(inputs)
```


inputs: 

```python
tensor([[[-1.1679,  1.2612, -0.7682,  0.6748],
         [ 1.6774, -0.9659, -0.3663, -0.3451],
         [ 0.7302,  0.6986, -1.7038,  0.2750],
         [ 0.0152, -1.0407, -0.5806,  1.6061],
         [ 0.3592, -1.6757,  0.9716,  0.3449],
         [-0.2412, -1.2953,  1.5043,  0.0321]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc原来是d_model->d_ff->d_model</div>


self.fc: 

```python
Sequential(
  (0): Linear(in_features=4, out_features=8, bias=False)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=4, bias=False)
)
```


output: 

```python
tensor([[[-5.2674e-02, -2.0209e-01,  1.5430e-01,  1.1338e-01],
         [-2.0710e-01,  7.1546e-02, -2.3680e-01, -1.2020e-01],
         [-1.5924e-01,  5.4519e-02, -2.4045e-01, -7.8554e-02],
         [-1.2485e-01,  3.4338e-02, -2.4967e-01, -1.3544e-01],
         [-2.7639e-02,  1.2333e-01,  4.2472e-02, -2.3591e-01],
         [ 2.2656e-04,  1.6121e-01,  1.5983e-01, -3.6344e-01]]],
       grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 6, 4])
```


## 前馈层后的层归一化和残差


<div style='color:#fe618e;font-weight:800;font-size:23px;'>FeedForward后的层归一化和残差</div>


: 

```python
ans = nn.LayerNorm(d_model).to(device)(output + residual)
```


residual: 

```python
tensor([[[-1.1679,  1.2612, -0.7682,  0.6748],
         [ 1.6774, -0.9659, -0.3663, -0.3451],
         [ 0.7302,  0.6986, -1.7038,  0.2750],
         [ 0.0152, -1.0407, -0.5806,  1.6061],
         [ 0.3592, -1.6757,  0.9716,  0.3449],
         [-0.2412, -1.2953,  1.5043,  0.0321]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>残差和层归一化之后的结果</div>


ans: 

```python
tensor([[[-1.2883,  1.1115, -0.6496,  0.8264],
         [ 1.7080, -0.8267, -0.5145, -0.3668],
         [ 0.6266,  0.7953, -1.7019,  0.2800],
         [ 0.0095, -0.9081, -0.7279,  1.6265],
         [ 0.3774, -1.6201,  1.1012,  0.1415],
         [-0.2242, -1.0935,  1.6299, -0.3122]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans.shape: 

```python
torch.Size([1, 6, 4])
```


# Decoder结束


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


dec_outputs: 

```python
tensor([[[-1.2883,  1.1115, -0.6496,  0.8264],
         [ 1.7080, -0.8267, -0.5145, -0.3668],
         [ 0.6266,  0.7953, -1.7019,  0.2800],
         [ 0.0095, -0.9081, -0.7279,  1.6265],
         [ 0.3774, -1.6201,  1.1012,  0.1415],
         [-0.2242, -1.0935,  1.6299, -0.3122]]],
       grad_fn=<NativeLayerNormBackward0>)
```


dec_outputs.shape: 

```python
torch.Size([1, 6, 4])
```


dec_self_attns: 

```python
[tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5840, 0.4160, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3118, 0.3468, 0.3414, 0.0000, 0.0000, 0.0000],
          [0.2072, 0.2610, 0.2352, 0.2967, 0.0000, 0.0000],
          [0.2153, 0.1437, 0.1485, 0.2207, 0.2719, 0.0000],
          [0.2184, 0.2296, 0.2409, 0.1733, 0.1379, 0.0000]],

         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.4790, 0.5210, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.4003, 0.2899, 0.3098, 0.0000, 0.0000, 0.0000],
          [0.3078, 0.2170, 0.2044, 0.2708, 0.0000, 0.0000],
          [0.0581, 0.0798, 0.0505, 0.1646, 0.6470, 0.0000],
          [0.1905, 0.1965, 0.1919, 0.2031, 0.2179, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>), tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.6043, 0.3957, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.2841, 0.4361, 0.2798, 0.0000, 0.0000, 0.0000],
          [0.2498, 0.2447, 0.2839, 0.2216, 0.0000, 0.0000],
          [0.2872, 0.1719, 0.2256, 0.1510, 0.1642, 0.0000],
          [0.2760, 0.1797, 0.2884, 0.1363, 0.1195, 0.0000]],

         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5320, 0.4680, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3252, 0.2170, 0.4577, 0.0000, 0.0000, 0.0000],
          [0.2456, 0.2542, 0.3099, 0.1903, 0.0000, 0.0000],
          [0.1779, 0.2369, 0.1669, 0.1717, 0.2466, 0.0000],
          [0.1568, 0.2332, 0.1249, 0.1727, 0.3124, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)]
```


dec_enc_attns: 

```python
[tensor([[[[0.1869, 0.2596, 0.3079, 0.2456, 0.0000],
          [0.3661, 0.1711, 0.1860, 0.2767, 0.0000],
          [0.2675, 0.1945, 0.2549, 0.2831, 0.0000],
          [0.1936, 0.3115, 0.2758, 0.2191, 0.0000],
          [0.2633, 0.2863, 0.2231, 0.2274, 0.0000],
          [0.2140, 0.3346, 0.2441, 0.2072, 0.0000]],

         [[0.1223, 0.3842, 0.3246, 0.1690, 0.0000],
          [0.3194, 0.1945, 0.2092, 0.2769, 0.0000],
          [0.1482, 0.3524, 0.3102, 0.1892, 0.0000],
          [0.2193, 0.2736, 0.2648, 0.2423, 0.0000],
          [0.3768, 0.1520, 0.1737, 0.2975, 0.0000],
          [0.3608, 0.1625, 0.1827, 0.2939, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>), tensor([[[[0.2480, 0.2262, 0.2514, 0.2744, 0.0000],
          [0.2681, 0.2632, 0.2368, 0.2319, 0.0000],
          [0.2659, 0.2588, 0.2387, 0.2366, 0.0000],
          [0.2840, 0.1699, 0.2208, 0.3253, 0.0000],
          [0.2648, 0.2006, 0.2382, 0.2964, 0.0000],
          [0.2492, 0.2111, 0.2496, 0.2902, 0.0000]],

         [[0.2670, 0.2262, 0.2383, 0.2684, 0.0000],
          [0.2121, 0.3191, 0.2672, 0.2016, 0.0000],
          [0.2228, 0.3112, 0.2587, 0.2073, 0.0000],
          [0.2287, 0.2898, 0.2603, 0.2212, 0.0000],
          [0.2440, 0.2514, 0.2557, 0.2488, 0.0000],
          [0.2634, 0.2150, 0.2437, 0.2780, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)]
```


# 阶段三：projection


<div style='color:#fe618e;font-weight:800;font-size:23px;'>projection操作代码</div>


: 

```python
dec_logits = self.projection(dec_outputs)
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


dec_outputs: 

```python
tensor([[[-1.2883,  1.1115, -0.6496,  0.8264],
         [ 1.7080, -0.8267, -0.5145, -0.3668],
         [ 0.6266,  0.7953, -1.7019,  0.2800],
         [ 0.0095, -0.9081, -0.7279,  1.6265],
         [ 0.3774, -1.6201,  1.1012,  0.1415],
         [-0.2242, -1.0935,  1.6299, -0.3122]]],
       grad_fn=<NativeLayerNormBackward0>)
```


dec_outputs.shape: 

```python
torch.Size([1, 6, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


dec_logits: 

```python
tensor([[[-0.1376,  3.4207, -3.3140,  1.2787, -0.3145, -1.8308, -0.5180],
         [ 0.0221, -3.1320,  3.5768,  1.2575, -0.0972, -0.9148,  0.9262],
         [-0.2110,  0.7595,  0.9466,  4.2880, -0.6069, -4.4531, -0.6859],
         [ 0.0529, -0.4522, -2.1237, -0.2987, -0.2529, -0.3458,  4.2754],
         [ 0.2421, -2.7486,  0.3195, -3.6255,  0.4455,  3.7378,  2.8776],
         [ 0.2308, -1.6233, -0.1853, -4.2175,  0.6036,  4.4488,  1.1629]]],
       grad_fn=<UnsafeViewBackward0>)
```


dec_logits.shape: 

```python
torch.Size([1, 6, 7])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>dec_logits的view操作</div>


: 

```python
ans = dec_logits.view(-1, dec_logits.size(-1)), enc_self_attns, dec_self_attns, dec_enc_attns
```


ans: 

```python
(tensor([[-0.1376,  3.4207, -3.3140,  1.2787, -0.3145, -1.8308, -0.5180],
        [ 0.0221, -3.1320,  3.5768,  1.2575, -0.0972, -0.9148,  0.9262],
        [-0.2110,  0.7595,  0.9466,  4.2880, -0.6069, -4.4531, -0.6859],
        [ 0.0529, -0.4522, -2.1237, -0.2987, -0.2529, -0.3458,  4.2754],
        [ 0.2421, -2.7486,  0.3195, -3.6255,  0.4455,  3.7378,  2.8776],
        [ 0.2308, -1.6233, -0.1853, -4.2175,  0.6036,  4.4488,  1.1629]],
       grad_fn=<ViewBackward0>), [tensor([[[[0.2114, 0.3080, 0.2878, 0.1928, 0.0000],
          [0.3139, 0.2365, 0.2056, 0.2440, 0.0000],
          [0.2552, 0.3224, 0.2517, 0.1707, 0.0000],
          [0.1341, 0.3989, 0.3514, 0.1156, 0.0000],
          [0.1804, 0.2671, 0.3124, 0.2401, 0.0000]],

         [[0.2540, 0.2377, 0.2372, 0.2711, 0.0000],
          [0.2548, 0.2489, 0.2519, 0.2444, 0.0000],
          [0.2255, 0.2800, 0.2706, 0.2239, 0.0000],
          [0.2002, 0.3030, 0.2779, 0.2189, 0.0000],
          [0.2784, 0.1990, 0.2049, 0.3176, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>), tensor([[[[0.2609, 0.2507, 0.2462, 0.2421, 0.0000],
          [0.2347, 0.2454, 0.2545, 0.2654, 0.0000],
          [0.2487, 0.2427, 0.2490, 0.2596, 0.0000],
          [0.2776, 0.2463, 0.2396, 0.2365, 0.0000],
          [0.2305, 0.2453, 0.2560, 0.2682, 0.0000]],

         [[0.3012, 0.2491, 0.2084, 0.2413, 0.0000],
          [0.2149, 0.2446, 0.2848, 0.2556, 0.0000],
          [0.2519, 0.2321, 0.2559, 0.2600, 0.0000],
          [0.3068, 0.2253, 0.2136, 0.2542, 0.0000],
          [0.2856, 0.2620, 0.2151, 0.2373, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)], [tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5840, 0.4160, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3118, 0.3468, 0.3414, 0.0000, 0.0000, 0.0000],
          [0.2072, 0.2610, 0.2352, 0.2967, 0.0000, 0.0000],
          [0.2153, 0.1437, 0.1485, 0.2207, 0.2719, 0.0000],
          [0.2184, 0.2296, 0.2409, 0.1733, 0.1379, 0.0000]],

         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.4790, 0.5210, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.4003, 0.2899, 0.3098, 0.0000, 0.0000, 0.0000],
          [0.3078, 0.2170, 0.2044, 0.2708, 0.0000, 0.0000],
          [0.0581, 0.0798, 0.0505, 0.1646, 0.6470, 0.0000],
          [0.1905, 0.1965, 0.1919, 0.2031, 0.2179, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>), tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.6043, 0.3957, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.2841, 0.4361, 0.2798, 0.0000, 0.0000, 0.0000],
          [0.2498, 0.2447, 0.2839, 0.2216, 0.0000, 0.0000],
          [0.2872, 0.1719, 0.2256, 0.1510, 0.1642, 0.0000],
          [0.2760, 0.1797, 0.2884, 0.1363, 0.1195, 0.0000]],

         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5320, 0.4680, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3252, 0.2170, 0.4577, 0.0000, 0.0000, 0.0000],
          [0.2456, 0.2542, 0.3099, 0.1903, 0.0000, 0.0000],
          [0.1779, 0.2369, 0.1669, 0.1717, 0.2466, 0.0000],
          [0.1568, 0.2332, 0.1249, 0.1727, 0.3124, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)], [tensor([[[[0.1869, 0.2596, 0.3079, 0.2456, 0.0000],
          [0.3661, 0.1711, 0.1860, 0.2767, 0.0000],
          [0.2675, 0.1945, 0.2549, 0.2831, 0.0000],
          [0.1936, 0.3115, 0.2758, 0.2191, 0.0000],
          [0.2633, 0.2863, 0.2231, 0.2274, 0.0000],
          [0.2140, 0.3346, 0.2441, 0.2072, 0.0000]],

         [[0.1223, 0.3842, 0.3246, 0.1690, 0.0000],
          [0.3194, 0.1945, 0.2092, 0.2769, 0.0000],
          [0.1482, 0.3524, 0.3102, 0.1892, 0.0000],
          [0.2193, 0.2736, 0.2648, 0.2423, 0.0000],
          [0.3768, 0.1520, 0.1737, 0.2975, 0.0000],
          [0.3608, 0.1625, 0.1827, 0.2939, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>), tensor([[[[0.2480, 0.2262, 0.2514, 0.2744, 0.0000],
          [0.2681, 0.2632, 0.2368, 0.2319, 0.0000],
          [0.2659, 0.2588, 0.2387, 0.2366, 0.0000],
          [0.2840, 0.1699, 0.2208, 0.3253, 0.0000],
          [0.2648, 0.2006, 0.2382, 0.2964, 0.0000],
          [0.2492, 0.2111, 0.2496, 0.2902, 0.0000]],

         [[0.2670, 0.2262, 0.2383, 0.2684, 0.0000],
          [0.2121, 0.3191, 0.2672, 0.2016, 0.0000],
          [0.2228, 0.3112, 0.2587, 0.2073, 0.0000],
          [0.2287, 0.2898, 0.2603, 0.2212, 0.0000],
          [0.2440, 0.2514, 0.2557, 0.2488, 0.0000],
          [0.2634, 0.2150, 0.2437, 0.2780, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)])
```


# 计算损失


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>预测值</div>


outputs: 

```python
tensor([[-0.1376,  3.4207, -3.3140,  1.2787, -0.3145, -1.8308, -0.5180],
        [ 0.0221, -3.1320,  3.5768,  1.2575, -0.0972, -0.9148,  0.9262],
        [-0.2110,  0.7595,  0.9466,  4.2880, -0.6069, -4.4531, -0.6859],
        [ 0.0529, -0.4522, -2.1237, -0.2987, -0.2529, -0.3458,  4.2754],
        [ 0.2421, -2.7486,  0.3195, -3.6255,  0.4455,  3.7378,  2.8776],
        [ 0.2308, -1.6233, -0.1853, -4.2175,  0.6036,  4.4488,  1.1629]],
       grad_fn=<ViewBackward0>)
```


outputs.shape: 

```python
torch.Size([6, 7])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>真实值</div>


dec_outputs: 

```python
tensor([[1, 2, 3, 6, 5, 0]])
```


dec_outputs.shape: 

```python
torch.Size([1, 6])
```


dec_outputs.view(-1): 

```python
tensor([1, 2, 3, 6, 5, 0])
```


dec_outputs.view(-1).shape: 

```python
torch.Size([6])
```


<div style='color:#19ce8b;font-weight:800;font-size:23px;'>损失</div>


loss: 

```python
tensor(0.1907, grad_fn=<NllLossBackward0>)
```

Epoch: 0200 loss = 0.190710

# ----------------------


# ----------------------


# 预测阶段


# 预测第【1】句话：


# greedy_decoder开始


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


: 

```python
greedy_decoder(model, enc_input, start_symbol)
```


enc_input: 

```python
tensor([[1, 2, 3, 4, 0]])
```


enc_input.shape: 

```python
torch.Size([1, 5])
```


start_symbol: 

```python
4
```


# 【经过encoder生成注意力的语义编码C】


# Encoder中


<div style='color:#3296ee;font-weight:800;font-size:23px;'>enc_inputs转换为词向量的结果</div>


: 

```python
enc_outputs = self.src_emb(enc_inputs)
```


enc_outputs: 

```python
tensor([[[-0.9266, -1.7498, -0.0633, -0.8935],
         [ 0.4778, -1.6670, -0.2534, -1.5649],
         [ 0.3815, -0.1522, -1.3199,  0.1646],
         [-1.0256, -0.0971, -1.7463,  0.2517],
         [ 0.7371, -0.8480,  1.6767,  0.6005]]], grad_fn=<EmbeddingBackward0>)
```


enc_outputs.shape: 

```python
torch.Size([1, 5, 4])
```


## PositionalEncoding


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入加上位置编码的代码</div>


加上位置编码: 

```python
x = x + self.pe[:x.size(0), :]
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


x: 

```python
tensor([[[-0.9266, -1.7498, -0.0633, -0.8935]],

        [[ 0.4778, -1.6670, -0.2534, -1.5649]],

        [[ 0.3815, -0.1522, -1.3199,  0.1646]],

        [[-1.0256, -0.0971, -1.7463,  0.2517]],

        [[ 0.7371, -0.8480,  1.6767,  0.6005]]], grad_fn=<TransposeBackward0>)
```


x.shape: 

```python
torch.Size([5, 1, 4])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>位置编码</div>


self.pe[:x.size(0), :]: 

```python
tensor([[[ 0.0000,  1.0000,  0.0000,  1.0000]],

        [[ 0.8415,  0.5403,  0.0100,  0.9999]],

        [[ 0.9093, -0.4161,  0.0200,  0.9998]],

        [[ 0.1411, -0.9900,  0.0300,  0.9996]],

        [[-0.7568, -0.6536,  0.0400,  0.9992]]])
```


self.pe[:x.size(0), :].shape: 

```python
torch.Size([5, 1, 4])
```


self.pe.shape: 

```python
torch.Size([5000, 1, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


x: 

```python
tensor([[[-0.9266, -0.7498, -0.0633,  0.1065]],

        [[ 1.3193, -1.1267, -0.2434, -0.5649]],

        [[ 1.2908, -0.5683, -1.2999,  1.1644]],

        [[-0.8845, -1.0870, -1.7163,  1.2513]],

        [[-0.0197, -1.5016,  1.7167,  1.5997]]], grad_fn=<AddBackward0>)
```


x.shape: 

```python
torch.Size([5, 1, 4])
```


## get_attn_pad_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq_q: 

```python
tensor([[1, 2, 3, 4, 0]])
```


seq_q.shape: 

```python
torch.Size([1, 5])
```


seq_k: 

```python
tensor([[1, 2, 3, 4, 0]])
```


seq_k.shape: 

```python
torch.Size([1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>获取对应的大小：len_q,len_k</div>


例如: 

```python
batch_size, len_q = seq_q.size()
```


batch_size: 

```python
1
```


len_q: 

```python
5
```


len_k: 

```python
5
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>操作pad_attn_mask矩阵：pad_attn_mask</div>


: 

```python
pad_attn_mask = seq_k.data.eq(0).unsqueeze(1) 
```


pad_attn_mask: 

```python
tensor([[[False, False, False, False,  True]]])
```


pad_attn_mask.shape: 

```python
torch.Size([1, 1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>扩展pad_attn_mask矩阵：pad_attn_mask.expand</div>


: 

```python
ans = pad_attn_mask.expand(batch_size, len_q, len_k)  
```


ans: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


ans.shape: 

```python
torch.Size([1, 5, 5])
```


# EncoderLayer


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-0.0000, -0.8331, -0.0704,  0.1183],
         [ 1.4658, -1.2519, -0.2705, -0.0000],
         [ 1.4342, -0.6314, -1.4444,  1.2938],
         [-0.9828, -1.2078, -1.9070,  1.3903],
         [-0.0219, -1.6685,  1.9075,  1.7774]]], grad_fn=<TransposeBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_K: 

```python
tensor([[[-0.0000, -0.8331, -0.0704,  0.1183],
         [ 1.4658, -1.2519, -0.2705, -0.0000],
         [ 1.4342, -0.6314, -1.4444,  1.2938],
         [-0.9828, -1.2078, -1.9070,  1.3903],
         [-0.0219, -1.6685,  1.9075,  1.7774]]], grad_fn=<TransposeBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[-0.0000, -0.8331, -0.0704,  0.1183],
         [ 1.4658, -1.2519, -0.2705, -0.0000],
         [ 1.4342, -0.6314, -1.4444,  1.2938],
         [-0.9828, -1.2078, -1.9070,  1.3903],
         [-0.0219, -1.6685,  1.9075,  1.7774]]], grad_fn=<TransposeBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 5, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 0.4179,  0.1041],
          [ 0.4492,  0.4786],
          [ 0.7737, -0.0666],
          [ 1.5626, -0.3462],
          [ 0.3272, -0.6270]],

         [[-0.3161,  0.3425],
          [-0.3009,  0.1957],
          [ 0.5982,  0.8611],
          [ 0.3116,  1.7053],
          [-1.1859,  0.7374]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 5, 2])
```


K: 

```python
tensor([[[[ 0.0196, -0.1224],
          [ 0.5721, -0.5702],
          [ 0.3341, -1.1676],
          [-0.7052, -0.6368],
          [ 0.5308, -0.4228]],

         [[ 0.0871, -0.3765],
          [ 0.5326, -0.6899],
          [ 0.4342, -0.3608],
          [-0.3342, -0.1285],
          [ 0.7675, -1.7886]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.3643, -0.2193],
          [-0.0271,  0.3385],
          [-0.2780,  0.7198],
          [ 0.5049, -0.5697],
          [ 2.2649, -0.2289]],

         [[-0.0091, -0.1184],
          [ 0.6066,  0.0349],
          [ 0.9034, -0.1092],
          [-0.1966, -0.5264],
          [ 0.3456, -0.3830]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 0.4179,  0.1041],
          [ 0.4492,  0.4786],
          [ 0.7737, -0.0666],
          [ 1.5626, -0.3462],
          [ 0.3272, -0.6270]],

         [[-0.3161,  0.3425],
          [-0.3009,  0.1957],
          [ 0.5982,  0.8611],
          [ 0.3116,  1.7053],
          [-1.1859,  0.7374]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 5, 2])
```


K: 

```python
tensor([[[[ 0.0196, -0.1224],
          [ 0.5721, -0.5702],
          [ 0.3341, -1.1676],
          [-0.7052, -0.6368],
          [ 0.5308, -0.4228]],

         [[ 0.0871, -0.3765],
          [ 0.5326, -0.6899],
          [ 0.4342, -0.3608],
          [-0.3342, -0.1285],
          [ 0.7675, -1.7886]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.3643, -0.2193],
          [-0.0271,  0.3385],
          [-0.2780,  0.7198],
          [ 0.5049, -0.5697],
          [ 2.2649, -0.2289]],

         [[-0.0091, -0.1184],
          [ 0.6066,  0.0349],
          [ 0.9034, -0.1092],
          [-0.1966, -0.5264],
          [ 0.3456, -0.3830]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[-0.0032,  0.1271,  0.0128, -0.2553,  0.1257],
          [-0.0352, -0.0113, -0.2890, -0.4395,  0.0255],
          [ 0.0165,  0.3398,  0.2378, -0.3558,  0.3103],
          [ 0.0517,  0.7717,  0.6549, -0.6233,  0.6900],
          [ 0.0588,  0.3851,  0.5949,  0.1192,  0.3103]],

         [[-0.1107, -0.2861, -0.1844,  0.0436, -0.6048],
          [-0.0706, -0.2088, -0.1423,  0.0533, -0.4109],
          [-0.1924, -0.1948, -0.0360, -0.2196, -0.7644],
          [-0.4348, -0.7146, -0.3394, -0.2286, -1.9876],
          [-0.2693, -0.8063, -0.5522,  0.2132, -1.5762]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[-3.2042e-03,  1.2708e-01,  1.2774e-02, -2.5528e-01, -1.0000e+09],
          [-3.5176e-02, -1.1254e-02, -2.8901e-01, -4.3951e-01, -1.0000e+09],
          [ 1.6510e-02,  3.3981e-01,  2.3776e-01, -3.5580e-01, -1.0000e+09],
          [ 5.1660e-02,  7.7165e-01,  6.5494e-01, -6.2332e-01, -1.0000e+09],
          [ 5.8799e-02,  3.8514e-01,  5.9493e-01,  1.1915e-01, -1.0000e+09]],

         [[-1.1065e-01, -2.8614e-01, -1.8444e-01,  4.3566e-02, -1.0000e+09],
          [-7.0642e-02, -2.0883e-01, -1.4234e-01,  5.3330e-02, -1.0000e+09],
          [-1.9239e-01, -1.9480e-01, -3.6048e-02, -2.1963e-01, -1.0000e+09],
          [-4.3477e-01, -7.1458e-01, -3.3944e-01, -2.2861e-01, -1.0000e+09],
          [-2.6933e-01, -8.0632e-01, -5.5222e-01,  2.1324e-01, -1.0000e+09]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[0.2543, 0.2897, 0.2584, 0.1976, 0.0000],
          [0.2884, 0.2954, 0.2237, 0.1925, 0.0000],
          [0.2316, 0.3199, 0.2889, 0.1596, 0.0000],
          [0.1855, 0.3810, 0.3391, 0.0944, 0.0000],
          [0.1939, 0.2687, 0.3314, 0.2060, 0.0000]],

         [[0.2542, 0.2132, 0.2361, 0.2965, 0.0000],
          [0.2542, 0.2214, 0.2366, 0.2878, 0.0000],
          [0.2415, 0.2410, 0.2824, 0.2351, 0.0000],
          [0.2448, 0.1851, 0.2693, 0.3009, 0.0000],
          [0.2526, 0.1477, 0.1904, 0.4093, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.1127,  0.1157],
          [ 0.1320,  0.0881],
          [ 0.0759,  0.1746],
          [ 0.0107,  0.2785],
          [ 0.0752,  0.1697]],

         [[ 0.2820, -0.2045],
          [ 0.2892, -0.1997],
          [ 0.3529, -0.1747],
          [ 0.2942, -0.2103],
          [ 0.1788, -0.2610]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[0.2543, 0.2897, 0.2584, 0.1976, 0.0000],
          [0.2884, 0.2954, 0.2237, 0.1925, 0.0000],
          [0.2316, 0.3199, 0.2889, 0.1596, 0.0000],
          [0.1855, 0.3810, 0.3391, 0.0944, 0.0000],
          [0.1939, 0.2687, 0.3314, 0.2060, 0.0000]],

         [[0.2542, 0.2132, 0.2361, 0.2965, 0.0000],
          [0.2542, 0.2214, 0.2366, 0.2878, 0.0000],
          [0.2415, 0.2410, 0.2824, 0.2351, 0.0000],
          [0.2448, 0.1851, 0.2693, 0.3009, 0.0000],
          [0.2526, 0.1477, 0.1904, 0.4093, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 5, 5])
```


context: 

```python
tensor([[[[ 0.1127,  0.1157],
          [ 0.1320,  0.0881],
          [ 0.0759,  0.1746],
          [ 0.0107,  0.2785],
          [ 0.0752,  0.1697]],

         [[ 0.2820, -0.2045],
          [ 0.2892, -0.1997],
          [ 0.3529, -0.1747],
          [ 0.2942, -0.2103],
          [ 0.1788, -0.2610]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.1127,  0.1157,  0.2820, -0.2045],
         [ 0.1320,  0.0881,  0.2892, -0.1997],
         [ 0.0759,  0.1746,  0.3529, -0.1747],
         [ 0.0107,  0.2785,  0.2942, -0.2103],
         [ 0.0752,  0.1697,  0.1788, -0.2610]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[-0.0875, -0.1761, -0.0335, -0.1510],
         [-0.0808, -0.1827, -0.0231, -0.1591],
         [-0.1260, -0.1770, -0.0367, -0.1742],
         [-0.1388, -0.1510, -0.0826, -0.1309],
         [-0.0741, -0.1512, -0.0744, -0.0940]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 5, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-0.0000, -0.8331, -0.0704,  0.1183],
         [ 1.4658, -1.2519, -0.2705, -0.0000],
         [ 1.4342, -0.6314, -1.4444,  1.2938],
         [-0.9828, -1.2078, -1.9070,  1.3903],
         [-0.0219, -1.6685,  1.9075,  1.7774]]], grad_fn=<TransposeBackward0>)
```


residual.shape: 

```python
torch.Size([1, 5, 4])
```


output + residual: 

```python
tensor([[[-0.0875, -1.0092, -0.1039, -0.0326],
         [ 1.3850, -1.4345, -0.2935, -0.1591],
         [ 1.3082, -0.8084, -1.4810,  1.1196],
         [-1.1216, -1.3588, -1.9896,  1.2594],
         [-0.0959, -1.8197,  1.8331,  1.6834]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[ 0.5445, -1.7283,  0.5041,  0.6797],
         [ 1.5059, -1.3050, -0.1675, -0.0335],
         [ 1.0570, -0.6996, -1.2579,  0.9005],
         [-0.2589, -0.4514, -0.9634,  1.6737],
         [-0.3331, -1.4904,  0.9620,  0.8615]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 5, 4])
```


## PoswiseFeedForwardNet


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


inputs: 

```python
tensor([[[ 0.5445, -1.7283,  0.5041,  0.6797],
         [ 1.5059, -1.3050, -0.1675, -0.0335],
         [ 1.0570, -0.6996, -1.2579,  0.9005],
         [-0.2589, -0.4514, -0.9634,  1.6737],
         [-0.3331, -1.4904,  0.9620,  0.8615]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc操作的代码</div>


: 

```python
output = self.fc(inputs)
```


inputs: 

```python
tensor([[[ 0.5445, -1.7283,  0.5041,  0.6797],
         [ 1.5059, -1.3050, -0.1675, -0.0335],
         [ 1.0570, -0.6996, -1.2579,  0.9005],
         [-0.2589, -0.4514, -0.9634,  1.6737],
         [-0.3331, -1.4904,  0.9620,  0.8615]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc原来是d_model->d_ff->d_model</div>


self.fc: 

```python
Sequential(
  (0): Linear(in_features=4, out_features=8, bias=False)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=4, bias=False)
)
```


output: 

```python
tensor([[[ 0.0087,  0.0362,  0.1060,  0.0437],
         [ 0.1864,  0.2368,  0.0537,  0.2576],
         [ 0.2807,  0.2313,  0.1243,  0.4474],
         [ 0.0087,  0.1988,  0.0761,  0.1637],
         [-0.0061,  0.0173,  0.0734,  0.0269]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 5, 4])
```


## 前馈层后的层归一化和残差


<div style='color:#fe618e;font-weight:800;font-size:23px;'>FeedForward后的层归一化和残差</div>


: 

```python
ans = nn.LayerNorm(d_model).to(device)(output + residual)
```


residual: 

```python
tensor([[[ 0.5445, -1.7283,  0.5041,  0.6797],
         [ 1.5059, -1.3050, -0.1675, -0.0335],
         [ 1.0570, -0.6996, -1.2579,  0.9005],
         [-0.2589, -0.4514, -0.9634,  1.6737],
         [-0.3331, -1.4904,  0.9620,  0.8615]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>残差和层归一化之后的结果</div>


ans: 

```python
tensor([[[ 0.5011, -1.7288,  0.5576,  0.6702],
         [ 1.5214, -1.2624, -0.2999,  0.0408],
         [ 0.9721, -0.6737, -1.2798,  0.9814],
         [-0.3516, -0.3540, -0.9705,  1.6761],
         [-0.3607, -1.4748,  0.9899,  0.8455]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans.shape: 

```python
torch.Size([1, 5, 4])
```


# EncoderLayer


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[ 0.5011, -1.7288,  0.5576,  0.6702],
         [ 1.5214, -1.2624, -0.2999,  0.0408],
         [ 0.9721, -0.6737, -1.2798,  0.9814],
         [-0.3516, -0.3540, -0.9705,  1.6761],
         [-0.3607, -1.4748,  0.9899,  0.8455]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_K: 

```python
tensor([[[ 0.5011, -1.7288,  0.5576,  0.6702],
         [ 1.5214, -1.2624, -0.2999,  0.0408],
         [ 0.9721, -0.6737, -1.2798,  0.9814],
         [-0.3516, -0.3540, -0.9705,  1.6761],
         [-0.3607, -1.4748,  0.9899,  0.8455]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[ 0.5011, -1.7288,  0.5576,  0.6702],
         [ 1.5214, -1.2624, -0.2999,  0.0408],
         [ 0.9721, -0.6737, -1.2798,  0.9814],
         [-0.3516, -0.3540, -0.9705,  1.6761],
         [-0.3607, -1.4748,  0.9899,  0.8455]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 5, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 0.5632,  0.3090],
          [ 0.5728,  0.3039],
          [ 0.1436,  0.0095],
          [-0.1943, -0.1857],
          [ 0.3761,  0.2153]],

         [[ 0.4758, -0.2011],
          [-0.0361,  0.0709],
          [-0.1320, -0.2395],
          [ 0.1688, -0.5368],
          [ 0.6694, -0.3104]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 5, 2])
```


K: 

```python
tensor([[[[-0.4045, -0.9023],
          [-0.4337, -0.1976],
          [ 0.0524,  0.1674],
          [ 0.3756, -0.0875],
          [-0.2602, -1.0908]],

         [[-0.8084,  0.0466],
          [-0.6296,  0.4016],
          [-0.6362,  0.4339],
          [-0.5432,  0.0900],
          [-0.6535, -0.2162]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[-0.4265, -0.3238],
          [ 0.5391,  0.3777],
          [ 0.1844,  0.8150],
          [-0.7167,  0.3967],
          [-0.9370, -0.7117]],

         [[ 0.3618,  0.4261],
          [ 0.6611,  1.1510],
          [ 1.1853,  1.3019],
          [ 0.9548,  0.5187],
          [ 0.0135, -0.2274]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 0.5632,  0.3090],
          [ 0.5728,  0.3039],
          [ 0.1436,  0.0095],
          [-0.1943, -0.1857],
          [ 0.3761,  0.2153]],

         [[ 0.4758, -0.2011],
          [-0.0361,  0.0709],
          [-0.1320, -0.2395],
          [ 0.1688, -0.5368],
          [ 0.6694, -0.3104]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 5, 2])
```


K: 

```python
tensor([[[[-0.4045, -0.9023],
          [-0.4337, -0.1976],
          [ 0.0524,  0.1674],
          [ 0.3756, -0.0875],
          [-0.2602, -1.0908]],

         [[-0.8084,  0.0466],
          [-0.6296,  0.4016],
          [-0.6362,  0.4339],
          [-0.5432,  0.0900],
          [-0.6535, -0.2162]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[-0.4265, -0.3238],
          [ 0.5391,  0.3777],
          [ 0.1844,  0.8150],
          [-0.7167,  0.3967],
          [-0.9370, -0.7117]],

         [[ 0.3618,  0.4261],
          [ 0.6611,  1.1510],
          [ 1.1853,  1.3019],
          [ 0.9548,  0.5187],
          [ 0.0135, -0.2274]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[-0.3582, -0.2159,  0.0574,  0.1305, -0.3420],
          [-0.3577, -0.2181,  0.0572,  0.1333, -0.3398],
          [-0.0471, -0.0454,  0.0064,  0.0375, -0.0337],
          [ 0.1740,  0.0855, -0.0292, -0.0401,  0.1789],
          [-0.2449, -0.1454,  0.0394,  0.0866, -0.2353]],

         [[-0.2786, -0.2689, -0.2758, -0.1955, -0.1891],
          [ 0.0230,  0.0362,  0.0380,  0.0184,  0.0059],
          [ 0.0676, -0.0092, -0.0141,  0.0355,  0.0976],
          [-0.1142, -0.2276, -0.2407, -0.0990,  0.0041],
          [-0.3929, -0.3861, -0.3964, -0.2768, -0.2619]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[-3.5823e-01, -2.1591e-01,  5.7427e-02,  1.3049e-01, -1.0000e+09],
          [-3.5774e-01, -2.1815e-01,  5.7184e-02,  1.3335e-01, -1.0000e+09],
          [-4.7095e-02, -4.5351e-02,  6.4353e-03,  3.7548e-02, -1.0000e+09],
          [ 1.7401e-01,  8.5518e-02, -2.9168e-02, -4.0110e-02, -1.0000e+09],
          [-2.4493e-01, -1.4542e-01,  3.9409e-02,  8.6568e-02, -1.0000e+09]],

         [[-2.7861e-01, -2.6893e-01, -2.7576e-01, -1.9554e-01, -1.0000e+09],
          [ 2.3000e-02,  3.6226e-02,  3.8018e-02,  1.8395e-02, -1.0000e+09],
          [ 6.7563e-02, -9.2392e-03, -1.4097e-02,  3.5464e-02, -1.0000e+09],
          [-1.1419e-01, -2.2759e-01, -2.4067e-01, -9.8994e-02, -1.0000e+09],
          [-3.9286e-01, -3.8614e-01, -3.9639e-01, -2.7685e-01, -1.0000e+09]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[0.1887, 0.2176, 0.2860, 0.3077, 0.0000],
          [0.1887, 0.2170, 0.2858, 0.3084, 0.0000],
          [0.2413, 0.2417, 0.2545, 0.2626, 0.0000],
          [0.2826, 0.2587, 0.2306, 0.2281, 0.0000],
          [0.2072, 0.2289, 0.2753, 0.2886, 0.0000]],

         [[0.2440, 0.2463, 0.2446, 0.2651, 0.0000],
          [0.2485, 0.2518, 0.2523, 0.2474, 0.0000],
          [0.2620, 0.2427, 0.2415, 0.2538, 0.0000],
          [0.2639, 0.2356, 0.2325, 0.2679, 0.0000],
          [0.2424, 0.2440, 0.2415, 0.2722, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[-0.1309,  0.3762],
          [-0.1318,  0.3761],
          [-0.1138,  0.3248],
          [-0.1020,  0.2847],
          [-0.1210,  0.3582]],

         [[ 0.7942,  0.8435],
          [ 0.7916,  0.8525],
          [ 0.7838,  0.8370],
          [ 0.7827,  0.8254],
          [ 0.7951,  0.8397]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[0.1887, 0.2176, 0.2860, 0.3077, 0.0000],
          [0.1887, 0.2170, 0.2858, 0.3084, 0.0000],
          [0.2413, 0.2417, 0.2545, 0.2626, 0.0000],
          [0.2826, 0.2587, 0.2306, 0.2281, 0.0000],
          [0.2072, 0.2289, 0.2753, 0.2886, 0.0000]],

         [[0.2440, 0.2463, 0.2446, 0.2651, 0.0000],
          [0.2485, 0.2518, 0.2523, 0.2474, 0.0000],
          [0.2620, 0.2427, 0.2415, 0.2538, 0.0000],
          [0.2639, 0.2356, 0.2325, 0.2679, 0.0000],
          [0.2424, 0.2440, 0.2415, 0.2722, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 5, 5])
```


context: 

```python
tensor([[[[-0.1309,  0.3762],
          [-0.1318,  0.3761],
          [-0.1138,  0.3248],
          [-0.1020,  0.2847],
          [-0.1210,  0.3582]],

         [[ 0.7942,  0.8435],
          [ 0.7916,  0.8525],
          [ 0.7838,  0.8370],
          [ 0.7827,  0.8254],
          [ 0.7951,  0.8397]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[-0.1309,  0.3762,  0.7942,  0.8435],
         [-0.1318,  0.3761,  0.7916,  0.8525],
         [-0.1138,  0.3248,  0.7838,  0.8370],
         [-0.1020,  0.2847,  0.7827,  0.8254],
         [-0.1210,  0.3582,  0.7951,  0.8397]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[-0.0447, -0.3100, -0.2870, -0.5220],
         [-0.0469, -0.3122, -0.2894, -0.5240],
         [-0.0456, -0.3212, -0.2858, -0.5066],
         [-0.0440, -0.3292, -0.2838, -0.4938],
         [-0.0439, -0.3145, -0.2860, -0.5181]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 5, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[ 0.5011, -1.7288,  0.5576,  0.6702],
         [ 1.5214, -1.2624, -0.2999,  0.0408],
         [ 0.9721, -0.6737, -1.2798,  0.9814],
         [-0.3516, -0.3540, -0.9705,  1.6761],
         [-0.3607, -1.4748,  0.9899,  0.8455]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 5, 4])
```


output + residual: 

```python
tensor([[[ 0.4564, -2.0388,  0.2706,  0.1481],
         [ 1.4745, -1.5746, -0.5893, -0.4832],
         [ 0.9265, -0.9948, -1.5656,  0.4747],
         [-0.3957, -0.6832, -1.2542,  1.1823],
         [-0.4045, -1.7893,  0.7040,  0.3274]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[ 0.7362, -1.7219,  0.5532,  0.4325],
         [ 1.5986, -1.1589, -0.2678, -0.1719],
         [ 1.1886, -0.6890, -1.2467,  0.7471],
         [-0.1196, -0.4379, -1.0701,  1.6275],
         [-0.1196, -1.5732,  1.0440,  0.6487]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 5, 4])
```


## PoswiseFeedForwardNet


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


inputs: 

```python
tensor([[[ 0.7362, -1.7219,  0.5532,  0.4325],
         [ 1.5986, -1.1589, -0.2678, -0.1719],
         [ 1.1886, -0.6890, -1.2467,  0.7471],
         [-0.1196, -0.4379, -1.0701,  1.6275],
         [-0.1196, -1.5732,  1.0440,  0.6487]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc操作的代码</div>


: 

```python
output = self.fc(inputs)
```


inputs: 

```python
tensor([[[ 0.7362, -1.7219,  0.5532,  0.4325],
         [ 1.5986, -1.1589, -0.2678, -0.1719],
         [ 1.1886, -0.6890, -1.2467,  0.7471],
         [-0.1196, -0.4379, -1.0701,  1.6275],
         [-0.1196, -1.5732,  1.0440,  0.6487]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc原来是d_model->d_ff->d_model</div>


self.fc: 

```python
Sequential(
  (0): Linear(in_features=4, out_features=8, bias=False)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=4, bias=False)
)
```


output: 

```python
tensor([[[-0.1722, -0.1816, -0.0954, -0.1040],
         [-0.0374, -0.1834, -0.1491, -0.1484],
         [-0.0221, -0.0769, -0.0967,  0.1006],
         [-0.1139,  0.0378,  0.0173,  0.3523],
         [-0.1714, -0.0436, -0.1228,  0.0891]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 5, 4])
```


## 前馈层后的层归一化和残差


<div style='color:#fe618e;font-weight:800;font-size:23px;'>FeedForward后的层归一化和残差</div>


: 

```python
ans = nn.LayerNorm(d_model).to(device)(output + residual)
```


residual: 

```python
tensor([[[ 0.7362, -1.7219,  0.5532,  0.4325],
         [ 1.5986, -1.1589, -0.2678, -0.1719],
         [ 1.1886, -0.6890, -1.2467,  0.7471],
         [-0.1196, -0.4379, -1.0701,  1.6275],
         [-0.1196, -1.5732,  1.0440,  0.6487]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>残差和层归一化之后的结果</div>


ans: 

```python
tensor([[[ 0.6868, -1.7263,  0.5829,  0.4565],
         [ 1.6033, -1.1500, -0.2725, -0.1809],
         [ 1.1261, -0.7021, -1.2486,  0.8246],
         [-0.2686, -0.4144, -0.9857,  1.6687],
         [-0.2267, -1.5400,  0.9742,  0.7925]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans.shape: 

```python
torch.Size([1, 5, 4])
```


# Encoder结束


# 【依次生成每个单词，借助语义编码C和之前生成好的单词】


# 预测这句话第【1】个单词：


<div style='color:#fe618e;font-weight:800;font-size:23px;'>生成dec_input</div>


: 

```python
dec_input = torch.cat([dec_input.to(device), torch.tensor([[next_symbol]], dtype=enc_input.dtype).to(device)],-1)
```


dec_input: 

```python
tensor([[4]])
```


dec_input.shape: 

```python
torch.Size([1, 1])
```


# Decoder中


<div style='color:#3296ee;font-weight:800;font-size:23px;'>dec_inputs转换为词向量的结果</div>


: 

```python
dec_outputs = self.tgt_emb(dec_inputs)
```


dec_outputs: 

```python
tensor([[[-1.0398,  1.3073, -0.2711, -0.4491]]], grad_fn=<EmbeddingBackward0>)
```


dec_outputs.shape: 

```python
torch.Size([1, 1, 4])
```


## PositionalEncoding


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入加上位置编码的代码</div>


加上位置编码: 

```python
x = x + self.pe[:x.size(0), :]
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


x: 

```python
tensor([[[-1.0398,  1.3073, -0.2711, -0.4491]]], grad_fn=<TransposeBackward0>)
```


x.shape: 

```python
torch.Size([1, 1, 4])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>位置编码</div>


self.pe[:x.size(0), :]: 

```python
tensor([[[0., 1., 0., 1.]]])
```


self.pe[:x.size(0), :].shape: 

```python
torch.Size([1, 1, 4])
```


self.pe.shape: 

```python
torch.Size([5000, 1, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


x: 

```python
tensor([[[-1.0398,  2.3073, -0.2711,  0.5509]]], grad_fn=<AddBackward0>)
```


x.shape: 

```python
torch.Size([1, 1, 4])
```


## decoder的self_attn的pad_mask


## get_attn_pad_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq_q: 

```python
tensor([[4]])
```


seq_q.shape: 

```python
torch.Size([1, 1])
```


seq_k: 

```python
tensor([[4]])
```


seq_k.shape: 

```python
torch.Size([1, 1])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>获取对应的大小：len_q,len_k</div>


例如: 

```python
batch_size, len_q = seq_q.size()
```


batch_size: 

```python
1
```


len_q: 

```python
1
```


len_k: 

```python
1
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>操作pad_attn_mask矩阵：pad_attn_mask</div>


: 

```python
pad_attn_mask = seq_k.data.eq(0).unsqueeze(1) 
```


pad_attn_mask: 

```python
tensor([[[False]]])
```


pad_attn_mask.shape: 

```python
torch.Size([1, 1, 1])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>扩展pad_attn_mask矩阵：pad_attn_mask.expand</div>


: 

```python
ans = pad_attn_mask.expand(batch_size, len_q, len_k)  
```


ans: 

```python
tensor([[[False]]])
```


ans.shape: 

```python
torch.Size([1, 1, 1])
```


## get_attn_subsequence_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq: 

```python
tensor([[4]])
```


seq.shape: 

```python
torch.Size([1, 1])
```


<div style='color:#19ce8b;font-weight:800;font-size:23px;'>求attn_shape</div>


: 

```python
attn_shape = [seq.size(0), seq.size(1), seq.size(1)]
```


attn_shape: 

```python
[1, 1, 1]
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>生成一个上三角矩阵</div>


: 

```python
subsequence_mask = np.triu(np.ones(attn_shape), k=1)
```


subsequence_mask: 

```python
[[[0.]]]
```


subsequence_mask.shape: 

```python
(1, 1, 1)
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>生成subsequence_mask</div>


: 

```python
subsequence_mask = torch.from_numpy(subsequence_mask).byte()
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


subsequence_mask: 

```python
tensor([[[0]]], dtype=torch.uint8)
```


subsequence_mask.shape: 

```python
torch.Size([1, 1, 1])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>两个mask相加</div>


: 

```python
dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequence_mask),0).to(device)
```


dec_self_attn_pad_mask: 

```python
tensor([[[False]]])
```


dec_self_attn_pad_mask.shape: 

```python
torch.Size([1, 1, 1])
```


dec_self_attn_subsequence_mask: 

```python
tensor([[[0]]], dtype=torch.uint8)
```


dec_self_attn_subsequence_mask.shape: 

```python
torch.Size([1, 1, 1])
```


dec_self_attn_mask: 

```python
tensor([[[False]]])
```


dec_self_attn_mask.shape: 

```python
torch.Size([1, 1, 1])
```


## 交互注意力层中的pad_mask


## get_attn_pad_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq_q: 

```python
tensor([[4]])
```


seq_q.shape: 

```python
torch.Size([1, 1])
```


seq_k: 

```python
tensor([[4]])
```


seq_k.shape: 

```python
torch.Size([1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>获取对应的大小：len_q,len_k</div>


例如: 

```python
batch_size, len_q = seq_q.size()
```


batch_size: 

```python
1
```


len_q: 

```python
1
```


len_k: 

```python
5
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>操作pad_attn_mask矩阵：pad_attn_mask</div>


: 

```python
pad_attn_mask = seq_k.data.eq(0).unsqueeze(1) 
```


pad_attn_mask: 

```python
tensor([[[False, False, False, False,  True]]])
```


pad_attn_mask.shape: 

```python
torch.Size([1, 1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>扩展pad_attn_mask矩阵：pad_attn_mask.expand</div>


: 

```python
ans = pad_attn_mask.expand(batch_size, len_q, len_k)  
```


ans: 

```python
tensor([[[False, False, False, False,  True]]])
```


ans.shape: 

```python
torch.Size([1, 1, 5])
```


# DecoderLayer


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-1.1553,  2.5637, -0.3013,  0.6121]]], grad_fn=<TransposeBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 1, 4])
```


input_K: 

```python
tensor([[[-1.1553,  2.5637, -0.3013,  0.6121]]], grad_fn=<TransposeBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 1, 4])
```


input_V: 

```python
tensor([[[-1.1553,  2.5637, -0.3013,  0.6121]]], grad_fn=<TransposeBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 1, 4])
```


attn_mask: 

```python
tensor([[[False]]])
```


attn_mask.shape: 

```python
torch.Size([1, 1, 1])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 0.9375, -0.0820]],

         [[-1.2241, -1.3372]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 1, 2])
```


K: 

```python
tensor([[[[-0.5534, -0.8596]],

         [[-1.2777, -0.0468]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 1, 2])
```


V: 

```python
tensor([[[[ 0.6492,  1.1050]],

         [[-0.3369,  0.7558]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 1, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False]],

         [[False]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 1, 1])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 0.9375, -0.0820]],

         [[-1.2241, -1.3372]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 1, 2])
```


K: 

```python
tensor([[[[-0.5534, -0.8596]],

         [[-1.2777, -0.0468]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 1, 2])
```


V: 

```python
tensor([[[[ 0.6492,  1.1050]],

         [[-0.3369,  0.7558]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 1, 2])
```


attn_mask: 

```python
tensor([[[[False]],

         [[False]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 1, 1])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[-0.3170]],

         [[ 1.1502]]]], grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 1, 1])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[-0.3170]],

         [[ 1.1502]]]], grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 1, 1])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[1.]],

         [[1.]]]], grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 1, 1])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.6492,  1.1050]],

         [[-0.3369,  0.7558]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 1, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[1.]],

         [[1.]]]], grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 1, 1])
```


context: 

```python
tensor([[[[ 0.6492,  1.1050]],

         [[-0.3369,  0.7558]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 1, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.6492,  1.1050, -0.3369,  0.7558]]],
       grad_fn=<ReshapeAliasBackward0>)
```


context.shape: 

```python
torch.Size([1, 1, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[ 0.6525,  0.1585, -0.2623,  0.4406]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 1, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-1.1553,  2.5637, -0.3013,  0.6121]]], grad_fn=<TransposeBackward0>)
```


residual.shape: 

```python
torch.Size([1, 1, 4])
```


output + residual: 

```python
tensor([[[-0.5027,  2.7222, -0.5635,  1.0527]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 1, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-0.8761,  1.5185, -0.9212,  0.2788]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 1, 4])
```


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-0.8761,  1.5185, -0.9212,  0.2788]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 1, 4])
```


input_K: 

```python
tensor([[[ 0.6868, -1.7263,  0.5829,  0.4565],
         [ 1.6033, -1.1500, -0.2725, -0.1809],
         [ 1.1261, -0.7021, -1.2486,  0.8246],
         [-0.2686, -0.4144, -0.9857,  1.6687],
         [-0.2267, -1.5400,  0.9742,  0.7925]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[ 0.6868, -1.7263,  0.5829,  0.4565],
         [ 1.6033, -1.1500, -0.2725, -0.1809],
         [ 1.1261, -0.7021, -1.2486,  0.8246],
         [-0.2686, -0.4144, -0.9857,  1.6687],
         [-0.2267, -1.5400,  0.9742,  0.7925]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 1, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 1.0464,  0.3356]],

         [[-0.7483,  0.2133]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 1, 2])
```


K: 

```python
tensor([[[[ 0.2876,  0.7402],
          [ 0.4966,  0.3560],
          [ 0.5376,  0.3952],
          [ 0.2229,  0.4991],
          [ 0.0389,  0.7666]],

         [[ 0.4759,  0.6528],
          [-0.5556, -0.0237],
          [-0.3791, -0.1074],
          [ 0.5440,  0.2833],
          [ 1.0660,  0.9173]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.9145,  0.2993],
          [ 0.9688, -0.2155],
          [-0.1428, -0.3849],
          [-0.9931, -0.0470],
          [ 0.5290,  0.5650]],

         [[ 0.1975,  0.7515],
          [ 0.3600,  0.7951],
          [-0.1420,  0.8862],
          [-0.5786,  0.5694],
          [-0.0029,  0.4654]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True]],

         [[False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 1, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 1.0464,  0.3356]],

         [[-0.7483,  0.2133]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 1, 2])
```


K: 

```python
tensor([[[[ 0.2876,  0.7402],
          [ 0.4966,  0.3560],
          [ 0.5376,  0.3952],
          [ 0.2229,  0.4991],
          [ 0.0389,  0.7666]],

         [[ 0.4759,  0.6528],
          [-0.5556, -0.0237],
          [-0.3791, -0.1074],
          [ 0.5440,  0.2833],
          [ 1.0660,  0.9173]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.9145,  0.2993],
          [ 0.9688, -0.2155],
          [-0.1428, -0.3849],
          [-0.9931, -0.0470],
          [ 0.5290,  0.5650]],

         [[ 0.1975,  0.7515],
          [ 0.3600,  0.7951],
          [-0.1420,  0.8862],
          [-0.5786,  0.5694],
          [-0.0029,  0.4654]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True]],

         [[False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[ 0.3884,  0.4519,  0.4916,  0.2833,  0.2107]],

         [[-0.1534,  0.2904,  0.1844, -0.2451, -0.4257]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 1, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[ 3.8840e-01,  4.5193e-01,  4.9157e-01,  2.8334e-01, -1.0000e+09]],

         [[-1.5338e-01,  2.9043e-01,  1.8441e-01, -2.4515e-01, -1.0000e+09]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 1, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[0.2454, 0.2615, 0.2721, 0.2210, 0.0000]],

         [[0.2052, 0.3199, 0.2877, 0.1872, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 1, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.2195, -0.0980]],

         [[ 0.0065,  0.7701]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 1, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[0.2454, 0.2615, 0.2721, 0.2210, 0.0000]],

         [[0.2052, 0.3199, 0.2877, 0.1872, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 1, 5])
```


context: 

```python
tensor([[[[ 0.2195, -0.0980]],

         [[ 0.0065,  0.7701]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 1, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.2195, -0.0980,  0.0065,  0.7701]]],
       grad_fn=<ReshapeAliasBackward0>)
```


context.shape: 

```python
torch.Size([1, 1, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[-0.3036, -0.2255,  0.3885, -0.2493]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 1, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-0.8761,  1.5185, -0.9212,  0.2788]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 1, 4])
```


output + residual: 

```python
tensor([[[-1.1798,  1.2931, -0.5327,  0.0296]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 1, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-1.1897,  1.5285, -0.4784,  0.1396]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 1, 4])
```


## PoswiseFeedForwardNet


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


inputs: 

```python
tensor([[[-1.1897,  1.5285, -0.4784,  0.1396]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 1, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc操作的代码</div>


: 

```python
output = self.fc(inputs)
```


inputs: 

```python
tensor([[[-1.1897,  1.5285, -0.4784,  0.1396]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 1, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc原来是d_model->d_ff->d_model</div>


self.fc: 

```python
Sequential(
  (0): Linear(in_features=4, out_features=8, bias=False)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=4, bias=False)
)
```


output: 

```python
tensor([[[ 0.0237, -0.1882, -0.1871,  0.2141]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 1, 4])
```


## 前馈层后的层归一化和残差


<div style='color:#fe618e;font-weight:800;font-size:23px;'>FeedForward后的层归一化和残差</div>


: 

```python
ans = nn.LayerNorm(d_model).to(device)(output + residual)
```


residual: 

```python
tensor([[[-1.1897,  1.5285, -0.4784,  0.1396]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 1, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>残差和层归一化之后的结果</div>


ans: 

```python
tensor([[[-1.1735,  1.4256, -0.6546,  0.4025]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans.shape: 

```python
torch.Size([1, 1, 4])
```


# DecoderLayer


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-1.1735,  1.4256, -0.6546,  0.4025]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 1, 4])
```


input_K: 

```python
tensor([[[-1.1735,  1.4256, -0.6546,  0.4025]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 1, 4])
```


input_V: 

```python
tensor([[[-1.1735,  1.4256, -0.6546,  0.4025]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 1, 4])
```


attn_mask: 

```python
tensor([[[False]]])
```


attn_mask.shape: 

```python
torch.Size([1, 1, 1])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 0.0535,  1.1167]],

         [[ 0.3753, -0.0296]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 1, 2])
```


K: 

```python
tensor([[[[ 0.4299, -0.1691]],

         [[ 0.2378, -0.6551]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 1, 2])
```


V: 

```python
tensor([[[[ 0.3322,  0.2007]],

         [[ 0.6469, -0.6036]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 1, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False]],

         [[False]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 1, 1])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 0.0535,  1.1167]],

         [[ 0.3753, -0.0296]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 1, 2])
```


K: 

```python
tensor([[[[ 0.4299, -0.1691]],

         [[ 0.2378, -0.6551]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 1, 2])
```


V: 

```python
tensor([[[[ 0.3322,  0.2007]],

         [[ 0.6469, -0.6036]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 1, 2])
```


attn_mask: 

```python
tensor([[[[False]],

         [[False]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 1, 1])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[-0.1173]],

         [[ 0.0768]]]], grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 1, 1])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[-0.1173]],

         [[ 0.0768]]]], grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 1, 1])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[1.]],

         [[1.]]]], grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 1, 1])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.3322,  0.2007]],

         [[ 0.6469, -0.6036]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 1, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[1.]],

         [[1.]]]], grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 1, 1])
```


context: 

```python
tensor([[[[ 0.3322,  0.2007]],

         [[ 0.6469, -0.6036]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 1, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.3322,  0.2007,  0.6469, -0.6036]]],
       grad_fn=<ReshapeAliasBackward0>)
```


context.shape: 

```python
torch.Size([1, 1, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[-0.2467,  0.2440,  0.0396,  0.5255]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 1, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-1.1735,  1.4256, -0.6546,  0.4025]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 1, 4])
```


output + residual: 

```python
tensor([[[-1.4202,  1.6696, -0.6150,  0.9280]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 1, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-1.2781,  1.2521, -0.6187,  0.6448]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 1, 4])
```


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-1.2781,  1.2521, -0.6187,  0.6448]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 1, 4])
```


input_K: 

```python
tensor([[[ 0.6868, -1.7263,  0.5829,  0.4565],
         [ 1.6033, -1.1500, -0.2725, -0.1809],
         [ 1.1261, -0.7021, -1.2486,  0.8246],
         [-0.2686, -0.4144, -0.9857,  1.6687],
         [-0.2267, -1.5400,  0.9742,  0.7925]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[ 0.6868, -1.7263,  0.5829,  0.4565],
         [ 1.6033, -1.1500, -0.2725, -0.1809],
         [ 1.1261, -0.7021, -1.2486,  0.8246],
         [-0.2686, -0.4144, -0.9857,  1.6687],
         [-0.2267, -1.5400,  0.9742,  0.7925]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 1, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[-0.0060,  0.4164]],

         [[-0.0061,  0.2313]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 1, 2])
```


K: 

```python
tensor([[[[ 0.0340,  0.0352],
          [ 0.1903,  0.0466],
          [-0.2709,  0.3840],
          [-0.6189,  0.4860],
          [-0.1048,  0.0250]],

         [[ 0.8016, -0.1494],
          [ 1.0380, -0.4053],
          [ 0.4957,  0.0590],
          [-0.2779,  0.5567],
          [ 0.3398,  0.1011]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 1.0637, -0.5323],
          [ 0.9685, -0.5174],
          [-0.2034, -0.3953],
          [-0.9852, -0.1468],
          [ 0.7337, -0.3573]],

         [[ 0.1639, -0.2189],
          [-0.3600, -0.3702],
          [-0.3778, -0.5270],
          [ 0.0821, -0.3430],
          [ 0.4870, -0.0390]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True]],

         [[False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 1, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[-0.0060,  0.4164]],

         [[-0.0061,  0.2313]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 1, 2])
```


K: 

```python
tensor([[[[ 0.0340,  0.0352],
          [ 0.1903,  0.0466],
          [-0.2709,  0.3840],
          [-0.6189,  0.4860],
          [-0.1048,  0.0250]],

         [[ 0.8016, -0.1494],
          [ 1.0380, -0.4053],
          [ 0.4957,  0.0590],
          [-0.2779,  0.5567],
          [ 0.3398,  0.1011]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 1.0637, -0.5323],
          [ 0.9685, -0.5174],
          [-0.2034, -0.3953],
          [-0.9852, -0.1468],
          [ 0.7337, -0.3573]],

         [[ 0.1639, -0.2189],
          [-0.3600, -0.3702],
          [-0.3778, -0.5270],
          [ 0.0821, -0.3430],
          [ 0.4870, -0.0390]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True]],

         [[False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[ 0.0102,  0.0129,  0.1142,  0.1457,  0.0078]],

         [[-0.0279, -0.0708,  0.0075,  0.0922,  0.0151]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 1, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[ 1.0219e-02,  1.2908e-02,  1.1419e-01,  1.4570e-01, -1.0000e+09]],

         [[-2.7881e-02, -7.0761e-02,  7.5098e-03,  9.2248e-02, -1.0000e+09]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 1, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[0.2349, 0.2355, 0.2606, 0.2690, 0.0000]],

         [[0.2426, 0.2324, 0.2514, 0.2736, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 1, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.1600, -0.3894]],

         [[-0.1164, -0.3655]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 1, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[0.2349, 0.2355, 0.2606, 0.2690, 0.0000]],

         [[0.2426, 0.2324, 0.2514, 0.2736, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 1, 5])
```


context: 

```python
tensor([[[[ 0.1600, -0.3894]],

         [[-0.1164, -0.3655]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 1, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.1600, -0.3894, -0.1164, -0.3655]]],
       grad_fn=<ReshapeAliasBackward0>)
```


context.shape: 

```python
torch.Size([1, 1, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[ 0.1121, -0.0036,  0.0622, -0.1185]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 1, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-1.2781,  1.2521, -0.6187,  0.6448]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 1, 4])
```


output + residual: 

```python
tensor([[[-1.1660,  1.2485, -0.5565,  0.5263]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 1, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-1.2597,  1.3199, -0.6085,  0.5483]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 1, 4])
```


## PoswiseFeedForwardNet


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


inputs: 

```python
tensor([[[-1.2597,  1.3199, -0.6085,  0.5483]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 1, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc操作的代码</div>


: 

```python
output = self.fc(inputs)
```


inputs: 

```python
tensor([[[-1.2597,  1.3199, -0.6085,  0.5483]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 1, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc原来是d_model->d_ff->d_model</div>


self.fc: 

```python
Sequential(
  (0): Linear(in_features=4, out_features=8, bias=False)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=4, bias=False)
)
```


output: 

```python
tensor([[[-0.0407, -0.1932,  0.2528,  0.1463]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 1, 4])
```


## 前馈层后的层归一化和残差


<div style='color:#fe618e;font-weight:800;font-size:23px;'>FeedForward后的层归一化和残差</div>


: 

```python
ans = nn.LayerNorm(d_model).to(device)(output + residual)
```


residual: 

```python
tensor([[[-1.2597,  1.3199, -0.6085,  0.5483]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 1, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>残差和层归一化之后的结果</div>


ans: 

```python
tensor([[[-1.4216,  1.1501, -0.4207,  0.6922]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans.shape: 

```python
torch.Size([1, 1, 4])
```


# Decoder结束


<div style='color:#fe618e;font-weight:800;font-size:23px;'>model的decode操作</div>


: 

```python
dec_outputs, _, _ = model.decoder(dec_input, enc_input, enc_outputs)
```


dec_outputs: 

```python
tensor([[[-1.4216,  1.1501, -0.4207,  0.6922]]],
       grad_fn=<NativeLayerNormBackward0>)
```


dec_outputs.shape: 

```python
torch.Size([1, 1, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>model的projection操作</div>


: 

```python
projected = model.projection(dec_outputs)
```


projected: 

```python
tensor([[[-0.1239,  3.5437, -3.4073,  0.8738, -0.2378, -1.3745, -0.8337]]],
       grad_fn=<UnsafeViewBackward0>)
```


projected.shape: 

```python
torch.Size([1, 1, 7])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>生成prob</div>


: 

```python
prob = projected.squeeze(0).max(dim=-1, keepdim=False)[1]
```


prob: 

```python
tensor([1])
```


prob.shape: 

```python
torch.Size([1])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>生成next_word</div>


: 

```python
next_word = prob.data[-1]
```


next_word: 

```python
tensor(1)
```


next_word.shape: 

```python
torch.Size([])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>迭代下一轮</div>


: 

```python
next_symbol = next_word
```


next_symbol: 

```python
tensor(1)
```


# 预测这句话第【2】个单词：


<div style='color:#fe618e;font-weight:800;font-size:23px;'>生成dec_input</div>


: 

```python
dec_input = torch.cat([dec_input.to(device), torch.tensor([[next_symbol]], dtype=enc_input.dtype).to(device)],-1)
```


dec_input: 

```python
tensor([[4, 1]])
```


dec_input.shape: 

```python
torch.Size([1, 2])
```


# Decoder中


<div style='color:#3296ee;font-weight:800;font-size:23px;'>dec_inputs转换为词向量的结果</div>


: 

```python
dec_outputs = self.tgt_emb(dec_inputs)
```


dec_outputs: 

```python
tensor([[[-1.0398,  1.3073, -0.2711, -0.4491],
         [ 1.2834, -0.4243,  0.4540, -1.6032]]], grad_fn=<EmbeddingBackward0>)
```


dec_outputs.shape: 

```python
torch.Size([1, 2, 4])
```


## PositionalEncoding


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入加上位置编码的代码</div>


加上位置编码: 

```python
x = x + self.pe[:x.size(0), :]
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


x: 

```python
tensor([[[-1.0398,  1.3073, -0.2711, -0.4491]],

        [[ 1.2834, -0.4243,  0.4540, -1.6032]]], grad_fn=<TransposeBackward0>)
```


x.shape: 

```python
torch.Size([2, 1, 4])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>位置编码</div>


self.pe[:x.size(0), :]: 

```python
tensor([[[0.0000, 1.0000, 0.0000, 1.0000]],

        [[0.8415, 0.5403, 0.0100, 0.9999]]])
```


self.pe[:x.size(0), :].shape: 

```python
torch.Size([2, 1, 4])
```


self.pe.shape: 

```python
torch.Size([5000, 1, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


x: 

```python
tensor([[[-1.0398,  2.3073, -0.2711,  0.5509]],

        [[ 2.1248,  0.1160,  0.4640, -0.6032]]], grad_fn=<AddBackward0>)
```


x.shape: 

```python
torch.Size([2, 1, 4])
```


## decoder的self_attn的pad_mask


## get_attn_pad_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq_q: 

```python
tensor([[4, 1]])
```


seq_q.shape: 

```python
torch.Size([1, 2])
```


seq_k: 

```python
tensor([[4, 1]])
```


seq_k.shape: 

```python
torch.Size([1, 2])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>获取对应的大小：len_q,len_k</div>


例如: 

```python
batch_size, len_q = seq_q.size()
```


batch_size: 

```python
1
```


len_q: 

```python
2
```


len_k: 

```python
2
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>操作pad_attn_mask矩阵：pad_attn_mask</div>


: 

```python
pad_attn_mask = seq_k.data.eq(0).unsqueeze(1) 
```


pad_attn_mask: 

```python
tensor([[[False, False]]])
```


pad_attn_mask.shape: 

```python
torch.Size([1, 1, 2])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>扩展pad_attn_mask矩阵：pad_attn_mask.expand</div>


: 

```python
ans = pad_attn_mask.expand(batch_size, len_q, len_k)  
```


ans: 

```python
tensor([[[False, False],
         [False, False]]])
```


ans.shape: 

```python
torch.Size([1, 2, 2])
```


## get_attn_subsequence_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq: 

```python
tensor([[4, 1]])
```


seq.shape: 

```python
torch.Size([1, 2])
```


<div style='color:#19ce8b;font-weight:800;font-size:23px;'>求attn_shape</div>


: 

```python
attn_shape = [seq.size(0), seq.size(1), seq.size(1)]
```


attn_shape: 

```python
[1, 2, 2]
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>生成一个上三角矩阵</div>


: 

```python
subsequence_mask = np.triu(np.ones(attn_shape), k=1)
```


subsequence_mask: 

```python
[[[0. 1.]
  [0. 0.]]]
```


subsequence_mask.shape: 

```python
(1, 2, 2)
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>生成subsequence_mask</div>


: 

```python
subsequence_mask = torch.from_numpy(subsequence_mask).byte()
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


subsequence_mask: 

```python
tensor([[[0, 1],
         [0, 0]]], dtype=torch.uint8)
```


subsequence_mask.shape: 

```python
torch.Size([1, 2, 2])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>两个mask相加</div>


: 

```python
dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequence_mask),0).to(device)
```


dec_self_attn_pad_mask: 

```python
tensor([[[False, False],
         [False, False]]])
```


dec_self_attn_pad_mask.shape: 

```python
torch.Size([1, 2, 2])
```


dec_self_attn_subsequence_mask: 

```python
tensor([[[0, 1],
         [0, 0]]], dtype=torch.uint8)
```


dec_self_attn_subsequence_mask.shape: 

```python
torch.Size([1, 2, 2])
```


dec_self_attn_mask: 

```python
tensor([[[False,  True],
         [False, False]]])
```


dec_self_attn_mask.shape: 

```python
torch.Size([1, 2, 2])
```


## 交互注意力层中的pad_mask


## get_attn_pad_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq_q: 

```python
tensor([[4, 1]])
```


seq_q.shape: 

```python
torch.Size([1, 2])
```


seq_k: 

```python
tensor([[4, 1]])
```


seq_k.shape: 

```python
torch.Size([1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>获取对应的大小：len_q,len_k</div>


例如: 

```python
batch_size, len_q = seq_q.size()
```


batch_size: 

```python
1
```


len_q: 

```python
2
```


len_k: 

```python
5
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>操作pad_attn_mask矩阵：pad_attn_mask</div>


: 

```python
pad_attn_mask = seq_k.data.eq(0).unsqueeze(1) 
```


pad_attn_mask: 

```python
tensor([[[False, False, False, False,  True]]])
```


pad_attn_mask.shape: 

```python
torch.Size([1, 1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>扩展pad_attn_mask矩阵：pad_attn_mask.expand</div>


: 

```python
ans = pad_attn_mask.expand(batch_size, len_q, len_k)  
```


ans: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


ans.shape: 

```python
torch.Size([1, 2, 5])
```


# DecoderLayer


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-0.0000,  2.5637, -0.3013,  0.6121],
         [ 2.3609,  0.1289,  0.5155, -0.6703]]], grad_fn=<TransposeBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 2, 4])
```


input_K: 

```python
tensor([[[-0.0000,  2.5637, -0.3013,  0.6121],
         [ 2.3609,  0.1289,  0.5155, -0.6703]]], grad_fn=<TransposeBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 2, 4])
```


input_V: 

```python
tensor([[[-0.0000,  2.5637, -0.3013,  0.6121],
         [ 2.3609,  0.1289,  0.5155, -0.6703]]], grad_fn=<TransposeBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 2, 4])
```


attn_mask: 

```python
tensor([[[False,  True],
         [False, False]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 0.8690, -0.2589],
          [-0.2406, -0.5678]],

         [[-1.0022, -0.8012],
          [ 0.6229,  0.6148]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 2, 2])
```


K: 

```python
tensor([[[[-0.1247, -0.7554],
          [ 0.6511, -0.1221]],

         [[-1.1388, -0.3664],
          [ 0.1760, -0.4867]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 2, 2])
```


V: 

```python
tensor([[[[ 0.8710,  0.6383],
          [ 0.8156, -0.9357]],

         [[-0.8069,  0.8370],
          [-0.8736, -0.3561]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 2, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False,  True],
          [False, False]],

         [[False,  True],
          [False, False]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 2, 2])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 0.8690, -0.2589],
          [-0.2406, -0.5678]],

         [[-1.0022, -0.8012],
          [ 0.6229,  0.6148]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 2, 2])
```


K: 

```python
tensor([[[[-0.1247, -0.7554],
          [ 0.6511, -0.1221]],

         [[-1.1388, -0.3664],
          [ 0.1760, -0.4867]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 2, 2])
```


V: 

```python
tensor([[[[ 0.8710,  0.6383],
          [ 0.8156, -0.9357]],

         [[-0.8069,  0.8370],
          [-0.8736, -0.3561]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 2, 2])
```


attn_mask: 

```python
tensor([[[[False,  True],
          [False, False]],

         [[False,  True],
          [False, False]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 2, 2])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[ 0.0617,  0.4224],
          [ 0.3245, -0.0618]],

         [[ 1.0146,  0.1510],
          [-0.6609, -0.1341]]]], grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 2, 2])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[ 6.1684e-02, -1.0000e+09],
          [ 3.2450e-01, -6.1765e-02]],

         [[ 1.0146e+00, -1.0000e+09],
          [-6.6091e-01, -1.3408e-01]]]], grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 2, 2])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[1.0000, 0.0000],
          [0.5954, 0.4046]],

         [[1.0000, 0.0000],
          [0.3713, 0.6287]]]], grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 2, 2])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.8710,  0.6383],
          [ 0.8486,  0.0014]],

         [[-0.8069,  0.8370],
          [-0.8489,  0.0868]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 2, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[1.0000, 0.0000],
          [0.5954, 0.4046]],

         [[1.0000, 0.0000],
          [0.3713, 0.6287]]]], grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 2, 2])
```


context: 

```python
tensor([[[[ 0.8710,  0.6383],
          [ 0.8486,  0.0014]],

         [[-0.8069,  0.8370],
          [-0.8489,  0.0868]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 2, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.8710,  0.6383, -0.8069,  0.8370],
         [ 0.8486,  0.0014, -0.8489,  0.0868]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[ 0.6138,  0.2324, -0.1685,  0.9687],
         [ 0.4355,  0.0865,  0.0875,  0.8211]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 2, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-0.0000,  2.5637, -0.3013,  0.6121],
         [ 2.3609,  0.1289,  0.5155, -0.6703]]], grad_fn=<TransposeBackward0>)
```


residual.shape: 

```python
torch.Size([1, 2, 4])
```


output + residual: 

```python
tensor([[[ 0.6138,  2.7960, -0.4698,  1.5808],
         [ 2.7964,  0.2153,  0.6031,  0.1509]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 2, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-0.4287,  1.3828, -1.3282,  0.3740],
         [ 1.7099, -0.6693, -0.3119, -0.7287]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 2, 4])
```


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-0.4287,  1.3828, -1.3282,  0.3740],
         [ 1.7099, -0.6693, -0.3119, -0.7287]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 2, 4])
```


input_K: 

```python
tensor([[[ 0.6868, -1.7263,  0.5829,  0.4565],
         [ 1.6033, -1.1500, -0.2725, -0.1809],
         [ 1.1261, -0.7021, -1.2486,  0.8246],
         [-0.2686, -0.4144, -0.9857,  1.6687],
         [-0.2267, -1.5400,  0.9742,  0.7925]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[ 0.6868, -1.7263,  0.5829,  0.4565],
         [ 1.6033, -1.1500, -0.2725, -0.1809],
         [ 1.1261, -0.7021, -1.2486,  0.8246],
         [-0.2686, -0.4144, -0.9857,  1.6687],
         [-0.2267, -1.5400,  0.9742,  0.7925]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 0.9212,  0.5570],
          [-1.0056,  0.8384]],

         [[-0.7378,  0.1759],
          [ 0.3028,  0.0299]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 2, 2])
```


K: 

```python
tensor([[[[ 0.2876,  0.7402],
          [ 0.4966,  0.3560],
          [ 0.5376,  0.3952],
          [ 0.2229,  0.4991],
          [ 0.0389,  0.7666]],

         [[ 0.4759,  0.6528],
          [-0.5556, -0.0237],
          [-0.3791, -0.1074],
          [ 0.5440,  0.2833],
          [ 1.0660,  0.9173]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.9145,  0.2993],
          [ 0.9688, -0.2155],
          [-0.1428, -0.3849],
          [-0.9931, -0.0470],
          [ 0.5290,  0.5650]],

         [[ 0.1975,  0.7515],
          [ 0.3600,  0.7951],
          [-0.1420,  0.8862],
          [-0.5786,  0.5694],
          [-0.0029,  0.4654]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 2, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 0.9212,  0.5570],
          [-1.0056,  0.8384]],

         [[-0.7378,  0.1759],
          [ 0.3028,  0.0299]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 2, 2])
```


K: 

```python
tensor([[[[ 0.2876,  0.7402],
          [ 0.4966,  0.3560],
          [ 0.5376,  0.3952],
          [ 0.2229,  0.4991],
          [ 0.0389,  0.7666]],

         [[ 0.4759,  0.6528],
          [-0.5556, -0.0237],
          [-0.3791, -0.1074],
          [ 0.5440,  0.2833],
          [ 1.0660,  0.9173]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.9145,  0.2993],
          [ 0.9688, -0.2155],
          [-0.1428, -0.3849],
          [-0.9931, -0.0470],
          [ 0.5290,  0.5650]],

         [[ 0.1975,  0.7515],
          [ 0.3600,  0.7951],
          [-0.1420,  0.8862],
          [-0.5786,  0.5694],
          [-0.0029,  0.4654]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 2, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[ 0.4789,  0.4637,  0.5059,  0.3418,  0.3273],
          [ 0.2343, -0.1421, -0.1480,  0.1374,  0.4268]],

         [[-0.1671,  0.2869,  0.1844, -0.2486, -0.4420],
          [ 0.1157, -0.1195, -0.0834,  0.1225,  0.2476]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 2, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[ 4.7885e-01,  4.6373e-01,  5.0588e-01,  3.4177e-01, -1.0000e+09],
          [ 2.3433e-01, -1.4210e-01, -1.4802e-01,  1.3741e-01, -1.0000e+09]],

         [[-1.6708e-01,  2.8691e-01,  1.8443e-01, -2.4858e-01, -1.0000e+09],
          [ 1.1569e-01, -1.1946e-01, -8.3442e-02,  1.2247e-01, -1.0000e+09]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 2, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[0.2574, 0.2536, 0.2645, 0.2245, 0.0000],
          [0.3052, 0.2095, 0.2082, 0.2770, 0.0000]],

         [[0.2034, 0.3202, 0.2890, 0.1874, 0.0000],
          [0.2765, 0.2186, 0.2266, 0.2784, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 2, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.2204, -0.0899],
          [ 0.1772, -0.0469]],

         [[ 0.0060,  0.7702],
          [-0.0599,  0.7408]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 2, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[0.2574, 0.2536, 0.2645, 0.2245, 0.0000],
          [0.3052, 0.2095, 0.2082, 0.2770, 0.0000]],

         [[0.2034, 0.3202, 0.2890, 0.1874, 0.0000],
          [0.2765, 0.2186, 0.2266, 0.2784, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 2, 5])
```


context: 

```python
tensor([[[[ 0.2204, -0.0899],
          [ 0.1772, -0.0469]],

         [[ 0.0060,  0.7702],
          [-0.0599,  0.7408]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 2, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.2204, -0.0899,  0.0060,  0.7702],
         [ 0.1772, -0.0469, -0.0599,  0.7408]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[-0.3010, -0.2249,  0.3865, -0.2513],
         [-0.2968, -0.1894,  0.4031, -0.2556]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 2, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-0.4287,  1.3828, -1.3282,  0.3740],
         [ 1.7099, -0.6693, -0.3119, -0.7287]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 2, 4])
```


output + residual: 

```python
tensor([[[-0.7296,  1.1580, -0.9417,  0.1227],
         [ 1.4131, -0.8587,  0.0912, -0.9843]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 2, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-0.7640,  1.5179, -1.0204,  0.2664],
         [ 1.5609, -0.8066,  0.1833, -0.9376]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 2, 4])
```


## PoswiseFeedForwardNet


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


inputs: 

```python
tensor([[[-0.7640,  1.5179, -1.0204,  0.2664],
         [ 1.5609, -0.8066,  0.1833, -0.9376]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 2, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc操作的代码</div>


: 

```python
output = self.fc(inputs)
```


inputs: 

```python
tensor([[[-0.7640,  1.5179, -1.0204,  0.2664],
         [ 1.5609, -0.8066,  0.1833, -0.9376]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 2, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc原来是d_model->d_ff->d_model</div>


self.fc: 

```python
Sequential(
  (0): Linear(in_features=4, out_features=8, bias=False)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=4, bias=False)
)
```


output: 

```python
tensor([[[ 0.0586, -0.2144, -0.2289,  0.2034],
         [ 0.0273, -0.0057, -0.0656,  0.0734]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 2, 4])
```


## 前馈层后的层归一化和残差


<div style='color:#fe618e;font-weight:800;font-size:23px;'>FeedForward后的层归一化和残差</div>


: 

```python
ans = nn.LayerNorm(d_model).to(device)(output + residual)
```


residual: 

```python
tensor([[[-0.7640,  1.5179, -1.0204,  0.2664],
         [ 1.5609, -0.8066,  0.1833, -0.9376]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 2, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>残差和层归一化之后的结果</div>


ans: 

```python
tensor([[[-0.6626,  1.3539, -1.2085,  0.5171],
         [ 1.5923, -0.8256,  0.1111, -0.8778]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans.shape: 

```python
torch.Size([1, 2, 4])
```


# DecoderLayer


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-0.6626,  1.3539, -1.2085,  0.5171],
         [ 1.5923, -0.8256,  0.1111, -0.8778]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 2, 4])
```


input_K: 

```python
tensor([[[-0.6626,  1.3539, -1.2085,  0.5171],
         [ 1.5923, -0.8256,  0.1111, -0.8778]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 2, 4])
```


input_V: 

```python
tensor([[[-0.6626,  1.3539, -1.2085,  0.5171],
         [ 1.5923, -0.8256,  0.1111, -0.8778]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 2, 4])
```


attn_mask: 

```python
tensor([[[False,  True],
         [False, False]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[-0.2694,  1.0717],
          [-0.4741, -0.9461]],

         [[ 0.4726, -0.3178],
          [ 0.1603, -0.0800]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 2, 2])
```


K: 

```python
tensor([[[[ 0.7898,  0.2129],
          [ 0.1835,  0.3390]],

         [[ 0.3101, -1.0616],
          [-0.2636,  0.1458]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 2, 2])
```


V: 

```python
tensor([[[[ 0.2251, -0.0811],
          [-0.2960, -0.6830]],

         [[ 0.7054, -0.5341],
          [-0.5842,  0.3466]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 2, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False,  True],
          [False, False]],

         [[False,  True],
          [False, False]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 2, 2])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[-0.2694,  1.0717],
          [-0.4741, -0.9461]],

         [[ 0.4726, -0.3178],
          [ 0.1603, -0.0800]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 2, 2])
```


K: 

```python
tensor([[[[ 0.7898,  0.2129],
          [ 0.1835,  0.3390]],

         [[ 0.3101, -1.0616],
          [-0.2636,  0.1458]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 2, 2])
```


V: 

```python
tensor([[[[ 0.2251, -0.0811],
          [-0.2960, -0.6830]],

         [[ 0.7054, -0.5341],
          [-0.5842,  0.3466]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 2, 2])
```


attn_mask: 

```python
tensor([[[[False,  True],
          [False, False]],

         [[False,  True],
          [False, False]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 2, 2])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[ 0.0109,  0.2219],
          [-0.4072, -0.2883]],

         [[ 0.3421, -0.1209],
          [ 0.0952, -0.0381]]]], grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 2, 2])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[ 1.0907e-02, -1.0000e+09],
          [-4.0722e-01, -2.8828e-01]],

         [[ 3.4214e-01, -1.0000e+09],
          [ 9.5203e-02, -3.8129e-02]]]], grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 2, 2])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[1.0000, 0.0000],
          [0.4703, 0.5297]],

         [[1.0000, 0.0000],
          [0.5333, 0.4667]]]], grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 2, 2])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.2251, -0.0811],
          [-0.0509, -0.4000]],

         [[ 0.7054, -0.5341],
          [ 0.1035, -0.1231]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 2, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[1.0000, 0.0000],
          [0.4703, 0.5297]],

         [[1.0000, 0.0000],
          [0.5333, 0.4667]]]], grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 2, 2])
```


context: 

```python
tensor([[[[ 0.2251, -0.0811],
          [-0.0509, -0.4000]],

         [[ 0.7054, -0.5341],
          [ 0.1035, -0.1231]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 2, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.2251, -0.0811,  0.7054, -0.5341],
         [-0.0509, -0.4000,  0.1035, -0.1231]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[-0.1149,  0.1599, -0.0084,  0.4247],
         [ 0.1924, -0.0945, -0.0994, -0.0504]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 2, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-0.6626,  1.3539, -1.2085,  0.5171],
         [ 1.5923, -0.8256,  0.1111, -0.8778]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 2, 4])
```


output + residual: 

```python
tensor([[[-0.7775,  1.5138, -1.2169,  0.9418],
         [ 1.7847, -0.9201,  0.0117, -0.9282]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 2, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-0.7822,  1.2253, -1.1672,  0.7241],
         [ 1.6254, -0.8202,  0.0223, -0.8275]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 2, 4])
```


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-0.7822,  1.2253, -1.1672,  0.7241],
         [ 1.6254, -0.8202,  0.0223, -0.8275]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 2, 4])
```


input_K: 

```python
tensor([[[ 0.6868, -1.7263,  0.5829,  0.4565],
         [ 1.6033, -1.1500, -0.2725, -0.1809],
         [ 1.1261, -0.7021, -1.2486,  0.8246],
         [-0.2686, -0.4144, -0.9857,  1.6687],
         [-0.2267, -1.5400,  0.9742,  0.7925]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[ 0.6868, -1.7263,  0.5829,  0.4565],
         [ 1.6033, -1.1500, -0.2725, -0.1809],
         [ 1.1261, -0.7021, -1.2486,  0.8246],
         [-0.2686, -0.4144, -0.9857,  1.6687],
         [-0.2267, -1.5400,  0.9742,  0.7925]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[-0.1262,  0.0510],
          [ 0.1041, -0.7187]],

         [[-0.1579, -0.2085],
          [-0.1206, -0.5332]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 2, 2])
```


K: 

```python
tensor([[[[ 0.0340,  0.0352],
          [ 0.1903,  0.0466],
          [-0.2709,  0.3840],
          [-0.6189,  0.4860],
          [-0.1048,  0.0250]],

         [[ 0.8016, -0.1494],
          [ 1.0380, -0.4053],
          [ 0.4957,  0.0590],
          [-0.2779,  0.5567],
          [ 0.3398,  0.1011]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 1.0637, -0.5323],
          [ 0.9685, -0.5174],
          [-0.2034, -0.3953],
          [-0.9852, -0.1468],
          [ 0.7337, -0.3573]],

         [[ 0.1639, -0.2189],
          [-0.3600, -0.3702],
          [-0.3778, -0.5270],
          [ 0.0821, -0.3430],
          [ 0.4870, -0.0390]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 2, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[-0.1262,  0.0510],
          [ 0.1041, -0.7187]],

         [[-0.1579, -0.2085],
          [-0.1206, -0.5332]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 2, 2])
```


K: 

```python
tensor([[[[ 0.0340,  0.0352],
          [ 0.1903,  0.0466],
          [-0.2709,  0.3840],
          [-0.6189,  0.4860],
          [-0.1048,  0.0250]],

         [[ 0.8016, -0.1494],
          [ 1.0380, -0.4053],
          [ 0.4957,  0.0590],
          [-0.2779,  0.5567],
          [ 0.3398,  0.1011]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 1.0637, -0.5323],
          [ 0.9685, -0.5174],
          [-0.2034, -0.3953],
          [-0.9852, -0.1468],
          [ 0.7337, -0.3573]],

         [[ 0.1639, -0.2189],
          [-0.3600, -0.3702],
          [-0.3778, -0.5270],
          [ 0.0821, -0.3430],
          [ 0.4870, -0.0390]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 2, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[-0.0018, -0.0153,  0.0380,  0.0728,  0.0103],
          [-0.0154, -0.0097, -0.2151, -0.2925, -0.0204]],

         [[-0.0675, -0.0561, -0.0640, -0.0511, -0.0528],
          [-0.0120,  0.0643, -0.0645, -0.1862, -0.0671]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 2, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[-1.7599e-03, -1.5302e-02,  3.8037e-02,  7.2778e-02, -1.0000e+09],
          [-1.5388e-02, -9.6661e-03, -2.1506e-01, -2.9251e-01, -1.0000e+09]],

         [[-6.7469e-02, -5.6122e-02, -6.4038e-02, -5.1052e-02, -1.0000e+09],
          [-1.2029e-02,  6.4316e-02, -6.4498e-02, -1.8620e-01, -1.0000e+09]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 2, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[0.2436, 0.2404, 0.2535, 0.2625, 0.0000],
          [0.2791, 0.2807, 0.2286, 0.2116, 0.0000]],

         [[0.2481, 0.2509, 0.2489, 0.2522, 0.0000],
          [0.2585, 0.2790, 0.2453, 0.2172, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 2, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.1818, -0.3928],
          [ 0.3139, -0.4152]],

         [[-0.1230, -0.3648],
          [-0.1329, -0.3636]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 2, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[0.2436, 0.2404, 0.2535, 0.2625, 0.0000],
          [0.2791, 0.2807, 0.2286, 0.2116, 0.0000]],

         [[0.2481, 0.2509, 0.2489, 0.2522, 0.0000],
          [0.2585, 0.2790, 0.2453, 0.2172, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 2, 5])
```


context: 

```python
tensor([[[[ 0.1818, -0.3928],
          [ 0.3139, -0.4152]],

         [[-0.1230, -0.3648],
          [-0.1329, -0.3636]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 2, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.1818, -0.3928, -0.1230, -0.3648],
         [ 0.3139, -0.4152, -0.1329, -0.3636]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[ 0.1087,  0.0010,  0.0669, -0.1148],
         [ 0.0750,  0.0229,  0.1022, -0.0901]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 2, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-0.7822,  1.2253, -1.1672,  0.7241],
         [ 1.6254, -0.8202,  0.0223, -0.8275]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 2, 4])
```


output + residual: 

```python
tensor([[[-0.6735,  1.2263, -1.1004,  0.6094],
         [ 1.7004, -0.7973,  0.1245, -0.9177]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 2, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-0.7325,  1.2874, -1.1863,  0.6315],
         [ 1.5984, -0.7880,  0.0927, -0.9031]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 2, 4])
```


## PoswiseFeedForwardNet


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


inputs: 

```python
tensor([[[-0.7325,  1.2874, -1.1863,  0.6315],
         [ 1.5984, -0.7880,  0.0927, -0.9031]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 2, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc操作的代码</div>


: 

```python
output = self.fc(inputs)
```


inputs: 

```python
tensor([[[-0.7325,  1.2874, -1.1863,  0.6315],
         [ 1.5984, -0.7880,  0.0927, -0.9031]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 2, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc原来是d_model->d_ff->d_model</div>


self.fc: 

```python
Sequential(
  (0): Linear(in_features=4, out_features=8, bias=False)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=4, bias=False)
)
```


output: 

```python
tensor([[[-0.0614, -0.1831, -0.0225,  0.0241],
         [-0.2362, -0.0408, -0.2841, -0.1324]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 2, 4])
```


## 前馈层后的层归一化和残差


<div style='color:#fe618e;font-weight:800;font-size:23px;'>FeedForward后的层归一化和残差</div>


: 

```python
ans = nn.LayerNorm(d_model).to(device)(output + residual)
```


residual: 

```python
tensor([[[-0.7325,  1.2874, -1.1863,  0.6315],
         [ 1.5984, -0.7880,  0.0927, -0.9031]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 2, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>残差和层归一化之后的结果</div>


ans: 

```python
tensor([[[-0.7597,  1.2070, -1.1895,  0.7422],
         [ 1.6343, -0.6976, -0.0192, -0.9175]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans.shape: 

```python
torch.Size([1, 2, 4])
```


# Decoder结束


<div style='color:#fe618e;font-weight:800;font-size:23px;'>model的decode操作</div>


: 

```python
dec_outputs, _, _ = model.decoder(dec_input, enc_input, enc_outputs)
```


dec_outputs: 

```python
tensor([[[-0.7597,  1.2070, -1.1895,  0.7422],
         [ 1.6343, -0.6976, -0.0192, -0.9175]]],
       grad_fn=<NativeLayerNormBackward0>)
```


dec_outputs.shape: 

```python
torch.Size([1, 2, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>model的projection操作</div>


: 

```python
projected = model.projection(dec_outputs)
```


projected: 

```python
tensor([[[-0.1951,  3.0093, -2.2052,  2.7557, -0.4902, -3.2442, -0.7391],
         [ 0.0407, -3.1940,  4.1533,  0.6630,  0.0790, -0.0890, -0.2498]]],
       grad_fn=<UnsafeViewBackward0>)
```


projected.shape: 

```python
torch.Size([1, 2, 7])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>生成prob</div>


: 

```python
prob = projected.squeeze(0).max(dim=-1, keepdim=False)[1]
```


prob: 

```python
tensor([1, 2])
```


prob.shape: 

```python
torch.Size([2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>生成next_word</div>


: 

```python
next_word = prob.data[-1]
```


next_word: 

```python
tensor(2)
```


next_word.shape: 

```python
torch.Size([])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>迭代下一轮</div>


: 

```python
next_symbol = next_word
```


next_symbol: 

```python
tensor(2)
```


# 预测这句话第【3】个单词：


<div style='color:#fe618e;font-weight:800;font-size:23px;'>生成dec_input</div>


: 

```python
dec_input = torch.cat([dec_input.to(device), torch.tensor([[next_symbol]], dtype=enc_input.dtype).to(device)],-1)
```


dec_input: 

```python
tensor([[4, 1, 2]])
```


dec_input.shape: 

```python
torch.Size([1, 3])
```


# Decoder中


<div style='color:#3296ee;font-weight:800;font-size:23px;'>dec_inputs转换为词向量的结果</div>


: 

```python
dec_outputs = self.tgt_emb(dec_inputs)
```


dec_outputs: 

```python
tensor([[[-1.0398,  1.3073, -0.2711, -0.4491],
         [ 1.2834, -0.4243,  0.4540, -1.6032],
         [ 0.1516,  1.9322, -0.6804, -0.9484]]], grad_fn=<EmbeddingBackward0>)
```


dec_outputs.shape: 

```python
torch.Size([1, 3, 4])
```


## PositionalEncoding


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入加上位置编码的代码</div>


加上位置编码: 

```python
x = x + self.pe[:x.size(0), :]
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


x: 

```python
tensor([[[-1.0398,  1.3073, -0.2711, -0.4491]],

        [[ 1.2834, -0.4243,  0.4540, -1.6032]],

        [[ 0.1516,  1.9322, -0.6804, -0.9484]]], grad_fn=<TransposeBackward0>)
```


x.shape: 

```python
torch.Size([3, 1, 4])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>位置编码</div>


self.pe[:x.size(0), :]: 

```python
tensor([[[ 0.0000,  1.0000,  0.0000,  1.0000]],

        [[ 0.8415,  0.5403,  0.0100,  0.9999]],

        [[ 0.9093, -0.4161,  0.0200,  0.9998]]])
```


self.pe[:x.size(0), :].shape: 

```python
torch.Size([3, 1, 4])
```


self.pe.shape: 

```python
torch.Size([5000, 1, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


x: 

```python
tensor([[[-1.0398,  2.3073, -0.2711,  0.5509]],

        [[ 2.1248,  0.1160,  0.4640, -0.6032]],

        [[ 1.0609,  1.5160, -0.6604,  0.0514]]], grad_fn=<AddBackward0>)
```


x.shape: 

```python
torch.Size([3, 1, 4])
```


## decoder的self_attn的pad_mask


## get_attn_pad_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq_q: 

```python
tensor([[4, 1, 2]])
```


seq_q.shape: 

```python
torch.Size([1, 3])
```


seq_k: 

```python
tensor([[4, 1, 2]])
```


seq_k.shape: 

```python
torch.Size([1, 3])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>获取对应的大小：len_q,len_k</div>


例如: 

```python
batch_size, len_q = seq_q.size()
```


batch_size: 

```python
1
```


len_q: 

```python
3
```


len_k: 

```python
3
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>操作pad_attn_mask矩阵：pad_attn_mask</div>


: 

```python
pad_attn_mask = seq_k.data.eq(0).unsqueeze(1) 
```


pad_attn_mask: 

```python
tensor([[[False, False, False]]])
```


pad_attn_mask.shape: 

```python
torch.Size([1, 1, 3])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>扩展pad_attn_mask矩阵：pad_attn_mask.expand</div>


: 

```python
ans = pad_attn_mask.expand(batch_size, len_q, len_k)  
```


ans: 

```python
tensor([[[False, False, False],
         [False, False, False],
         [False, False, False]]])
```


ans.shape: 

```python
torch.Size([1, 3, 3])
```


## get_attn_subsequence_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq: 

```python
tensor([[4, 1, 2]])
```


seq.shape: 

```python
torch.Size([1, 3])
```


<div style='color:#19ce8b;font-weight:800;font-size:23px;'>求attn_shape</div>


: 

```python
attn_shape = [seq.size(0), seq.size(1), seq.size(1)]
```


attn_shape: 

```python
[1, 3, 3]
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>生成一个上三角矩阵</div>


: 

```python
subsequence_mask = np.triu(np.ones(attn_shape), k=1)
```


subsequence_mask: 

```python
[[[0. 1. 1.]
  [0. 0. 1.]
  [0. 0. 0.]]]
```


subsequence_mask.shape: 

```python
(1, 3, 3)
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>生成subsequence_mask</div>


: 

```python
subsequence_mask = torch.from_numpy(subsequence_mask).byte()
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


subsequence_mask: 

```python
tensor([[[0, 1, 1],
         [0, 0, 1],
         [0, 0, 0]]], dtype=torch.uint8)
```


subsequence_mask.shape: 

```python
torch.Size([1, 3, 3])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>两个mask相加</div>


: 

```python
dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequence_mask),0).to(device)
```


dec_self_attn_pad_mask: 

```python
tensor([[[False, False, False],
         [False, False, False],
         [False, False, False]]])
```


dec_self_attn_pad_mask.shape: 

```python
torch.Size([1, 3, 3])
```


dec_self_attn_subsequence_mask: 

```python
tensor([[[0, 1, 1],
         [0, 0, 1],
         [0, 0, 0]]], dtype=torch.uint8)
```


dec_self_attn_subsequence_mask.shape: 

```python
torch.Size([1, 3, 3])
```


dec_self_attn_mask: 

```python
tensor([[[False,  True,  True],
         [False, False,  True],
         [False, False, False]]])
```


dec_self_attn_mask.shape: 

```python
torch.Size([1, 3, 3])
```


## 交互注意力层中的pad_mask


## get_attn_pad_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq_q: 

```python
tensor([[4, 1, 2]])
```


seq_q.shape: 

```python
torch.Size([1, 3])
```


seq_k: 

```python
tensor([[4, 1, 2]])
```


seq_k.shape: 

```python
torch.Size([1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>获取对应的大小：len_q,len_k</div>


例如: 

```python
batch_size, len_q = seq_q.size()
```


batch_size: 

```python
1
```


len_q: 

```python
3
```


len_k: 

```python
5
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>操作pad_attn_mask矩阵：pad_attn_mask</div>


: 

```python
pad_attn_mask = seq_k.data.eq(0).unsqueeze(1) 
```


pad_attn_mask: 

```python
tensor([[[False, False, False, False,  True]]])
```


pad_attn_mask.shape: 

```python
torch.Size([1, 1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>扩展pad_attn_mask矩阵：pad_attn_mask.expand</div>


: 

```python
ans = pad_attn_mask.expand(batch_size, len_q, len_k)  
```


ans: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


ans.shape: 

```python
torch.Size([1, 3, 5])
```


# DecoderLayer


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-1.1553,  2.5637, -0.3013,  0.6121],
         [ 2.3609,  0.1289,  0.5155, -0.6703],
         [ 1.1788,  1.6845, -0.7337,  0.0572]]], grad_fn=<TransposeBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 3, 4])
```


input_K: 

```python
tensor([[[-1.1553,  2.5637, -0.3013,  0.6121],
         [ 2.3609,  0.1289,  0.5155, -0.6703],
         [ 1.1788,  1.6845, -0.7337,  0.0572]]], grad_fn=<TransposeBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 3, 4])
```


input_V: 

```python
tensor([[[-1.1553,  2.5637, -0.3013,  0.6121],
         [ 2.3609,  0.1289,  0.5155, -0.6703],
         [ 1.1788,  1.6845, -0.7337,  0.0572]]], grad_fn=<TransposeBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 3, 4])
```


attn_mask: 

```python
tensor([[[False,  True,  True],
         [False, False,  True],
         [False, False, False]]])
```


attn_mask.shape: 

```python
torch.Size([1, 3, 3])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 0.9375, -0.0820],
          [-0.2406, -0.5678],
          [ 0.1645, -0.0746]],

         [[-1.2241, -1.3372],
          [ 0.6229,  0.6148],
          [-0.2854,  0.1582]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 3, 2])
```


K: 

```python
tensor([[[[-0.5534, -0.8596],
          [ 0.6511, -0.1221],
          [ 0.4262, -0.3733]],

         [[-1.2777, -0.0468],
          [ 0.1760, -0.4867],
          [-0.3548, -0.6770]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 3, 2])
```


V: 

```python
tensor([[[[ 0.6492,  1.1050],
          [ 0.8156, -0.9357],
          [ 0.7731,  0.0703]],

         [[-0.3369,  0.7558],
          [-0.8736, -0.3561],
          [-1.0386,  0.7502]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 3, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False,  True,  True],
          [False, False,  True],
          [False, False, False]],

         [[False,  True,  True],
          [False, False,  True],
          [False, False, False]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 3, 3])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 0.9375, -0.0820],
          [-0.2406, -0.5678],
          [ 0.1645, -0.0746]],

         [[-1.2241, -1.3372],
          [ 0.6229,  0.6148],
          [-0.2854,  0.1582]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 3, 2])
```


K: 

```python
tensor([[[[-0.5534, -0.8596],
          [ 0.6511, -0.1221],
          [ 0.4262, -0.3733]],

         [[-1.2777, -0.0468],
          [ 0.1760, -0.4867],
          [-0.3548, -0.6770]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 3, 2])
```


V: 

```python
tensor([[[[ 0.6492,  1.1050],
          [ 0.8156, -0.9357],
          [ 0.7731,  0.0703]],

         [[-0.3369,  0.7558],
          [-0.8736, -0.3561],
          [-1.0386,  0.7502]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 3, 2])
```


attn_mask: 

```python
tensor([[[[False,  True,  True],
          [False, False,  True],
          [False, False, False]],

         [[False,  True,  True],
          [False, False,  True],
          [False, False, False]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 3, 3])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[-0.3170,  0.4387,  0.3042],
          [ 0.4393, -0.0618,  0.0773],
          [-0.0190,  0.0822,  0.0692]],

         [[ 1.1502,  0.3079,  0.9472],
          [-0.5831, -0.1341, -0.4506],
          [ 0.2526, -0.0899, -0.0041]]]], grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 3, 3])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[-3.1701e-01, -1.0000e+09, -1.0000e+09],
          [ 4.3930e-01, -6.1765e-02, -1.0000e+09],
          [-1.9041e-02,  8.2160e-02,  6.9249e-02]],

         [[ 1.1502e+00, -1.0000e+09, -1.0000e+09],
          [-5.8314e-01, -1.3408e-01, -1.0000e+09],
          [ 2.5259e-01, -8.9948e-02, -4.1206e-03]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 3, 3])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[1.0000, 0.0000, 0.0000],
          [0.6227, 0.3773, 0.0000],
          [0.3126, 0.3459, 0.3415]],

         [[1.0000, 0.0000, 0.0000],
          [0.3896, 0.6104, 0.0000],
          [0.4026, 0.2859, 0.3115]]]], grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 3, 3])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.6492,  1.1050],
          [ 0.7120,  0.3350],
          [ 0.7491,  0.0458]],

         [[-0.3369,  0.7558],
          [-0.6645,  0.0771],
          [-0.7089,  0.4362]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 3, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[1.0000, 0.0000, 0.0000],
          [0.6227, 0.3773, 0.0000],
          [0.3126, 0.3459, 0.3415]],

         [[1.0000, 0.0000, 0.0000],
          [0.3896, 0.6104, 0.0000],
          [0.4026, 0.2859, 0.3115]]]], grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 3, 3])
```


context: 

```python
tensor([[[[ 0.6492,  1.1050],
          [ 0.7120,  0.3350],
          [ 0.7491,  0.0458]],

         [[-0.3369,  0.7558],
          [-0.6645,  0.0771],
          [-0.7089,  0.4362]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 3, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.6492,  1.1050, -0.3369,  0.7558],
         [ 0.7120,  0.3350, -0.6645,  0.0771],
         [ 0.7491,  0.0458, -0.7089,  0.4362]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 3, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[ 0.6525,  0.1585, -0.2623,  0.4406],
         [ 0.4765,  0.0612,  0.0371,  0.5614],
         [ 0.3756,  0.1495, -0.0289,  0.8599]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 3, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-1.1553,  2.5637, -0.3013,  0.6121],
         [ 2.3609,  0.1289,  0.5155, -0.6703],
         [ 1.1788,  1.6845, -0.7337,  0.0572]]], grad_fn=<TransposeBackward0>)
```


residual.shape: 

```python
torch.Size([1, 3, 4])
```


output + residual: 

```python
tensor([[[-0.5027,  2.7222, -0.5635,  1.0527],
         [ 2.8374,  0.1900,  0.5526, -0.1088],
         [ 1.5544,  1.8340, -0.7626,  0.9171]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 3, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-0.8761,  1.5185, -0.9212,  0.2788],
         [ 1.6964, -0.5838, -0.2715, -0.8412],
         [ 0.6633,  0.9408, -1.6352,  0.0311]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 3, 4])
```


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-0.8761,  1.5185, -0.9212,  0.2788],
         [ 1.6964, -0.5838, -0.2715, -0.8412],
         [ 0.6633,  0.9408, -1.6352,  0.0311]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 3, 4])
```


input_K: 

```python
tensor([[[ 0.6868, -1.7263,  0.5829,  0.4565],
         [ 1.6033, -1.1500, -0.2725, -0.1809],
         [ 1.1261, -0.7021, -1.2486,  0.8246],
         [-0.2686, -0.4144, -0.9857,  1.6687],
         [-0.2267, -1.5400,  0.9742,  0.7925]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[ 0.6868, -1.7263,  0.5829,  0.4565],
         [ 1.6033, -1.1500, -0.2725, -0.1809],
         [ 1.1261, -0.7021, -1.2486,  0.8246],
         [-0.2686, -0.4144, -0.9857,  1.6687],
         [-0.2267, -1.5400,  0.9742,  0.7925]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 3, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 1.0464,  0.3356],
          [-1.0079,  0.8932],
          [ 0.3229,  1.0730]],

         [[-0.7483,  0.2133],
          [ 0.2788,  0.0657],
          [-0.5575,  0.1700]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 3, 2])
```


K: 

```python
tensor([[[[ 0.2876,  0.7402],
          [ 0.4966,  0.3560],
          [ 0.5376,  0.3952],
          [ 0.2229,  0.4991],
          [ 0.0389,  0.7666]],

         [[ 0.4759,  0.6528],
          [-0.5556, -0.0237],
          [-0.3791, -0.1074],
          [ 0.5440,  0.2833],
          [ 1.0660,  0.9173]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.9145,  0.2993],
          [ 0.9688, -0.2155],
          [-0.1428, -0.3849],
          [-0.9931, -0.0470],
          [ 0.5290,  0.5650]],

         [[ 0.1975,  0.7515],
          [ 0.3600,  0.7951],
          [-0.1420,  0.8862],
          [-0.5786,  0.5694],
          [-0.0029,  0.4654]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 3, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 1.0464,  0.3356],
          [-1.0079,  0.8932],
          [ 0.3229,  1.0730]],

         [[-0.7483,  0.2133],
          [ 0.2788,  0.0657],
          [-0.5575,  0.1700]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 3, 2])
```


K: 

```python
tensor([[[[ 0.2876,  0.7402],
          [ 0.4966,  0.3560],
          [ 0.5376,  0.3952],
          [ 0.2229,  0.4991],
          [ 0.0389,  0.7666]],

         [[ 0.4759,  0.6528],
          [-0.5556, -0.0237],
          [-0.3791, -0.1074],
          [ 0.5440,  0.2833],
          [ 1.0660,  0.9173]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.9145,  0.2993],
          [ 0.9688, -0.2155],
          [-0.1428, -0.3849],
          [-0.9931, -0.0470],
          [ 0.5290,  0.5650]],

         [[ 0.1975,  0.7515],
          [ 0.3600,  0.7951],
          [-0.1420,  0.8862],
          [-0.5786,  0.5694],
          [-0.0029,  0.4654]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 3, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[ 0.3884,  0.4519,  0.4916,  0.2833,  0.2107],
          [ 0.2625, -0.1291, -0.1336,  0.1564,  0.4564],
          [ 0.6272,  0.3835,  0.4226,  0.4296,  0.5905]],

         [[-0.1534,  0.2904,  0.1844, -0.2451, -0.4257],
          [ 0.1241, -0.1106, -0.0797,  0.1204,  0.2528],
          [-0.1092,  0.2162,  0.1365, -0.1804, -0.3100]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 3, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[ 3.8840e-01,  4.5193e-01,  4.9157e-01,  2.8334e-01, -1.0000e+09],
          [ 2.6252e-01, -1.2913e-01, -1.3360e-01,  1.5638e-01, -1.0000e+09],
          [ 6.2725e-01,  3.8348e-01,  4.2257e-01,  4.2958e-01, -1.0000e+09]],

         [[-1.5338e-01,  2.9043e-01,  1.8441e-01, -2.4515e-01, -1.0000e+09],
          [ 1.2414e-01, -1.1063e-01, -7.9728e-02,  1.2040e-01, -1.0000e+09],
          [-1.0915e-01,  2.1618e-01,  1.3655e-01, -1.8042e-01, -1.0000e+09]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 3, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[0.2454, 0.2615, 0.2721, 0.2210, 0.0000],
          [0.3079, 0.2081, 0.2072, 0.2769, 0.0000],
          [0.2925, 0.2292, 0.2383, 0.2400, 0.0000]],

         [[0.2052, 0.3199, 0.2877, 0.1872, 0.0000],
          [0.2776, 0.2195, 0.2264, 0.2765, 0.0000],
          [0.2177, 0.3014, 0.2783, 0.2027, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 3, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.2195, -0.0980],
          [ 0.1786, -0.0454],
          [ 0.2171, -0.0649]],

         [[ 0.0065,  0.7701],
          [-0.0583,  0.7412],
          [-0.0053,  0.7652]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 3, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[0.2454, 0.2615, 0.2721, 0.2210, 0.0000],
          [0.3079, 0.2081, 0.2072, 0.2769, 0.0000],
          [0.2925, 0.2292, 0.2383, 0.2400, 0.0000]],

         [[0.2052, 0.3199, 0.2877, 0.1872, 0.0000],
          [0.2776, 0.2195, 0.2264, 0.2765, 0.0000],
          [0.2177, 0.3014, 0.2783, 0.2027, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 3, 5])
```


context: 

```python
tensor([[[[ 0.2195, -0.0980],
          [ 0.1786, -0.0454],
          [ 0.2171, -0.0649]],

         [[ 0.0065,  0.7701],
          [-0.0583,  0.7412],
          [-0.0053,  0.7652]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 3, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.2195, -0.0980,  0.0065,  0.7701],
         [ 0.1786, -0.0454, -0.0583,  0.7412],
         [ 0.2171, -0.0649, -0.0053,  0.7652]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 3, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[-0.3036, -0.2255,  0.3885, -0.2493],
         [-0.2958, -0.1900,  0.4017, -0.2560],
         [-0.2935, -0.2178,  0.3833, -0.2567]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 3, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-0.8761,  1.5185, -0.9212,  0.2788],
         [ 1.6964, -0.5838, -0.2715, -0.8412],
         [ 0.6633,  0.9408, -1.6352,  0.0311]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 3, 4])
```


output + residual: 

```python
tensor([[[-1.1798,  1.2931, -0.5327,  0.0296],
         [ 1.4006, -0.7738,  0.1302, -1.0972],
         [ 0.3698,  0.7229, -1.2520, -0.2256]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 3, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-1.1897,  1.5285, -0.4784,  0.1396],
         [ 1.5339, -0.7111,  0.2223, -1.0450],
         [ 0.6226,  1.0945, -1.5442, -0.1729]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 3, 4])
```


## PoswiseFeedForwardNet


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


inputs: 

```python
tensor([[[-1.1897,  1.5285, -0.4784,  0.1396],
         [ 1.5339, -0.7111,  0.2223, -1.0450],
         [ 0.6226,  1.0945, -1.5442, -0.1729]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 3, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc操作的代码</div>


: 

```python
output = self.fc(inputs)
```


inputs: 

```python
tensor([[[-1.1897,  1.5285, -0.4784,  0.1396],
         [ 1.5339, -0.7111,  0.2223, -1.0450],
         [ 0.6226,  1.0945, -1.5442, -0.1729]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 3, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc原来是d_model->d_ff->d_model</div>


self.fc: 

```python
Sequential(
  (0): Linear(in_features=4, out_features=8, bias=False)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=4, bias=False)
)
```


output: 

```python
tensor([[[ 0.0237, -0.1882, -0.1871,  0.2141],
         [ 0.0482,  0.0034, -0.0285,  0.0392],
         [ 0.0606, -0.2262, -0.2742,  0.2698]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 3, 4])
```


## 前馈层后的层归一化和残差


<div style='color:#fe618e;font-weight:800;font-size:23px;'>FeedForward后的层归一化和残差</div>


: 

```python
ans = nn.LayerNorm(d_model).to(device)(output + residual)
```


residual: 

```python
tensor([[[-1.1897,  1.5285, -0.4784,  0.1396],
         [ 1.5339, -0.7111,  0.2223, -1.0450],
         [ 0.6226,  1.0945, -1.5442, -0.1729]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 3, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>残差和层归一化之后的结果</div>


ans: 

```python
tensor([[[-1.1735,  1.4256, -0.6546,  0.4025],
         [ 1.5564, -0.7186,  0.1771, -1.0148],
         [ 0.6820,  0.8559, -1.6689,  0.1310]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans.shape: 

```python
torch.Size([1, 3, 4])
```


# DecoderLayer


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-1.1735,  1.4256, -0.6546,  0.4025],
         [ 1.5564, -0.7186,  0.1771, -1.0148],
         [ 0.6820,  0.8559, -1.6689,  0.1310]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 3, 4])
```


input_K: 

```python
tensor([[[-1.1735,  1.4256, -0.6546,  0.4025],
         [ 1.5564, -0.7186,  0.1771, -1.0148],
         [ 0.6820,  0.8559, -1.6689,  0.1310]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 3, 4])
```


input_V: 

```python
tensor([[[-1.1735,  1.4256, -0.6546,  0.4025],
         [ 1.5564, -0.7186,  0.1771, -1.0148],
         [ 0.6820,  0.8559, -1.6689,  0.1310]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 3, 4])
```


attn_mask: 

```python
tensor([[[False,  True,  True],
         [False, False,  True],
         [False, False, False]]])
```


attn_mask.shape: 

```python
torch.Size([1, 3, 3])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 0.0535,  1.1167],
          [-0.4665, -0.9251],
          [-0.8339,  0.5206]],

         [[ 0.3753, -0.0296],
          [ 0.2304, -0.0184],
          [ 0.6634, -0.6275]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 3, 2])
```


K: 

```python
tensor([[[[ 0.4299, -0.1691],
          [ 0.1924,  0.2671],
          [ 1.2353,  0.7510]],

         [[ 0.2378, -0.6551],
          [-0.2951,  0.1763],
          [ 0.2320, -1.3676]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 3, 2])
```


V: 

```python
tensor([[[[ 0.3322,  0.2007],
          [-0.2658, -0.7029],
          [-0.0328, -0.7235]],

         [[ 0.6469, -0.6036],
          [-0.6035,  0.2894],
          [ 0.4426, -0.2891]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 3, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False,  True,  True],
          [False, False,  True],
          [False, False, False]],

         [[False,  True,  True],
          [False, False,  True],
          [False, False, False]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 3, 3])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 0.0535,  1.1167],
          [-0.4665, -0.9251],
          [-0.8339,  0.5206]],

         [[ 0.3753, -0.0296],
          [ 0.2304, -0.0184],
          [ 0.6634, -0.6275]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 3, 2])
```


K: 

```python
tensor([[[[ 0.4299, -0.1691],
          [ 0.1924,  0.2671],
          [ 1.2353,  0.7510]],

         [[ 0.2378, -0.6551],
          [-0.2951,  0.1763],
          [ 0.2320, -1.3676]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 3, 2])
```


V: 

```python
tensor([[[[ 0.3322,  0.2007],
          [-0.2658, -0.7029],
          [-0.0328, -0.7235]],

         [[ 0.6469, -0.6036],
          [-0.6035,  0.2894],
          [ 0.4426, -0.2891]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 3, 2])
```


attn_mask: 

```python
tensor([[[[False,  True,  True],
          [False, False,  True],
          [False, False, False]],

         [[False,  True,  True],
          [False, False,  True],
          [False, False, False]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 3, 3])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[-0.1173,  0.2182,  0.6397],
          [-0.0312, -0.2382, -0.8987],
          [-0.3157, -0.0151, -0.4519]],

         [[ 0.0768, -0.0820,  0.0901],
          [ 0.0473, -0.0504,  0.0556],
          [ 0.4022, -0.2166,  0.7156]]]], grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 3, 3])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[-1.1728e-01, -1.0000e+09, -1.0000e+09],
          [-3.1171e-02, -2.3817e-01, -1.0000e+09],
          [-3.1574e-01, -1.5129e-02, -4.5195e-01]],

         [[ 7.6782e-02, -1.0000e+09, -1.0000e+09],
          [ 4.7259e-02, -5.0367e-02, -1.0000e+09],
          [ 4.0220e-01, -2.1664e-01,  7.1565e-01]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 3, 3])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[1.0000, 0.0000, 0.0000],
          [0.5516, 0.4484, 0.0000],
          [0.3102, 0.4190, 0.2707]],

         [[1.0000, 0.0000, 0.0000],
          [0.5244, 0.4756, 0.0000],
          [0.3440, 0.1853, 0.4707]]]], grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 3, 3])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.3322,  0.2007],
          [ 0.0640, -0.2045],
          [-0.0172, -0.4282]],

         [[ 0.6469, -0.6036],
          [ 0.0522, -0.1789],
          [ 0.3191, -0.2901]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 3, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[1.0000, 0.0000, 0.0000],
          [0.5516, 0.4484, 0.0000],
          [0.3102, 0.4190, 0.2707]],

         [[1.0000, 0.0000, 0.0000],
          [0.5244, 0.4756, 0.0000],
          [0.3440, 0.1853, 0.4707]]]], grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 3, 3])
```


context: 

```python
tensor([[[[ 0.3322,  0.2007],
          [ 0.0640, -0.2045],
          [-0.0172, -0.4282]],

         [[ 0.6469, -0.6036],
          [ 0.0522, -0.1789],
          [ 0.3191, -0.2901]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 3, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.3322,  0.2007,  0.6469, -0.6036],
         [ 0.0640, -0.2045,  0.0522, -0.1789],
         [-0.0172, -0.4282,  0.3191, -0.2901]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 3, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[-0.2467,  0.2440,  0.0396,  0.5255],
         [ 0.0948, -0.0288, -0.0558,  0.0105],
         [ 0.1684, -0.0547, -0.1158,  0.0875]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 3, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-1.1735,  1.4256, -0.6546,  0.4025],
         [ 1.5564, -0.7186,  0.1771, -1.0148],
         [ 0.6820,  0.8559, -1.6689,  0.1310]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 3, 4])
```


output + residual: 

```python
tensor([[[-1.4202,  1.6696, -0.6150,  0.9280],
         [ 1.6512, -0.7474,  0.1213, -1.0043],
         [ 0.8504,  0.8011, -1.7847,  0.2185]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 3, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-1.2781,  1.2521, -0.6187,  0.6448],
         [ 1.5860, -0.7252,  0.1119, -0.9727],
         [ 0.7735,  0.7275, -1.6848,  0.1839]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 3, 4])
```


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-1.2781,  1.2521, -0.6187,  0.6448],
         [ 1.5860, -0.7252,  0.1119, -0.9727],
         [ 0.7735,  0.7275, -1.6848,  0.1839]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 3, 4])
```


input_K: 

```python
tensor([[[ 0.6868, -1.7263,  0.5829,  0.4565],
         [ 1.6033, -1.1500, -0.2725, -0.1809],
         [ 1.1261, -0.7021, -1.2486,  0.8246],
         [-0.2686, -0.4144, -0.9857,  1.6687],
         [-0.2267, -1.5400,  0.9742,  0.7925]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[ 0.6868, -1.7263,  0.5829,  0.4565],
         [ 1.6033, -1.1500, -0.2725, -0.1809],
         [ 1.1261, -0.7021, -1.2486,  0.8246],
         [-0.2686, -0.4144, -0.9857,  1.6687],
         [-0.2267, -1.5400,  0.9742,  0.7925]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 3, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[-0.0060,  0.4164],
          [ 0.1995, -0.6747],
          [-0.1278, -0.7768]],

         [[-0.0061,  0.2313],
          [-0.0918, -0.4411],
          [-0.3804, -0.9662]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 3, 2])
```


K: 

```python
tensor([[[[ 0.0340,  0.0352],
          [ 0.1903,  0.0466],
          [-0.2709,  0.3840],
          [-0.6189,  0.4860],
          [-0.1048,  0.0250]],

         [[ 0.8016, -0.1494],
          [ 1.0380, -0.4053],
          [ 0.4957,  0.0590],
          [-0.2779,  0.5567],
          [ 0.3398,  0.1011]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 1.0637, -0.5323],
          [ 0.9685, -0.5174],
          [-0.2034, -0.3953],
          [-0.9852, -0.1468],
          [ 0.7337, -0.3573]],

         [[ 0.1639, -0.2189],
          [-0.3600, -0.3702],
          [-0.3778, -0.5270],
          [ 0.0821, -0.3430],
          [ 0.4870, -0.0390]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 3, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[-0.0060,  0.4164],
          [ 0.1995, -0.6747],
          [-0.1278, -0.7768]],

         [[-0.0061,  0.2313],
          [-0.0918, -0.4411],
          [-0.3804, -0.9662]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 3, 2])
```


K: 

```python
tensor([[[[ 0.0340,  0.0352],
          [ 0.1903,  0.0466],
          [-0.2709,  0.3840],
          [-0.6189,  0.4860],
          [-0.1048,  0.0250]],

         [[ 0.8016, -0.1494],
          [ 1.0380, -0.4053],
          [ 0.4957,  0.0590],
          [-0.2779,  0.5567],
          [ 0.3398,  0.1011]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 1.0637, -0.5323],
          [ 0.9685, -0.5174],
          [-0.2034, -0.3953],
          [-0.9852, -0.1468],
          [ 0.7337, -0.3573]],

         [[ 0.1639, -0.2189],
          [-0.3600, -0.3702],
          [-0.3778, -0.5270],
          [ 0.0821, -0.3430],
          [ 0.4870, -0.0390]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 3, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[ 0.0102,  0.0129,  0.1142,  0.1457,  0.0078],
          [-0.0120,  0.0046, -0.2214, -0.3192, -0.0267],
          [-0.0224, -0.0428, -0.1864, -0.2110, -0.0043]],

         [[-0.0279, -0.0708,  0.0075,  0.0922,  0.0151],
          [-0.0054,  0.0591, -0.0506, -0.1556, -0.0536],
          [-0.1135, -0.0022, -0.1736, -0.3056, -0.1605]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 3, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[ 1.0219e-02,  1.2908e-02,  1.1419e-01,  1.4570e-01, -1.0000e+09],
          [-1.2002e-02,  4.6286e-03, -2.2141e-01, -3.1918e-01, -1.0000e+09],
          [-2.2402e-02, -4.2786e-02, -1.8640e-01, -2.1097e-01, -1.0000e+09]],

         [[-2.7881e-02, -7.0761e-02,  7.5097e-03,  9.2248e-02, -1.0000e+09],
          [-5.4384e-03,  5.9055e-02, -5.0570e-02, -1.5561e-01, -1.0000e+09],
          [-1.1355e-01, -2.2499e-03, -1.7362e-01, -3.0561e-01, -1.0000e+09]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 3, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[0.2349, 0.2355, 0.2606, 0.2690, 0.0000],
          [0.2806, 0.2853, 0.2276, 0.2064, 0.0000],
          [0.2735, 0.2680, 0.2321, 0.2265, 0.0000]],

         [[0.2426, 0.2324, 0.2514, 0.2736, 0.0000],
          [0.2575, 0.2747, 0.2462, 0.2216, 0.0000],
          [0.2574, 0.2877, 0.2424, 0.2124, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 3, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.1600, -0.3894],
          [ 0.3252, -0.4173],
          [ 0.2801, -0.4092]],

         [[-0.1164, -0.3655],
          [-0.1315, -0.3638],
          [-0.1355, -0.3635]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 3, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[0.2349, 0.2355, 0.2606, 0.2690, 0.0000],
          [0.2806, 0.2853, 0.2276, 0.2064, 0.0000],
          [0.2735, 0.2680, 0.2321, 0.2265, 0.0000]],

         [[0.2426, 0.2324, 0.2514, 0.2736, 0.0000],
          [0.2575, 0.2747, 0.2462, 0.2216, 0.0000],
          [0.2574, 0.2877, 0.2424, 0.2124, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 3, 5])
```


context: 

```python
tensor([[[[ 0.1600, -0.3894],
          [ 0.3252, -0.4173],
          [ 0.2801, -0.4092]],

         [[-0.1164, -0.3655],
          [-0.1315, -0.3638],
          [-0.1355, -0.3635]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 3, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.1600, -0.3894, -0.1164, -0.3655],
         [ 0.3252, -0.4173, -0.1315, -0.3638],
         [ 0.2801, -0.4092, -0.1355, -0.3635]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 3, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[ 0.1121, -0.0036,  0.0622, -0.1185],
         [ 0.0711,  0.0244,  0.1058, -0.0879],
         [ 0.0858,  0.0182,  0.0919, -0.0968]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 3, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-1.2781,  1.2521, -0.6187,  0.6448],
         [ 1.5860, -0.7252,  0.1119, -0.9727],
         [ 0.7735,  0.7275, -1.6848,  0.1839]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 3, 4])
```


output + residual: 

```python
tensor([[[-1.1660,  1.2485, -0.5565,  0.5263],
         [ 1.6571, -0.7007,  0.2177, -1.0606],
         [ 0.8593,  0.7457, -1.5929,  0.0871]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 3, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-1.2597,  1.3199, -0.6085,  0.5483],
         [ 1.5519, -0.6947,  0.1804, -1.0376],
         [ 0.8520,  0.7361, -1.6517,  0.0636]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 3, 4])
```


## PoswiseFeedForwardNet


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


inputs: 

```python
tensor([[[-1.2597,  1.3199, -0.6085,  0.5483],
         [ 1.5519, -0.6947,  0.1804, -1.0376],
         [ 0.8520,  0.7361, -1.6517,  0.0636]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 3, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc操作的代码</div>


: 

```python
output = self.fc(inputs)
```


inputs: 

```python
tensor([[[-1.2597,  1.3199, -0.6085,  0.5483],
         [ 1.5519, -0.6947,  0.1804, -1.0376],
         [ 0.8520,  0.7361, -1.6517,  0.0636]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 3, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc原来是d_model->d_ff->d_model</div>


self.fc: 

```python
Sequential(
  (0): Linear(in_features=4, out_features=8, bias=False)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=4, bias=False)
)
```


output: 

```python
tensor([[[-0.0407, -0.1932,  0.2528,  0.1463],
         [-0.2417, -0.0686, -0.2907, -0.1350],
         [-0.1535,  0.0538, -0.2170, -0.0581]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 3, 4])
```


## 前馈层后的层归一化和残差


<div style='color:#fe618e;font-weight:800;font-size:23px;'>FeedForward后的层归一化和残差</div>


: 

```python
ans = nn.LayerNorm(d_model).to(device)(output + residual)
```


residual: 

```python
tensor([[[-1.2597,  1.3199, -0.6085,  0.5483],
         [ 1.5519, -0.6947,  0.1804, -1.0376],
         [ 0.8520,  0.7361, -1.6517,  0.0636]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 3, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>残差和层归一化之后的结果</div>


ans: 

```python
tensor([[[-1.4216,  1.1501, -0.4207,  0.6922],
         [ 1.5859, -0.6148,  0.0782, -1.0492],
         [ 0.7413,  0.8268, -1.6608,  0.0928]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans.shape: 

```python
torch.Size([1, 3, 4])
```


# Decoder结束


<div style='color:#fe618e;font-weight:800;font-size:23px;'>model的decode操作</div>


: 

```python
dec_outputs, _, _ = model.decoder(dec_input, enc_input, enc_outputs)
```


dec_outputs: 

```python
tensor([[[-1.4216,  1.1501, -0.4207,  0.6922],
         [ 1.5859, -0.6148,  0.0782, -1.0492],
         [ 0.7413,  0.8268, -1.6608,  0.0928]]],
       grad_fn=<NativeLayerNormBackward0>)
```


dec_outputs.shape: 

```python
torch.Size([1, 3, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>model的projection操作</div>


: 

```python
projected = model.projection(dec_outputs)
```


projected: 

```python
tensor([[[-0.1239,  3.5437, -3.4073,  0.8738, -0.2378, -1.3745, -0.8337],
         [ 0.0392, -3.0964,  4.2367,  0.5962,  0.1112,  0.0266, -0.6191],
         [-0.2163,  0.5834,  1.4033,  4.4136, -0.5882, -4.4854, -1.0458]]],
       grad_fn=<UnsafeViewBackward0>)
```


projected.shape: 

```python
torch.Size([1, 3, 7])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>生成prob</div>


: 

```python
prob = projected.squeeze(0).max(dim=-1, keepdim=False)[1]
```


prob: 

```python
tensor([1, 2, 3])
```


prob.shape: 

```python
torch.Size([3])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>生成next_word</div>


: 

```python
next_word = prob.data[-1]
```


next_word: 

```python
tensor(3)
```


next_word.shape: 

```python
torch.Size([])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>迭代下一轮</div>


: 

```python
next_symbol = next_word
```


next_symbol: 

```python
tensor(3)
```


# 预测这句话第【4】个单词：


<div style='color:#fe618e;font-weight:800;font-size:23px;'>生成dec_input</div>


: 

```python
dec_input = torch.cat([dec_input.to(device), torch.tensor([[next_symbol]], dtype=enc_input.dtype).to(device)],-1)
```


dec_input: 

```python
tensor([[4, 1, 2, 3]])
```


dec_input.shape: 

```python
torch.Size([1, 4])
```


# Decoder中


<div style='color:#3296ee;font-weight:800;font-size:23px;'>dec_inputs转换为词向量的结果</div>


: 

```python
dec_outputs = self.tgt_emb(dec_inputs)
```


dec_outputs: 

```python
tensor([[[-1.0398,  1.3073, -0.2711, -0.4491],
         [ 1.2834, -0.4243,  0.4540, -1.6032],
         [ 0.1516,  1.9322, -0.6804, -0.9484],
         [-0.2245,  0.3270, -0.5733, -0.1797]]], grad_fn=<EmbeddingBackward0>)
```


dec_outputs.shape: 

```python
torch.Size([1, 4, 4])
```


## PositionalEncoding


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入加上位置编码的代码</div>


加上位置编码: 

```python
x = x + self.pe[:x.size(0), :]
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


x: 

```python
tensor([[[-1.0398,  1.3073, -0.2711, -0.4491]],

        [[ 1.2834, -0.4243,  0.4540, -1.6032]],

        [[ 0.1516,  1.9322, -0.6804, -0.9484]],

        [[-0.2245,  0.3270, -0.5733, -0.1797]]], grad_fn=<TransposeBackward0>)
```


x.shape: 

```python
torch.Size([4, 1, 4])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>位置编码</div>


self.pe[:x.size(0), :]: 

```python
tensor([[[ 0.0000,  1.0000,  0.0000,  1.0000]],

        [[ 0.8415,  0.5403,  0.0100,  0.9999]],

        [[ 0.9093, -0.4161,  0.0200,  0.9998]],

        [[ 0.1411, -0.9900,  0.0300,  0.9996]]])
```


self.pe[:x.size(0), :].shape: 

```python
torch.Size([4, 1, 4])
```


self.pe.shape: 

```python
torch.Size([5000, 1, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


x: 

```python
tensor([[[-1.0398,  2.3073, -0.2711,  0.5509]],

        [[ 2.1248,  0.1160,  0.4640, -0.6032]],

        [[ 1.0609,  1.5160, -0.6604,  0.0514]],

        [[-0.0834, -0.6630, -0.5433,  0.8198]]], grad_fn=<AddBackward0>)
```


x.shape: 

```python
torch.Size([4, 1, 4])
```


## decoder的self_attn的pad_mask


## get_attn_pad_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq_q: 

```python
tensor([[4, 1, 2, 3]])
```


seq_q.shape: 

```python
torch.Size([1, 4])
```


seq_k: 

```python
tensor([[4, 1, 2, 3]])
```


seq_k.shape: 

```python
torch.Size([1, 4])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>获取对应的大小：len_q,len_k</div>


例如: 

```python
batch_size, len_q = seq_q.size()
```


batch_size: 

```python
1
```


len_q: 

```python
4
```


len_k: 

```python
4
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>操作pad_attn_mask矩阵：pad_attn_mask</div>


: 

```python
pad_attn_mask = seq_k.data.eq(0).unsqueeze(1) 
```


pad_attn_mask: 

```python
tensor([[[False, False, False, False]]])
```


pad_attn_mask.shape: 

```python
torch.Size([1, 1, 4])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>扩展pad_attn_mask矩阵：pad_attn_mask.expand</div>


: 

```python
ans = pad_attn_mask.expand(batch_size, len_q, len_k)  
```


ans: 

```python
tensor([[[False, False, False, False],
         [False, False, False, False],
         [False, False, False, False],
         [False, False, False, False]]])
```


ans.shape: 

```python
torch.Size([1, 4, 4])
```


## get_attn_subsequence_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq: 

```python
tensor([[4, 1, 2, 3]])
```


seq.shape: 

```python
torch.Size([1, 4])
```


<div style='color:#19ce8b;font-weight:800;font-size:23px;'>求attn_shape</div>


: 

```python
attn_shape = [seq.size(0), seq.size(1), seq.size(1)]
```


attn_shape: 

```python
[1, 4, 4]
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>生成一个上三角矩阵</div>


: 

```python
subsequence_mask = np.triu(np.ones(attn_shape), k=1)
```


subsequence_mask: 

```python
[[[0. 1. 1. 1.]
  [0. 0. 1. 1.]
  [0. 0. 0. 1.]
  [0. 0. 0. 0.]]]
```


subsequence_mask.shape: 

```python
(1, 4, 4)
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>生成subsequence_mask</div>


: 

```python
subsequence_mask = torch.from_numpy(subsequence_mask).byte()
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


subsequence_mask: 

```python
tensor([[[0, 1, 1, 1],
         [0, 0, 1, 1],
         [0, 0, 0, 1],
         [0, 0, 0, 0]]], dtype=torch.uint8)
```


subsequence_mask.shape: 

```python
torch.Size([1, 4, 4])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>两个mask相加</div>


: 

```python
dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequence_mask),0).to(device)
```


dec_self_attn_pad_mask: 

```python
tensor([[[False, False, False, False],
         [False, False, False, False],
         [False, False, False, False],
         [False, False, False, False]]])
```


dec_self_attn_pad_mask.shape: 

```python
torch.Size([1, 4, 4])
```


dec_self_attn_subsequence_mask: 

```python
tensor([[[0, 1, 1, 1],
         [0, 0, 1, 1],
         [0, 0, 0, 1],
         [0, 0, 0, 0]]], dtype=torch.uint8)
```


dec_self_attn_subsequence_mask.shape: 

```python
torch.Size([1, 4, 4])
```


dec_self_attn_mask: 

```python
tensor([[[False,  True,  True,  True],
         [False, False,  True,  True],
         [False, False, False,  True],
         [False, False, False, False]]])
```


dec_self_attn_mask.shape: 

```python
torch.Size([1, 4, 4])
```


## 交互注意力层中的pad_mask


## get_attn_pad_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq_q: 

```python
tensor([[4, 1, 2, 3]])
```


seq_q.shape: 

```python
torch.Size([1, 4])
```


seq_k: 

```python
tensor([[4, 1, 2, 3]])
```


seq_k.shape: 

```python
torch.Size([1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>获取对应的大小：len_q,len_k</div>


例如: 

```python
batch_size, len_q = seq_q.size()
```


batch_size: 

```python
1
```


len_q: 

```python
4
```


len_k: 

```python
5
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>操作pad_attn_mask矩阵：pad_attn_mask</div>


: 

```python
pad_attn_mask = seq_k.data.eq(0).unsqueeze(1) 
```


pad_attn_mask: 

```python
tensor([[[False, False, False, False,  True]]])
```


pad_attn_mask.shape: 

```python
torch.Size([1, 1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>扩展pad_attn_mask矩阵：pad_attn_mask.expand</div>


: 

```python
ans = pad_attn_mask.expand(batch_size, len_q, len_k)  
```


ans: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


ans.shape: 

```python
torch.Size([1, 4, 5])
```


# DecoderLayer


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-0.0000,  2.5637, -0.3013,  0.6121],
         [ 2.3609,  0.1289,  0.5155, -0.6703],
         [ 1.1788,  0.0000, -0.0000,  0.0572],
         [-0.0927, -0.7367, -0.6036,  0.9109]]], grad_fn=<TransposeBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 4, 4])
```


input_K: 

```python
tensor([[[-0.0000,  2.5637, -0.3013,  0.6121],
         [ 2.3609,  0.1289,  0.5155, -0.6703],
         [ 1.1788,  0.0000, -0.0000,  0.0572],
         [-0.0927, -0.7367, -0.6036,  0.9109]]], grad_fn=<TransposeBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 4, 4])
```


input_V: 

```python
tensor([[[-0.0000,  2.5637, -0.3013,  0.6121],
         [ 2.3609,  0.1289,  0.5155, -0.6703],
         [ 1.1788,  0.0000, -0.0000,  0.0572],
         [-0.0927, -0.7367, -0.6036,  0.9109]]], grad_fn=<TransposeBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 4, 4])
```


attn_mask: 

```python
tensor([[[False,  True,  True,  True],
         [False, False,  True,  True],
         [False, False, False,  True],
         [False, False, False, False]]])
```


attn_mask.shape: 

```python
torch.Size([1, 4, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 0.8690, -0.2589],
          [-0.2406, -0.5678],
          [-0.0437, -0.1849],
          [ 0.0236,  0.3265]],

         [[-1.0022, -0.8012],
          [ 0.6229,  0.6148],
          [ 0.2064,  0.5636],
          [-0.0770,  0.8109]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 4, 2])
```


K: 

```python
tensor([[[[-0.1247, -0.7554],
          [ 0.6511, -0.1221],
          [ 0.4456,  0.1217],
          [ 0.3109,  0.6422]],

         [[-1.1388, -0.3664],
          [ 0.1760, -0.4867],
          [ 0.1308, -0.3303],
          [ 0.3487, -0.1223]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 4, 2])
```


V: 

```python
tensor([[[[ 0.8710,  0.6383],
          [ 0.8156, -0.9357],
          [ 0.2102, -0.4823],
          [-0.7317, -0.1465]],

         [[-0.8069,  0.8370],
          [-0.8736, -0.3561],
          [-0.4850,  0.1074],
          [ 0.0873,  0.5617]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 4, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False,  True,  True,  True],
          [False, False,  True,  True],
          [False, False, False,  True],
          [False, False, False, False]],

         [[False,  True,  True,  True],
          [False, False,  True,  True],
          [False, False, False,  True],
          [False, False, False, False]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 4, 4])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 0.8690, -0.2589],
          [-0.2406, -0.5678],
          [-0.0437, -0.1849],
          [ 0.0236,  0.3265]],

         [[-1.0022, -0.8012],
          [ 0.6229,  0.6148],
          [ 0.2064,  0.5636],
          [-0.0770,  0.8109]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 4, 2])
```


K: 

```python
tensor([[[[-0.1247, -0.7554],
          [ 0.6511, -0.1221],
          [ 0.4456,  0.1217],
          [ 0.3109,  0.6422]],

         [[-1.1388, -0.3664],
          [ 0.1760, -0.4867],
          [ 0.1308, -0.3303],
          [ 0.3487, -0.1223]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 4, 2])
```


V: 

```python
tensor([[[[ 0.8710,  0.6383],
          [ 0.8156, -0.9357],
          [ 0.2102, -0.4823],
          [-0.7317, -0.1465]],

         [[-0.8069,  0.8370],
          [-0.8736, -0.3561],
          [-0.4850,  0.1074],
          [ 0.0873,  0.5617]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 4, 2])
```


attn_mask: 

```python
tensor([[[[False,  True,  True,  True],
          [False, False,  True,  True],
          [False, False, False,  True],
          [False, False, False, False]],

         [[False,  True,  True,  True],
          [False, False,  True,  True],
          [False, False, False,  True],
          [False, False, False, False]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 4, 4])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[ 0.0617,  0.4224,  0.2515,  0.0735],
          [ 0.3245, -0.0618, -0.1247, -0.3108],
          [ 0.1026, -0.0042, -0.0297, -0.0936],
          [-0.1765, -0.0173,  0.0355,  0.1535]],

         [[ 1.0146,  0.1510,  0.0944, -0.1778],
          [-0.6609, -0.1341, -0.0860,  0.1004],
          [-0.3122, -0.1683, -0.1125,  0.0022],
          [-0.1481, -0.2887, -0.1965, -0.0891]]]], grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 4, 4])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[ 6.1684e-02, -1.0000e+09, -1.0000e+09, -1.0000e+09],
          [ 3.2450e-01, -6.1765e-02, -1.0000e+09, -1.0000e+09],
          [ 1.0263e-01, -4.1685e-03, -2.9694e-02, -1.0000e+09],
          [-1.7646e-01, -1.7302e-02,  3.5546e-02,  1.5345e-01]],

         [[ 1.0146e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09],
          [-6.6091e-01, -1.3408e-01, -1.0000e+09, -1.0000e+09],
          [-3.1225e-01, -1.6827e-01, -1.1253e-01, -1.0000e+09],
          [-1.4815e-01, -2.8866e-01, -1.9652e-01, -8.9103e-02]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 4, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],
          [0.5954, 0.4046, 0.0000, 0.0000],
          [0.3604, 0.3239, 0.3157, 0.0000],
          [0.2084, 0.2443, 0.2576, 0.2898]],

         [[1.0000, 0.0000, 0.0000, 0.0000],
          [0.3713, 0.6287, 0.0000, 0.0000],
          [0.2962, 0.3421, 0.3617, 0.0000],
          [0.2576, 0.2238, 0.2454, 0.2732]]]], grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 4, 4])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.8710,  0.6383],
          [ 0.8486,  0.0014],
          [ 0.6444, -0.2253],
          [ 0.2228, -0.2623]],

         [[-0.8069,  0.8370],
          [-0.8489,  0.0868],
          [-0.7133,  0.1649],
          [-0.4985,  0.3157]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 4, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],
          [0.5954, 0.4046, 0.0000, 0.0000],
          [0.3604, 0.3239, 0.3157, 0.0000],
          [0.2084, 0.2443, 0.2576, 0.2898]],

         [[1.0000, 0.0000, 0.0000, 0.0000],
          [0.3713, 0.6287, 0.0000, 0.0000],
          [0.2962, 0.3421, 0.3617, 0.0000],
          [0.2576, 0.2238, 0.2454, 0.2732]]]], grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 4, 4])
```


context: 

```python
tensor([[[[ 0.8710,  0.6383],
          [ 0.8486,  0.0014],
          [ 0.6444, -0.2253],
          [ 0.2228, -0.2623]],

         [[-0.8069,  0.8370],
          [-0.8489,  0.0868],
          [-0.7133,  0.1649],
          [-0.4985,  0.3157]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 4, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.8710,  0.6383, -0.8069,  0.8370],
         [ 0.8486,  0.0014, -0.8489,  0.0868],
         [ 0.6444, -0.2253, -0.7133,  0.1649],
         [ 0.2228, -0.2623, -0.4985,  0.3157]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 4, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[ 0.6138,  0.2324, -0.1685,  0.9687],
         [ 0.4355,  0.0865,  0.0875,  0.8211],
         [ 0.2504,  0.1000,  0.0717,  0.7796],
         [ 0.0175,  0.1244,  0.0222,  0.5945]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 4, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-0.0000,  2.5637, -0.3013,  0.6121],
         [ 2.3609,  0.1289,  0.5155, -0.6703],
         [ 1.1788,  0.0000, -0.0000,  0.0572],
         [-0.0927, -0.7367, -0.6036,  0.9109]]], grad_fn=<TransposeBackward0>)
```


residual.shape: 

```python
torch.Size([1, 4, 4])
```


output + residual: 

```python
tensor([[[ 0.6138,  2.7960, -0.4698,  1.5808],
         [ 2.7964,  0.2153,  0.6031,  0.1509],
         [ 1.4292,  0.1000,  0.0717,  0.8368],
         [-0.0751, -0.6123, -0.5814,  1.5055]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 4, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-0.4287,  1.3828, -1.3282,  0.3740],
         [ 1.7099, -0.6693, -0.3119, -0.7287],
         [ 1.4535, -0.9033, -0.9533,  0.4031],
         [-0.1558, -0.7791, -0.7433,  1.6782]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 4, 4])
```


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-0.4287,  1.3828, -1.3282,  0.3740],
         [ 1.7099, -0.6693, -0.3119, -0.7287],
         [ 1.4535, -0.9033, -0.9533,  0.4031],
         [-0.1558, -0.7791, -0.7433,  1.6782]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 4, 4])
```


input_K: 

```python
tensor([[[ 0.6868, -1.7263,  0.5829,  0.4565],
         [ 1.6033, -1.1500, -0.2725, -0.1809],
         [ 1.1261, -0.7021, -1.2486,  0.8246],
         [-0.2686, -0.4144, -0.9857,  1.6687],
         [-0.2267, -1.5400,  0.9742,  0.7925]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[ 0.6868, -1.7263,  0.5829,  0.4565],
         [ 1.6033, -1.1500, -0.2725, -0.1809],
         [ 1.1261, -0.7021, -1.2486,  0.8246],
         [-0.2686, -0.4144, -0.9857,  1.6687],
         [-0.2267, -1.5400,  0.9742,  0.7925]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 4, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 0.9212,  0.5570],
          [-1.0056,  0.8384],
          [-0.5918,  0.4136],
          [ 0.3543, -0.7495]],

         [[-0.7378,  0.1759],
          [ 0.3028,  0.0299],
          [ 0.2580, -0.2217],
          [ 0.1355, -0.4484]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 4, 2])
```


K: 

```python
tensor([[[[ 0.2876,  0.7402],
          [ 0.4966,  0.3560],
          [ 0.5376,  0.3952],
          [ 0.2229,  0.4991],
          [ 0.0389,  0.7666]],

         [[ 0.4759,  0.6528],
          [-0.5556, -0.0237],
          [-0.3791, -0.1074],
          [ 0.5440,  0.2833],
          [ 1.0660,  0.9173]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.9145,  0.2993],
          [ 0.9688, -0.2155],
          [-0.1428, -0.3849],
          [-0.9931, -0.0470],
          [ 0.5290,  0.5650]],

         [[ 0.1975,  0.7515],
          [ 0.3600,  0.7951],
          [-0.1420,  0.8862],
          [-0.5786,  0.5694],
          [-0.0029,  0.4654]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 4, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 0.9212,  0.5570],
          [-1.0056,  0.8384],
          [-0.5918,  0.4136],
          [ 0.3543, -0.7495]],

         [[-0.7378,  0.1759],
          [ 0.3028,  0.0299],
          [ 0.2580, -0.2217],
          [ 0.1355, -0.4484]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 4, 2])
```


K: 

```python
tensor([[[[ 0.2876,  0.7402],
          [ 0.4966,  0.3560],
          [ 0.5376,  0.3952],
          [ 0.2229,  0.4991],
          [ 0.0389,  0.7666]],

         [[ 0.4759,  0.6528],
          [-0.5556, -0.0237],
          [-0.3791, -0.1074],
          [ 0.5440,  0.2833],
          [ 1.0660,  0.9173]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.9145,  0.2993],
          [ 0.9688, -0.2155],
          [-0.1428, -0.3849],
          [-0.9931, -0.0470],
          [ 0.5290,  0.5650]],

         [[ 0.1975,  0.7515],
          [ 0.3600,  0.7951],
          [-0.1420,  0.8862],
          [-0.5786,  0.5694],
          [-0.0029,  0.4654]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 4, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[ 0.4789,  0.4637,  0.5059,  0.3418,  0.3273],
          [ 0.2343, -0.1421, -0.1480,  0.1374,  0.4268],
          [ 0.0962, -0.1037, -0.1094,  0.0527,  0.2080],
          [-0.3202, -0.0642, -0.0747, -0.2087, -0.3965]],

         [[-0.1671,  0.2869,  0.1844, -0.2486, -0.4420],
          [ 0.1157, -0.1195, -0.0834,  0.1225,  0.2476],
          [-0.0155, -0.0976, -0.0523,  0.0548,  0.0507],
          [-0.1614, -0.0458, -0.0023, -0.0377, -0.1887]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 4, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[ 4.7885e-01,  4.6373e-01,  5.0588e-01,  3.4177e-01, -1.0000e+09],
          [ 2.3433e-01, -1.4210e-01, -1.4802e-01,  1.3741e-01, -1.0000e+09],
          [ 9.6164e-02, -1.0370e-01, -1.0939e-01,  5.2722e-02, -1.0000e+09],
          [-3.2021e-01, -6.4226e-02, -7.4719e-02, -2.0866e-01, -1.0000e+09]],

         [[-1.6708e-01,  2.8691e-01,  1.8443e-01, -2.4858e-01, -1.0000e+09],
          [ 1.1569e-01, -1.1946e-01, -8.3442e-02,  1.2247e-01, -1.0000e+09],
          [-1.5499e-02, -9.7647e-02, -5.2328e-02,  5.4847e-02, -1.0000e+09],
          [-1.6137e-01, -4.5751e-02, -2.2864e-03, -3.7666e-02, -1.0000e+09]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 4, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[0.2574, 0.2536, 0.2645, 0.2245, 0.0000],
          [0.3052, 0.2095, 0.2082, 0.2770, 0.0000],
          [0.2785, 0.2281, 0.2268, 0.2667, 0.0000],
          [0.2133, 0.2755, 0.2727, 0.2385, 0.0000]],

         [[0.2034, 0.3202, 0.2890, 0.1874, 0.0000],
          [0.2765, 0.2186, 0.2266, 0.2784, 0.0000],
          [0.2527, 0.2327, 0.2435, 0.2711, 0.0000],
          [0.2259, 0.2536, 0.2649, 0.2556, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 4, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.2204, -0.0899],
          [ 0.1772, -0.0469],
          [ 0.1784, -0.0656],
          [ 0.1863, -0.1117]],

         [[ 0.0060,  0.7702],
          [-0.0599,  0.7408],
          [-0.0577,  0.7451],
          [-0.0496,  0.7517]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 4, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[0.2574, 0.2536, 0.2645, 0.2245, 0.0000],
          [0.3052, 0.2095, 0.2082, 0.2770, 0.0000],
          [0.2785, 0.2281, 0.2268, 0.2667, 0.0000],
          [0.2133, 0.2755, 0.2727, 0.2385, 0.0000]],

         [[0.2034, 0.3202, 0.2890, 0.1874, 0.0000],
          [0.2765, 0.2186, 0.2266, 0.2784, 0.0000],
          [0.2527, 0.2327, 0.2435, 0.2711, 0.0000],
          [0.2259, 0.2536, 0.2649, 0.2556, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 4, 5])
```


context: 

```python
tensor([[[[ 0.2204, -0.0899],
          [ 0.1772, -0.0469],
          [ 0.1784, -0.0656],
          [ 0.1863, -0.1117]],

         [[ 0.0060,  0.7702],
          [-0.0599,  0.7408],
          [-0.0577,  0.7451],
          [-0.0496,  0.7517]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 4, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.2204, -0.0899,  0.0060,  0.7702],
         [ 0.1772, -0.0469, -0.0599,  0.7408],
         [ 0.1784, -0.0656, -0.0577,  0.7451],
         [ 0.1863, -0.1117, -0.0496,  0.7517]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 4, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[-0.3010, -0.2249,  0.3865, -0.2513],
         [-0.2968, -0.1894,  0.4031, -0.2556],
         [-0.3039, -0.1925,  0.4090, -0.2528],
         [-0.3183, -0.2000,  0.4182, -0.2455]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 4, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-0.4287,  1.3828, -1.3282,  0.3740],
         [ 1.7099, -0.6693, -0.3119, -0.7287],
         [ 1.4535, -0.9033, -0.9533,  0.4031],
         [-0.1558, -0.7791, -0.7433,  1.6782]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 4, 4])
```


output + residual: 

```python
tensor([[[-0.7296,  1.1580, -0.9417,  0.1227],
         [ 1.4131, -0.8587,  0.0912, -0.9843],
         [ 1.1496, -1.0957, -0.5444,  0.1503],
         [-0.4741, -0.9791, -0.3251,  1.4327]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 4, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-0.7640,  1.5179, -1.0204,  0.2664],
         [ 1.5609, -0.8066,  0.1833, -0.9376],
         [ 1.4725, -1.2054, -0.5478,  0.2807],
         [-0.4261, -0.9811, -0.2623,  1.6695]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 4, 4])
```


## PoswiseFeedForwardNet


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


inputs: 

```python
tensor([[[-0.7640,  1.5179, -1.0204,  0.2664],
         [ 1.5609, -0.8066,  0.1833, -0.9376],
         [ 1.4725, -1.2054, -0.5478,  0.2807],
         [-0.4261, -0.9811, -0.2623,  1.6695]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 4, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc操作的代码</div>


: 

```python
output = self.fc(inputs)
```


inputs: 

```python
tensor([[[-0.7640,  1.5179, -1.0204,  0.2664],
         [ 1.5609, -0.8066,  0.1833, -0.9376],
         [ 1.4725, -1.2054, -0.5478,  0.2807],
         [-0.4261, -0.9811, -0.2623,  1.6695]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 4, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc原来是d_model->d_ff->d_model</div>


self.fc: 

```python
Sequential(
  (0): Linear(in_features=4, out_features=8, bias=False)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=4, bias=False)
)
```


output: 

```python
tensor([[[ 0.0586, -0.2144, -0.2289,  0.2034],
         [ 0.0273, -0.0057, -0.0656,  0.0734],
         [-0.0693, -0.2689, -0.2535,  0.4377],
         [ 0.0171, -0.4217, -0.1075,  0.4529]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 4, 4])
```


## 前馈层后的层归一化和残差


<div style='color:#fe618e;font-weight:800;font-size:23px;'>FeedForward后的层归一化和残差</div>


: 

```python
ans = nn.LayerNorm(d_model).to(device)(output + residual)
```


residual: 

```python
tensor([[[-0.7640,  1.5179, -1.0204,  0.2664],
         [ 1.5609, -0.8066,  0.1833, -0.9376],
         [ 1.4725, -1.2054, -0.5478,  0.2807],
         [-0.4261, -0.9811, -0.2623,  1.6695]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 4, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>残差和层归一化之后的结果</div>


ans: 

```python
tensor([[[-0.6626,  1.3539, -1.2085,  0.5171],
         [ 1.5923, -0.8256,  0.1111, -0.8778],
         [ 1.2531, -1.2479, -0.6630,  0.6579],
         [-0.3029, -1.0664, -0.2728,  1.6421]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans.shape: 

```python
torch.Size([1, 4, 4])
```


# DecoderLayer


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-0.6626,  1.3539, -1.2085,  0.5171],
         [ 1.5923, -0.8256,  0.1111, -0.8778],
         [ 1.2531, -1.2479, -0.6630,  0.6579],
         [-0.3029, -1.0664, -0.2728,  1.6421]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 4, 4])
```


input_K: 

```python
tensor([[[-0.6626,  1.3539, -1.2085,  0.5171],
         [ 1.5923, -0.8256,  0.1111, -0.8778],
         [ 1.2531, -1.2479, -0.6630,  0.6579],
         [-0.3029, -1.0664, -0.2728,  1.6421]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 4, 4])
```


input_V: 

```python
tensor([[[-0.6626,  1.3539, -1.2085,  0.5171],
         [ 1.5923, -0.8256,  0.1111, -0.8778],
         [ 1.2531, -1.2479, -0.6630,  0.6579],
         [-0.3029, -1.0664, -0.2728,  1.6421]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 4, 4])
```


attn_mask: 

```python
tensor([[[False,  True,  True,  True],
         [False, False,  True,  True],
         [False, False, False,  True],
         [False, False, False, False]]])
```


attn_mask.shape: 

```python
torch.Size([1, 4, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[-0.2694,  1.0717],
          [-0.4741, -0.9461],
          [-0.4161, -0.6411],
          [ 0.2871, -0.0589]],

         [[ 0.4726, -0.3178],
          [ 0.1603, -0.0800],
          [-0.4176, -0.6205],
          [-0.9423, -0.4423]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 4, 2])
```


K: 

```python
tensor([[[[ 0.7898,  0.2129],
          [ 0.1835,  0.3390],
          [ 0.1618,  0.8625],
          [-0.4722,  0.4355]],

         [[ 0.3101, -1.0616],
          [-0.2636,  0.1458],
          [ 0.1384, -0.3185],
          [ 0.3432,  0.0013]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 4, 2])
```


V: 

```python
tensor([[[[ 0.2251, -0.0811],
          [-0.2960, -0.6830],
          [-0.4171, -0.2928],
          [-0.2099,  0.6050]],

         [[ 0.7054, -0.5341],
          [-0.5842,  0.3466],
          [-0.1165,  0.6325],
          [ 0.2628,  0.5548]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 4, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False,  True,  True,  True],
          [False, False,  True,  True],
          [False, False, False,  True],
          [False, False, False, False]],

         [[False,  True,  True,  True],
          [False, False,  True,  True],
          [False, False, False,  True],
          [False, False, False, False]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 4, 4])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[-0.2694,  1.0717],
          [-0.4741, -0.9461],
          [-0.4161, -0.6411],
          [ 0.2871, -0.0589]],

         [[ 0.4726, -0.3178],
          [ 0.1603, -0.0800],
          [-0.4176, -0.6205],
          [-0.9423, -0.4423]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 4, 2])
```


K: 

```python
tensor([[[[ 0.7898,  0.2129],
          [ 0.1835,  0.3390],
          [ 0.1618,  0.8625],
          [-0.4722,  0.4355]],

         [[ 0.3101, -1.0616],
          [-0.2636,  0.1458],
          [ 0.1384, -0.3185],
          [ 0.3432,  0.0013]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 4, 2])
```


V: 

```python
tensor([[[[ 0.2251, -0.0811],
          [-0.2960, -0.6830],
          [-0.4171, -0.2928],
          [-0.2099,  0.6050]],

         [[ 0.7054, -0.5341],
          [-0.5842,  0.3466],
          [-0.1165,  0.6325],
          [ 0.2628,  0.5548]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 4, 2])
```


attn_mask: 

```python
tensor([[[[False,  True,  True,  True],
          [False, False,  True,  True],
          [False, False, False,  True],
          [False, False, False, False]],

         [[False,  True,  True,  True],
          [False, False,  True,  True],
          [False, False, False,  True],
          [False, False, False, False]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 4, 4])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[ 0.0109,  0.2219,  0.6228,  0.4200],
          [-0.4072, -0.2883, -0.6312, -0.1330],
          [-0.3289, -0.2076, -0.4386, -0.0585],
          [ 0.1515,  0.0231, -0.0030, -0.1140]],

         [[ 0.3421, -0.1209,  0.1178,  0.1144],
          [ 0.0952, -0.0381,  0.0337,  0.0388],
          [ 0.3742,  0.0139,  0.0989, -0.1019],
          [ 0.1254,  0.1301,  0.0074, -0.2291]]]], grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 4, 4])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[ 1.0907e-02, -1.0000e+09, -1.0000e+09, -1.0000e+09],
          [-4.0722e-01, -2.8828e-01, -1.0000e+09, -1.0000e+09],
          [-3.2889e-01, -2.0765e-01, -4.3859e-01, -1.0000e+09],
          [ 1.5148e-01,  2.3135e-02, -3.0420e-03, -1.1399e-01]],

         [[ 3.4214e-01, -1.0000e+09, -1.0000e+09, -1.0000e+09],
          [ 9.5203e-02, -3.8129e-02, -1.0000e+09, -1.0000e+09],
          [ 3.7422e-01,  1.3872e-02,  9.8854e-02, -1.0000e+09],
          [ 1.2543e-01,  1.3006e-01,  7.3621e-03, -2.2911e-01]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 4, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],
          [0.4703, 0.5297, 0.0000, 0.0000],
          [0.3306, 0.3732, 0.2962, 0.0000],
          [0.2855, 0.2511, 0.2446, 0.2189]],

         [[1.0000, 0.0000, 0.0000, 0.0000],
          [0.5333, 0.4667, 0.0000, 0.0000],
          [0.4070, 0.2839, 0.3091, 0.0000],
          [0.2782, 0.2795, 0.2472, 0.1951]]]], grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 4, 4])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.2251, -0.0811],
          [-0.0509, -0.4000],
          [-0.1596, -0.3685],
          [-0.1580, -0.1338]],

         [[ 0.7054, -0.5341],
          [ 0.1035, -0.1231],
          [ 0.0853,  0.0765],
          [ 0.0554,  0.2129]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 4, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],
          [0.4703, 0.5297, 0.0000, 0.0000],
          [0.3306, 0.3732, 0.2962, 0.0000],
          [0.2855, 0.2511, 0.2446, 0.2189]],

         [[1.0000, 0.0000, 0.0000, 0.0000],
          [0.5333, 0.4667, 0.0000, 0.0000],
          [0.4070, 0.2839, 0.3091, 0.0000],
          [0.2782, 0.2795, 0.2472, 0.1951]]]], grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 4, 4])
```


context: 

```python
tensor([[[[ 0.2251, -0.0811],
          [-0.0509, -0.4000],
          [-0.1596, -0.3685],
          [-0.1580, -0.1338]],

         [[ 0.7054, -0.5341],
          [ 0.1035, -0.1231],
          [ 0.0853,  0.0765],
          [ 0.0554,  0.2129]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 4, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.2251, -0.0811,  0.7054, -0.5341],
         [-0.0509, -0.4000,  0.1035, -0.1231],
         [-0.1596, -0.3685,  0.0853,  0.0765],
         [-0.1580, -0.1338,  0.0554,  0.2129]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 4, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[-0.1149,  0.1599, -0.0084,  0.4247],
         [ 0.1924, -0.0945, -0.0994, -0.0504],
         [ 0.1773, -0.1130, -0.0729, -0.1174],
         [ 0.0531, -0.0576, -0.0005, -0.1019]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 4, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-0.6626,  1.3539, -1.2085,  0.5171],
         [ 1.5923, -0.8256,  0.1111, -0.8778],
         [ 1.2531, -1.2479, -0.6630,  0.6579],
         [-0.3029, -1.0664, -0.2728,  1.6421]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 4, 4])
```


output + residual: 

```python
tensor([[[-0.7775,  1.5138, -1.2169,  0.9418],
         [ 1.7847, -0.9201,  0.0117, -0.9282],
         [ 1.4304, -1.3610, -0.7360,  0.5405],
         [-0.2499, -1.1240, -0.2733,  1.5402]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 4, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-0.7822,  1.2253, -1.1672,  0.7241],
         [ 1.6254, -0.8202,  0.0223, -0.8275],
         [ 1.3446, -1.2228, -0.6480,  0.5261],
         [-0.2298, -1.1303, -0.2539,  1.6140]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 4, 4])
```


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-0.7822,  1.2253, -1.1672,  0.7241],
         [ 1.6254, -0.8202,  0.0223, -0.8275],
         [ 1.3446, -1.2228, -0.6480,  0.5261],
         [-0.2298, -1.1303, -0.2539,  1.6140]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 4, 4])
```


input_K: 

```python
tensor([[[ 0.6868, -1.7263,  0.5829,  0.4565],
         [ 1.6033, -1.1500, -0.2725, -0.1809],
         [ 1.1261, -0.7021, -1.2486,  0.8246],
         [-0.2686, -0.4144, -0.9857,  1.6687],
         [-0.2267, -1.5400,  0.9742,  0.7925]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[ 0.6868, -1.7263,  0.5829,  0.4565],
         [ 1.6033, -1.1500, -0.2725, -0.1809],
         [ 1.1261, -0.7021, -1.2486,  0.8246],
         [-0.2686, -0.4144, -0.9857,  1.6687],
         [-0.2267, -1.5400,  0.9742,  0.7925]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 4, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[-0.1262,  0.0510],
          [ 0.1041, -0.7187],
          [-0.6311, -0.7906],
          [-0.9700,  0.0012]],

         [[-0.1579, -0.2085],
          [-0.1206, -0.5332],
          [-0.2903, -1.0229],
          [-0.1220, -0.4631]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 4, 2])
```


K: 

```python
tensor([[[[ 0.0340,  0.0352],
          [ 0.1903,  0.0466],
          [-0.2709,  0.3840],
          [-0.6189,  0.4860],
          [-0.1048,  0.0250]],

         [[ 0.8016, -0.1494],
          [ 1.0380, -0.4053],
          [ 0.4957,  0.0590],
          [-0.2779,  0.5567],
          [ 0.3398,  0.1011]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 1.0637, -0.5323],
          [ 0.9685, -0.5174],
          [-0.2034, -0.3953],
          [-0.9852, -0.1468],
          [ 0.7337, -0.3573]],

         [[ 0.1639, -0.2189],
          [-0.3600, -0.3702],
          [-0.3778, -0.5270],
          [ 0.0821, -0.3430],
          [ 0.4870, -0.0390]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 4, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[-0.1262,  0.0510],
          [ 0.1041, -0.7187],
          [-0.6311, -0.7906],
          [-0.9700,  0.0012]],

         [[-0.1579, -0.2085],
          [-0.1206, -0.5332],
          [-0.2903, -1.0229],
          [-0.1220, -0.4631]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 4, 2])
```


K: 

```python
tensor([[[[ 0.0340,  0.0352],
          [ 0.1903,  0.0466],
          [-0.2709,  0.3840],
          [-0.6189,  0.4860],
          [-0.1048,  0.0250]],

         [[ 0.8016, -0.1494],
          [ 1.0380, -0.4053],
          [ 0.4957,  0.0590],
          [-0.2779,  0.5567],
          [ 0.3398,  0.1011]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 1.0637, -0.5323],
          [ 0.9685, -0.5174],
          [-0.2034, -0.3953],
          [-0.9852, -0.1468],
          [ 0.7337, -0.3573]],

         [[ 0.1639, -0.2189],
          [-0.3600, -0.3702],
          [-0.3778, -0.5270],
          [ 0.0821, -0.3430],
          [ 0.4870, -0.0390]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 4, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[-0.0018, -0.0153,  0.0380,  0.0728,  0.0103],
          [-0.0154, -0.0097, -0.2151, -0.2925, -0.0204],
          [-0.0348, -0.1110, -0.0938,  0.0045,  0.0328],
          [-0.0233, -0.1305,  0.1861,  0.4250,  0.0719]],

         [[-0.0675, -0.0561, -0.0640, -0.0511, -0.0528],
          [-0.0120,  0.0643, -0.0645, -0.1862, -0.0671],
          [-0.0565,  0.0801, -0.1444, -0.3456, -0.1429],
          [-0.0202,  0.0432, -0.0621, -0.1583, -0.0624]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 4, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[-1.7599e-03, -1.5302e-02,  3.8037e-02,  7.2778e-02, -1.0000e+09],
          [-1.5388e-02, -9.6661e-03, -2.1506e-01, -2.9251e-01, -1.0000e+09],
          [-3.4828e-02, -1.1096e-01, -9.3760e-02,  4.5087e-03, -1.0000e+09],
          [-2.3261e-02, -1.3049e-01,  1.8615e-01,  4.2495e-01, -1.0000e+09]],

         [[-6.7469e-02, -5.6122e-02, -6.4038e-02, -5.1052e-02, -1.0000e+09],
          [-1.2029e-02,  6.4316e-02, -6.4498e-02, -1.8620e-01, -1.0000e+09],
          [-5.6493e-02,  8.0121e-02, -1.4441e-01, -3.4563e-01, -1.0000e+09],
          [-2.0221e-02,  4.3203e-02, -6.2061e-02, -1.5832e-01, -1.0000e+09]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 4, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[0.2436, 0.2404, 0.2535, 0.2625, 0.0000],
          [0.2791, 0.2807, 0.2286, 0.2116, 0.0000],
          [0.2558, 0.2370, 0.2411, 0.2660, 0.0000],
          [0.2129, 0.1913, 0.2625, 0.3333, 0.0000]],

         [[0.2481, 0.2509, 0.2489, 0.2522, 0.0000],
          [0.2585, 0.2790, 0.2453, 0.2172, 0.0000],
          [0.2624, 0.3008, 0.2403, 0.1965, 0.0000],
          [0.2567, 0.2735, 0.2462, 0.2236, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 4, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.1818, -0.3928],
          [ 0.3139, -0.4152],
          [ 0.1905, -0.3931],
          [ 0.0299, -0.3650]],

         [[-0.1230, -0.3648],
          [-0.1329, -0.3636],
          [-0.1399, -0.3628],
          [-0.1310, -0.3639]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 4, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[0.2436, 0.2404, 0.2535, 0.2625, 0.0000],
          [0.2791, 0.2807, 0.2286, 0.2116, 0.0000],
          [0.2558, 0.2370, 0.2411, 0.2660, 0.0000],
          [0.2129, 0.1913, 0.2625, 0.3333, 0.0000]],

         [[0.2481, 0.2509, 0.2489, 0.2522, 0.0000],
          [0.2585, 0.2790, 0.2453, 0.2172, 0.0000],
          [0.2624, 0.3008, 0.2403, 0.1965, 0.0000],
          [0.2567, 0.2735, 0.2462, 0.2236, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 4, 5])
```


context: 

```python
tensor([[[[ 0.1818, -0.3928],
          [ 0.3139, -0.4152],
          [ 0.1905, -0.3931],
          [ 0.0299, -0.3650]],

         [[-0.1230, -0.3648],
          [-0.1329, -0.3636],
          [-0.1399, -0.3628],
          [-0.1310, -0.3639]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 4, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.1818, -0.3928, -0.1230, -0.3648],
         [ 0.3139, -0.4152, -0.1329, -0.3636],
         [ 0.1905, -0.3931, -0.1399, -0.3628],
         [ 0.0299, -0.3650, -0.1310, -0.3639]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 4, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[ 0.1087,  0.0010,  0.0669, -0.1148],
         [ 0.0750,  0.0229,  0.1022, -0.0901],
         [ 0.1134,  0.0053,  0.0653, -0.1141],
         [ 0.1557, -0.0207,  0.0214, -0.1442]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 4, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-0.7822,  1.2253, -1.1672,  0.7241],
         [ 1.6254, -0.8202,  0.0223, -0.8275],
         [ 1.3446, -1.2228, -0.6480,  0.5261],
         [-0.2298, -1.1303, -0.2539,  1.6140]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 4, 4])
```


output + residual: 

```python
tensor([[[-0.6735,  1.2263, -1.1004,  0.6094],
         [ 1.7004, -0.7973,  0.1245, -0.9177],
         [ 1.4581, -1.2175, -0.5827,  0.4120],
         [-0.0742, -1.1509, -0.2325,  1.4699]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 4, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-0.7325,  1.2874, -1.1863,  0.6315],
         [ 1.5984, -0.7880,  0.0927, -0.9031],
         [ 1.4201, -1.2174, -0.5916,  0.3889],
         [-0.0820, -1.2259, -0.2503,  1.5582]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 4, 4])
```


## PoswiseFeedForwardNet


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


inputs: 

```python
tensor([[[-0.7325,  1.2874, -1.1863,  0.6315],
         [ 1.5984, -0.7880,  0.0927, -0.9031],
         [ 1.4201, -1.2174, -0.5916,  0.3889],
         [-0.0820, -1.2259, -0.2503,  1.5582]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 4, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc操作的代码</div>


: 

```python
output = self.fc(inputs)
```


inputs: 

```python
tensor([[[-0.7325,  1.2874, -1.1863,  0.6315],
         [ 1.5984, -0.7880,  0.0927, -0.9031],
         [ 1.4201, -1.2174, -0.5916,  0.3889],
         [-0.0820, -1.2259, -0.2503,  1.5582]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 4, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc原来是d_model->d_ff->d_model</div>


self.fc: 

```python
Sequential(
  (0): Linear(in_features=4, out_features=8, bias=False)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=4, bias=False)
)
```


output: 

```python
tensor([[[-0.0614, -0.1831, -0.0225,  0.0241],
         [-0.2362, -0.0408, -0.2841, -0.1324],
         [-0.1947,  0.1199, -0.2546, -0.1425],
         [-0.0980,  0.0248, -0.2062, -0.1187]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 4, 4])
```


## 前馈层后的层归一化和残差


<div style='color:#fe618e;font-weight:800;font-size:23px;'>FeedForward后的层归一化和残差</div>


: 

```python
ans = nn.LayerNorm(d_model).to(device)(output + residual)
```


residual: 

```python
tensor([[[-0.7325,  1.2874, -1.1863,  0.6315],
         [ 1.5984, -0.7880,  0.0927, -0.9031],
         [ 1.4201, -1.2174, -0.5916,  0.3889],
         [-0.0820, -1.2259, -0.2503,  1.5582]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 4, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>残差和层归一化之后的结果</div>


ans: 

```python
tensor([[[-0.7597,  1.2070, -1.1895,  0.7422],
         [ 1.6343, -0.6976, -0.0192, -0.9175],
         [ 1.4513, -1.0582, -0.7867,  0.3937],
         [-0.0835, -1.1429, -0.3703,  1.5968]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans.shape: 

```python
torch.Size([1, 4, 4])
```


# Decoder结束


<div style='color:#fe618e;font-weight:800;font-size:23px;'>model的decode操作</div>


: 

```python
dec_outputs, _, _ = model.decoder(dec_input, enc_input, enc_outputs)
```


dec_outputs: 

```python
tensor([[[-0.7597,  1.2070, -1.1895,  0.7422],
         [ 1.6343, -0.6976, -0.0192, -0.9175],
         [ 1.4513, -1.0582, -0.7867,  0.3937],
         [-0.0835, -1.1429, -0.3703,  1.5968]]],
       grad_fn=<NativeLayerNormBackward0>)
```


dec_outputs.shape: 

```python
torch.Size([1, 4, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>model的projection操作</div>


: 

```python
projected = model.projection(dec_outputs)
```


projected: 

```python
tensor([[[-0.1951,  3.0093, -2.2052,  2.7557, -0.4902, -3.2442, -0.7391],
         [ 0.0407, -3.1940,  4.1533,  0.6630,  0.0790, -0.0890, -0.2498],
         [ 0.0332, -2.8074,  2.1219,  1.0454, -0.2050, -1.0397,  2.5895],
         [ 0.1024, -0.7365, -2.3041, -1.2663, -0.1213,  0.6461,  4.5999]]],
       grad_fn=<UnsafeViewBackward0>)
```


projected.shape: 

```python
torch.Size([1, 4, 7])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>生成prob</div>


: 

```python
prob = projected.squeeze(0).max(dim=-1, keepdim=False)[1]
```


prob: 

```python
tensor([1, 2, 6, 6])
```


prob.shape: 

```python
torch.Size([4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>生成next_word</div>


: 

```python
next_word = prob.data[-1]
```


next_word: 

```python
tensor(6)
```


next_word.shape: 

```python
torch.Size([])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>迭代下一轮</div>


: 

```python
next_symbol = next_word
```


next_symbol: 

```python
tensor(6)
```


# 预测这句话第【5】个单词：


<div style='color:#fe618e;font-weight:800;font-size:23px;'>生成dec_input</div>


: 

```python
dec_input = torch.cat([dec_input.to(device), torch.tensor([[next_symbol]], dtype=enc_input.dtype).to(device)],-1)
```


dec_input: 

```python
tensor([[4, 1, 2, 3, 6]])
```


dec_input.shape: 

```python
torch.Size([1, 5])
```


# Decoder中


<div style='color:#3296ee;font-weight:800;font-size:23px;'>dec_inputs转换为词向量的结果</div>


: 

```python
dec_outputs = self.tgt_emb(dec_inputs)
```


dec_outputs: 

```python
tensor([[[-1.0398,  1.3073, -0.2711, -0.4491],
         [ 1.2834, -0.4243,  0.4540, -1.6032],
         [ 0.1516,  1.9322, -0.6804, -0.9484],
         [-0.2245,  0.3270, -0.5733, -0.1797],
         [-1.2789, -2.6762,  0.6514, -0.5435]]], grad_fn=<EmbeddingBackward0>)
```


dec_outputs.shape: 

```python
torch.Size([1, 5, 4])
```


## PositionalEncoding


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入加上位置编码的代码</div>


加上位置编码: 

```python
x = x + self.pe[:x.size(0), :]
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


x: 

```python
tensor([[[-1.0398,  1.3073, -0.2711, -0.4491]],

        [[ 1.2834, -0.4243,  0.4540, -1.6032]],

        [[ 0.1516,  1.9322, -0.6804, -0.9484]],

        [[-0.2245,  0.3270, -0.5733, -0.1797]],

        [[-1.2789, -2.6762,  0.6514, -0.5435]]], grad_fn=<TransposeBackward0>)
```


x.shape: 

```python
torch.Size([5, 1, 4])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>位置编码</div>


self.pe[:x.size(0), :]: 

```python
tensor([[[ 0.0000,  1.0000,  0.0000,  1.0000]],

        [[ 0.8415,  0.5403,  0.0100,  0.9999]],

        [[ 0.9093, -0.4161,  0.0200,  0.9998]],

        [[ 0.1411, -0.9900,  0.0300,  0.9996]],

        [[-0.7568, -0.6536,  0.0400,  0.9992]]])
```


self.pe[:x.size(0), :].shape: 

```python
torch.Size([5, 1, 4])
```


self.pe.shape: 

```python
torch.Size([5000, 1, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


x: 

```python
tensor([[[-1.0398,  2.3073, -0.2711,  0.5509]],

        [[ 2.1248,  0.1160,  0.4640, -0.6032]],

        [[ 1.0609,  1.5160, -0.6604,  0.0514]],

        [[-0.0834, -0.6630, -0.5433,  0.8198]],

        [[-2.0357, -3.3299,  0.6914,  0.4557]]], grad_fn=<AddBackward0>)
```


x.shape: 

```python
torch.Size([5, 1, 4])
```


## decoder的self_attn的pad_mask


## get_attn_pad_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq_q: 

```python
tensor([[4, 1, 2, 3, 6]])
```


seq_q.shape: 

```python
torch.Size([1, 5])
```


seq_k: 

```python
tensor([[4, 1, 2, 3, 6]])
```


seq_k.shape: 

```python
torch.Size([1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>获取对应的大小：len_q,len_k</div>


例如: 

```python
batch_size, len_q = seq_q.size()
```


batch_size: 

```python
1
```


len_q: 

```python
5
```


len_k: 

```python
5
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>操作pad_attn_mask矩阵：pad_attn_mask</div>


: 

```python
pad_attn_mask = seq_k.data.eq(0).unsqueeze(1) 
```


pad_attn_mask: 

```python
tensor([[[False, False, False, False, False]]])
```


pad_attn_mask.shape: 

```python
torch.Size([1, 1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>扩展pad_attn_mask矩阵：pad_attn_mask.expand</div>


: 

```python
ans = pad_attn_mask.expand(batch_size, len_q, len_k)  
```


ans: 

```python
tensor([[[False, False, False, False, False],
         [False, False, False, False, False],
         [False, False, False, False, False],
         [False, False, False, False, False],
         [False, False, False, False, False]]])
```


ans.shape: 

```python
torch.Size([1, 5, 5])
```


## get_attn_subsequence_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq: 

```python
tensor([[4, 1, 2, 3, 6]])
```


seq.shape: 

```python
torch.Size([1, 5])
```


<div style='color:#19ce8b;font-weight:800;font-size:23px;'>求attn_shape</div>


: 

```python
attn_shape = [seq.size(0), seq.size(1), seq.size(1)]
```


attn_shape: 

```python
[1, 5, 5]
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>生成一个上三角矩阵</div>


: 

```python
subsequence_mask = np.triu(np.ones(attn_shape), k=1)
```


subsequence_mask: 

```python
[[[0. 1. 1. 1. 1.]
  [0. 0. 1. 1. 1.]
  [0. 0. 0. 1. 1.]
  [0. 0. 0. 0. 1.]
  [0. 0. 0. 0. 0.]]]
```


subsequence_mask.shape: 

```python
(1, 5, 5)
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>生成subsequence_mask</div>


: 

```python
subsequence_mask = torch.from_numpy(subsequence_mask).byte()
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>输出</div>


subsequence_mask: 

```python
tensor([[[0, 1, 1, 1, 1],
         [0, 0, 1, 1, 1],
         [0, 0, 0, 1, 1],
         [0, 0, 0, 0, 1],
         [0, 0, 0, 0, 0]]], dtype=torch.uint8)
```


subsequence_mask.shape: 

```python
torch.Size([1, 5, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>两个mask相加</div>


: 

```python
dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequence_mask),0).to(device)
```


dec_self_attn_pad_mask: 

```python
tensor([[[False, False, False, False, False],
         [False, False, False, False, False],
         [False, False, False, False, False],
         [False, False, False, False, False],
         [False, False, False, False, False]]])
```


dec_self_attn_pad_mask.shape: 

```python
torch.Size([1, 5, 5])
```


dec_self_attn_subsequence_mask: 

```python
tensor([[[0, 1, 1, 1, 1],
         [0, 0, 1, 1, 1],
         [0, 0, 0, 1, 1],
         [0, 0, 0, 0, 1],
         [0, 0, 0, 0, 0]]], dtype=torch.uint8)
```


dec_self_attn_subsequence_mask.shape: 

```python
torch.Size([1, 5, 5])
```


dec_self_attn_mask: 

```python
tensor([[[False,  True,  True,  True,  True],
         [False, False,  True,  True,  True],
         [False, False, False,  True,  True],
         [False, False, False, False,  True],
         [False, False, False, False, False]]])
```


dec_self_attn_mask.shape: 

```python
torch.Size([1, 5, 5])
```


## 交互注意力层中的pad_mask


## get_attn_pad_mask


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


seq_q: 

```python
tensor([[4, 1, 2, 3, 6]])
```


seq_q.shape: 

```python
torch.Size([1, 5])
```


seq_k: 

```python
tensor([[4, 1, 2, 3, 6]])
```


seq_k.shape: 

```python
torch.Size([1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>获取对应的大小：len_q,len_k</div>


例如: 

```python
batch_size, len_q = seq_q.size()
```


batch_size: 

```python
1
```


len_q: 

```python
5
```


len_k: 

```python
5
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>操作pad_attn_mask矩阵：pad_attn_mask</div>


: 

```python
pad_attn_mask = seq_k.data.eq(0).unsqueeze(1) 
```


pad_attn_mask: 

```python
tensor([[[False, False, False, False,  True]]])
```


pad_attn_mask.shape: 

```python
torch.Size([1, 1, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>扩展pad_attn_mask矩阵：pad_attn_mask.expand</div>


: 

```python
ans = pad_attn_mask.expand(batch_size, len_q, len_k)  
```


ans: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


ans.shape: 

```python
torch.Size([1, 5, 5])
```


# DecoderLayer


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-1.1553,  2.5637, -0.0000,  0.6121],
         [ 2.3609,  0.1289,  0.0000, -0.6703],
         [ 0.0000,  1.6845, -0.0000,  0.0572],
         [-0.0000, -0.7367, -0.6036,  0.0000],
         [-2.2619, -3.6999,  0.7682,  0.5063]]], grad_fn=<TransposeBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_K: 

```python
tensor([[[-1.1553,  2.5637, -0.0000,  0.6121],
         [ 2.3609,  0.1289,  0.0000, -0.6703],
         [ 0.0000,  1.6845, -0.0000,  0.0572],
         [-0.0000, -0.7367, -0.6036,  0.0000],
         [-2.2619, -3.6999,  0.7682,  0.5063]]], grad_fn=<TransposeBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[-1.1553,  2.5637, -0.0000,  0.6121],
         [ 2.3609,  0.1289,  0.0000, -0.6703],
         [ 0.0000,  1.6845, -0.0000,  0.0572],
         [-0.0000, -0.7367, -0.6036,  0.0000],
         [-2.2619, -3.6999,  0.7682,  0.5063]]], grad_fn=<TransposeBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False,  True,  True,  True,  True],
         [False, False,  True,  True,  True],
         [False, False, False,  True,  True],
         [False, False, False, False,  True],
         [False, False, False, False, False]]])
```


attn_mask.shape: 

```python
torch.Size([1, 5, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 1.0378, -0.2223],
          [-0.4124, -0.3277],
          [ 0.4789, -0.2358],
          [-0.3991,  0.3823],
          [-0.3723,  0.4579]],

         [[-1.2387, -1.4712],
          [ 0.6479,  0.8441],
          [-0.5473, -0.7150],
          [ 0.2598,  0.5884],
          [ 0.5092,  0.3636]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 5, 2])
```


K: 

```python
tensor([[[[-0.6208, -0.9212],
          [ 0.7665, -0.0166],
          [-0.1754, -0.6297],
          [ 0.2154,  0.4055],
          [-0.5358,  1.1918]],

         [[-1.3822,  0.0292],
          [ 0.3549, -0.6168],
          [-0.7512, -0.1657],
          [ 0.5333, -0.0816],
          [ 0.9910,  1.1376]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.7181,  1.0543],
          [ 0.6977, -0.8490],
          [ 0.7147,  0.4231],
          [-0.4576, -0.0862],
          [-2.0060, -0.2125]],

         [[-0.3024,  0.6065],
          [-0.9328, -0.1006],
          [-0.4748,  0.3037],
          [ 0.1360,  0.1771],
          [ 1.9912, -0.9354]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False,  True,  True,  True,  True],
          [False, False,  True,  True,  True],
          [False, False, False,  True,  True],
          [False, False, False, False,  True],
          [False, False, False, False, False]],

         [[False,  True,  True,  True,  True],
          [False, False,  True,  True,  True],
          [False, False, False,  True,  True],
          [False, False, False, False,  True],
          [False, False, False, False, False]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 1.0378, -0.2223],
          [-0.4124, -0.3277],
          [ 0.4789, -0.2358],
          [-0.3991,  0.3823],
          [-0.3723,  0.4579]],

         [[-1.2387, -1.4712],
          [ 0.6479,  0.8441],
          [-0.5473, -0.7150],
          [ 0.2598,  0.5884],
          [ 0.5092,  0.3636]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 5, 2])
```


K: 

```python
tensor([[[[-0.6208, -0.9212],
          [ 0.7665, -0.0166],
          [-0.1754, -0.6297],
          [ 0.2154,  0.4055],
          [-0.5358,  1.1918]],

         [[-1.3822,  0.0292],
          [ 0.3549, -0.6168],
          [-0.7512, -0.1657],
          [ 0.5333, -0.0816],
          [ 0.9910,  1.1376]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.7181,  1.0543],
          [ 0.6977, -0.8490],
          [ 0.7147,  0.4231],
          [-0.4576, -0.0862],
          [-2.0060, -0.2125]],

         [[-0.3024,  0.6065],
          [-0.9328, -0.1006],
          [-0.4748,  0.3037],
          [ 0.1360,  0.1771],
          [ 1.9912, -0.9354]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False,  True,  True,  True,  True],
          [False, False,  True,  True,  True],
          [False, False, False,  True,  True],
          [False, False, False, False,  True],
          [False, False, False, False, False]],

         [[False,  True,  True,  True,  True],
          [False, False,  True,  True,  True],
          [False, False, False,  True,  True],
          [False, False, False, False,  True],
          [False, False, False, False, False]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[-0.3108,  0.5651, -0.0298,  0.0943, -0.5805],
          [ 0.3945, -0.2196,  0.1971, -0.1568, -0.1199],
          [-0.0566,  0.2623,  0.0456,  0.0053, -0.3801],
          [-0.0738, -0.2208, -0.1207,  0.0488,  0.4734],
          [-0.1348, -0.2072, -0.1577,  0.0746,  0.5269]],

         [[ 1.1803,  0.3307,  0.8304, -0.3822, -2.0514],
          [-0.6158, -0.2055, -0.4430,  0.1956,  1.1329],
          [ 0.5201,  0.1745,  0.3745, -0.1651, -0.9587],
          [-0.2417, -0.1914, -0.2069,  0.0640,  0.6554],
          [-0.4902, -0.0308, -0.3131,  0.1710,  0.6493]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[-3.1080e-01, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],
          [ 3.9450e-01, -2.1964e-01, -1.0000e+09, -1.0000e+09, -1.0000e+09],
          [-5.6633e-02,  2.6231e-01,  4.5564e-02, -1.0000e+09, -1.0000e+09],
          [-7.3847e-02, -2.2081e-01, -1.2071e-01,  4.8848e-02, -1.0000e+09],
          [-1.3484e-01, -2.0715e-01, -1.5768e-01,  7.4600e-02,  5.2691e-01]],

         [[ 1.1803e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],
          [-6.1578e-01, -2.0553e-01, -1.0000e+09, -1.0000e+09, -1.0000e+09],
          [ 5.2014e-01,  1.7449e-01,  3.7450e-01, -1.0000e+09, -1.0000e+09],
          [-2.4174e-01, -1.9144e-01, -2.0694e-01,  6.3999e-02, -1.0000e+09],
          [-4.9017e-01, -3.0796e-02, -3.1309e-01,  1.7104e-01,  6.4932e-01]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.6489, 0.3511, 0.0000, 0.0000, 0.0000],
          [0.2871, 0.3949, 0.3180, 0.0000, 0.0000],
          [0.2533, 0.2187, 0.2417, 0.2864, 0.0000],
          [0.1645, 0.1530, 0.1608, 0.2028, 0.3188]],

         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3989, 0.6011, 0.0000, 0.0000, 0.0000],
          [0.3888, 0.2752, 0.3361, 0.0000, 0.0000],
          [0.2250, 0.2366, 0.2330, 0.3055, 0.0000],
          [0.1131, 0.1791, 0.1351, 0.2192, 0.3536]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.7181,  1.0543],
          [ 0.7109,  0.3860],
          [ 0.7089,  0.1019],
          [ 0.3761,  0.1590],
          [-0.3926,  0.0263]],

         [[-0.3024,  0.6065],
          [-0.6814,  0.1814],
          [-0.5338,  0.3102],
          [-0.3578,  0.2375],
          [ 0.4684, -0.2003]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.6489, 0.3511, 0.0000, 0.0000, 0.0000],
          [0.2871, 0.3949, 0.3180, 0.0000, 0.0000],
          [0.2533, 0.2187, 0.2417, 0.2864, 0.0000],
          [0.1645, 0.1530, 0.1608, 0.2028, 0.3188]],

         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.3989, 0.6011, 0.0000, 0.0000, 0.0000],
          [0.3888, 0.2752, 0.3361, 0.0000, 0.0000],
          [0.2250, 0.2366, 0.2330, 0.3055, 0.0000],
          [0.1131, 0.1791, 0.1351, 0.2192, 0.3536]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 5, 5])
```


context: 

```python
tensor([[[[ 0.7181,  1.0543],
          [ 0.7109,  0.3860],
          [ 0.7089,  0.1019],
          [ 0.3761,  0.1590],
          [-0.3926,  0.0263]],

         [[-0.3024,  0.6065],
          [-0.6814,  0.1814],
          [-0.5338,  0.3102],
          [-0.3578,  0.2375],
          [ 0.4684, -0.2003]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.7181,  1.0543, -0.3024,  0.6065],
         [ 0.7109,  0.3860, -0.6814,  0.1814],
         [ 0.7089,  0.1019, -0.5338,  0.3102],
         [ 0.3761,  0.1590, -0.3578,  0.2375],
         [-0.3926,  0.0263,  0.4684, -0.2003]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[ 0.6765,  0.1202, -0.2313,  0.3884],
         [ 0.4874,  0.0850,  0.0093,  0.6051],
         [ 0.3765,  0.1018, -0.0328,  0.6679],
         [ 0.2336,  0.0766, -0.0294,  0.4001],
         [-0.1853, -0.0845, -0.0159, -0.5082]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 5, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-1.1553,  2.5637, -0.0000,  0.6121],
         [ 2.3609,  0.1289,  0.0000, -0.6703],
         [ 0.0000,  1.6845, -0.0000,  0.0572],
         [-0.0000, -0.7367, -0.6036,  0.0000],
         [-2.2619, -3.6999,  0.7682,  0.5063]]], grad_fn=<TransposeBackward0>)
```


residual.shape: 

```python
torch.Size([1, 5, 4])
```


output + residual: 

```python
tensor([[[-4.7878e-01,  2.6838e+00, -2.3127e-01,  1.0006e+00],
         [ 2.8484e+00,  2.1389e-01,  9.2905e-03, -6.5197e-02],
         [ 3.7651e-01,  1.7863e+00, -3.2793e-02,  7.2511e-01],
         [ 2.3361e-01, -6.6009e-01, -6.3302e-01,  4.0009e-01],
         [-2.4471e+00, -3.7844e+00,  7.5228e-01, -1.9027e-03]]],
       grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-0.9759,  1.5491, -0.7783,  0.2052],
         [ 1.7259, -0.4426, -0.6110, -0.6723],
         [-0.4998,  1.5893, -1.1063,  0.0168],
         [ 0.8209, -1.0203, -0.9645,  1.1639],
         [-0.5891, -1.3207,  1.1612,  0.7486]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 5, 4])
```


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-0.9759,  1.5491, -0.7783,  0.2052],
         [ 1.7259, -0.4426, -0.6110, -0.6723],
         [-0.4998,  1.5893, -1.1063,  0.0168],
         [ 0.8209, -1.0203, -0.9645,  1.1639],
         [-0.5891, -1.3207,  1.1612,  0.7486]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_K: 

```python
tensor([[[ 0.6868, -1.7263,  0.5829,  0.4565],
         [ 1.6033, -1.1500, -0.2725, -0.1809],
         [ 1.1261, -0.7021, -1.2486,  0.8246],
         [-0.2686, -0.4144, -0.9857,  1.6687],
         [-0.2267, -1.5400,  0.9742,  0.7925]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[ 0.6868, -1.7263,  0.5829,  0.4565],
         [ 1.6033, -1.1500, -0.2725, -0.1809],
         [ 1.1261, -0.7021, -1.2486,  0.8246],
         [-0.2686, -0.4144, -0.9857,  1.6687],
         [-0.2267, -1.5400,  0.9742,  0.7925]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 5, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 1.0526,  0.2907],
          [-0.8757,  0.9912],
          [ 0.8886,  0.6689],
          [-0.1924, -0.1716],
          [-0.1993, -1.3290]],

         [[-0.7420,  0.2312],
          [ 0.1743,  0.0605],
          [-0.7775,  0.2776],
          [ 0.2520, -0.3881],
          [ 0.6155, -0.3801]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 5, 2])
```


K: 

```python
tensor([[[[ 0.2876,  0.7402],
          [ 0.4966,  0.3560],
          [ 0.5376,  0.3952],
          [ 0.2229,  0.4991],
          [ 0.0389,  0.7666]],

         [[ 0.4759,  0.6528],
          [-0.5556, -0.0237],
          [-0.3791, -0.1074],
          [ 0.5440,  0.2833],
          [ 1.0660,  0.9173]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.9145,  0.2993],
          [ 0.9688, -0.2155],
          [-0.1428, -0.3849],
          [-0.9931, -0.0470],
          [ 0.5290,  0.5650]],

         [[ 0.1975,  0.7515],
          [ 0.3600,  0.7951],
          [-0.1420,  0.8862],
          [-0.5786,  0.5694],
          [-0.0029,  0.4654]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 1.0526,  0.2907],
          [-0.8757,  0.9912],
          [ 0.8886,  0.6689],
          [-0.1924, -0.1716],
          [-0.1993, -1.3290]],

         [[-0.7420,  0.2312],
          [ 0.1743,  0.0605],
          [-0.7775,  0.2776],
          [ 0.2520, -0.3881],
          [ 0.6155, -0.3801]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 5, 2])
```


K: 

```python
tensor([[[[ 0.2876,  0.7402],
          [ 0.4966,  0.3560],
          [ 0.5376,  0.3952],
          [ 0.2229,  0.4991],
          [ 0.0389,  0.7666]],

         [[ 0.4759,  0.6528],
          [-0.5556, -0.0237],
          [-0.3791, -0.1074],
          [ 0.5440,  0.2833],
          [ 1.0660,  0.9173]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.9145,  0.2993],
          [ 0.9688, -0.2155],
          [-0.1428, -0.3849],
          [-0.9931, -0.0470],
          [ 0.5290,  0.5650]],

         [[ 0.1975,  0.7515],
          [ 0.3600,  0.7951],
          [-0.1420,  0.8862],
          [-0.5786,  0.5694],
          [-0.0029,  0.4654]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[ 0.3662,  0.4428,  0.4814,  0.2685,  0.1865],
          [ 0.3407, -0.0580, -0.0559,  0.2118,  0.5132],
          [ 0.5308,  0.4804,  0.5247,  0.3761,  0.3870],
          [-0.1289, -0.1108, -0.1211, -0.0909, -0.0983],
          [-0.7361, -0.4045, -0.4471, -0.5005, -0.7259]],

         [[-0.1429,  0.2876,  0.1813, -0.2391, -0.4093],
          [ 0.0866, -0.0695, -0.0513,  0.0791,  0.1706],
          [-0.1335,  0.3008,  0.1873, -0.2435, -0.4060],
          [-0.0943, -0.0925, -0.0381,  0.0192, -0.0618],
          [ 0.0317, -0.2354, -0.1361,  0.1606,  0.2174]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[ 3.6616e-01,  4.4281e-01,  4.8139e-01,  2.6847e-01, -1.0000e+09],
          [ 3.4071e-01, -5.8019e-02, -5.5945e-02,  2.1181e-01, -1.0000e+09],
          [ 5.3079e-01,  4.8043e-01,  5.2473e-01,  3.7612e-01, -1.0000e+09],
          [-1.2895e-01, -1.1077e-01, -1.2110e-01, -9.0892e-02, -1.0000e+09],
          [-7.3612e-01, -4.0454e-01, -4.4715e-01, -5.0046e-01, -1.0000e+09]],

         [[-1.4295e-01,  2.8763e-01,  1.8134e-01, -2.3910e-01, -1.0000e+09],
          [ 8.6555e-02, -6.9471e-02, -5.1305e-02,  7.9143e-02, -1.0000e+09],
          [-1.3349e-01,  3.0082e-01,  1.8735e-01, -2.4349e-01, -1.0000e+09],
          [-9.4337e-02, -9.2495e-02, -3.8076e-02,  1.9202e-02, -1.0000e+09],
          [ 3.1669e-02, -2.3543e-01, -1.3613e-01,  1.6063e-01, -1.0000e+09]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[0.2434, 0.2628, 0.2731, 0.2207, 0.0000],
          [0.3103, 0.2083, 0.2087, 0.2728, 0.0000],
          [0.2631, 0.2501, 0.2615, 0.2254, 0.0000],
          [0.2460, 0.2505, 0.2479, 0.2555, 0.0000],
          [0.2002, 0.2790, 0.2673, 0.2535, 0.0000]],

         [[0.2071, 0.3185, 0.2864, 0.1881, 0.0000],
          [0.2689, 0.2300, 0.2342, 0.2669, 0.0000],
          [0.2076, 0.3204, 0.2861, 0.1859, 0.0000],
          [0.2392, 0.2397, 0.2531, 0.2680, 0.0000],
          [0.2668, 0.2042, 0.2255, 0.3035, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.2190, -0.0993],
          [ 0.1849, -0.0451],
          [ 0.2218, -0.0864],
          [ 0.1785, -0.0878],
          [ 0.1635, -0.1150]],

         [[ 0.0061,  0.7697],
          [-0.0517,  0.7445],
          [ 0.0082,  0.7701],
          [-0.0574,  0.7472],
          [-0.0814,  0.7355]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[0.2434, 0.2628, 0.2731, 0.2207, 0.0000],
          [0.3103, 0.2083, 0.2087, 0.2728, 0.0000],
          [0.2631, 0.2501, 0.2615, 0.2254, 0.0000],
          [0.2460, 0.2505, 0.2479, 0.2555, 0.0000],
          [0.2002, 0.2790, 0.2673, 0.2535, 0.0000]],

         [[0.2071, 0.3185, 0.2864, 0.1881, 0.0000],
          [0.2689, 0.2300, 0.2342, 0.2669, 0.0000],
          [0.2076, 0.3204, 0.2861, 0.1859, 0.0000],
          [0.2392, 0.2397, 0.2531, 0.2680, 0.0000],
          [0.2668, 0.2042, 0.2255, 0.3035, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 5, 5])
```


context: 

```python
tensor([[[[ 0.2190, -0.0993],
          [ 0.1849, -0.0451],
          [ 0.2218, -0.0864],
          [ 0.1785, -0.0878],
          [ 0.1635, -0.1150]],

         [[ 0.0061,  0.7697],
          [-0.0517,  0.7445],
          [ 0.0082,  0.7701],
          [-0.0574,  0.7472],
          [-0.0814,  0.7355]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.2190, -0.0993,  0.0061,  0.7697],
         [ 0.1849, -0.0451, -0.0517,  0.7445],
         [ 0.2218, -0.0864,  0.0082,  0.7701],
         [ 0.1785, -0.0878, -0.0574,  0.7472],
         [ 0.1635, -0.1150, -0.0814,  0.7355]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[-0.3041, -0.2253,  0.3890, -0.2489],
         [-0.2945, -0.1934,  0.3984, -0.2571],
         [-0.2991, -0.2255,  0.3840, -0.2519],
         [-0.3120, -0.1944,  0.4158, -0.2488],
         [-0.3237, -0.1837,  0.4320, -0.2416]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 5, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-0.9759,  1.5491, -0.7783,  0.2052],
         [ 1.7259, -0.4426, -0.6110, -0.6723],
         [-0.4998,  1.5893, -1.1063,  0.0168],
         [ 0.8209, -1.0203, -0.9645,  1.1639],
         [-0.5891, -1.3207,  1.1612,  0.7486]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 5, 4])
```


output + residual: 

```python
tensor([[[-1.2800,  1.3238, -0.3893, -0.0437],
         [ 1.4315, -0.6360, -0.2126, -0.9294],
         [-0.7988,  1.3639, -0.7223, -0.2351],
         [ 0.5089, -1.2147, -0.5488,  0.9151],
         [-0.9128, -1.5044,  1.5931,  0.5070]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-1.2632,  1.5178, -0.3119,  0.0572],
         [ 1.6632, -0.6018, -0.1380, -0.9233],
         [-0.8042,  1.6779, -0.7164, -0.1572],
         [ 0.7042, -1.3399, -0.5501,  1.1858],
         [-0.6883, -1.1768,  1.3810,  0.4841]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 5, 4])
```


## PoswiseFeedForwardNet


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


inputs: 

```python
tensor([[[-1.2632,  1.5178, -0.3119,  0.0572],
         [ 1.6632, -0.6018, -0.1380, -0.9233],
         [-0.8042,  1.6779, -0.7164, -0.1572],
         [ 0.7042, -1.3399, -0.5501,  1.1858],
         [-0.6883, -1.1768,  1.3810,  0.4841]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc操作的代码</div>


: 

```python
output = self.fc(inputs)
```


inputs: 

```python
tensor([[[-1.2632,  1.5178, -0.3119,  0.0572],
         [ 1.6632, -0.6018, -0.1380, -0.9233],
         [-0.8042,  1.6779, -0.7164, -0.1572],
         [ 0.7042, -1.3399, -0.5501,  1.1858],
         [-0.6883, -1.1768,  1.3810,  0.4841]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc原来是d_model->d_ff->d_model</div>


self.fc: 

```python
Sequential(
  (0): Linear(in_features=4, out_features=8, bias=False)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=4, bias=False)
)
```


output: 

```python
tensor([[[ 0.0130, -0.1788, -0.1711,  0.2196],
         [ 0.0209, -0.0199, -0.1327,  0.1461],
         [ 0.0352, -0.1977, -0.2166,  0.2440],
         [-0.0393, -0.4175, -0.2204,  0.5455],
         [ 0.0584, -0.0302,  0.4046, -0.3510]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 5, 4])
```


## 前馈层后的层归一化和残差


<div style='color:#fe618e;font-weight:800;font-size:23px;'>FeedForward后的层归一化和残差</div>


: 

```python
ans = nn.LayerNorm(d_model).to(device)(output + residual)
```


residual: 

```python
tensor([[[-1.2632,  1.5178, -0.3119,  0.0572],
         [ 1.6632, -0.6018, -0.1380, -0.9233],
         [-0.8042,  1.6779, -0.7164, -0.1572],
         [ 0.7042, -1.3399, -0.5501,  1.1858],
         [-0.6883, -1.1768,  1.3810,  0.4841]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>残差和层归一化之后的结果</div>


ans: 

```python
tensor([[[-1.2759,  1.4300, -0.4741,  0.3200],
         [ 1.7019, -0.6333, -0.2778, -0.7908],
         [-0.7691,  1.5836, -0.9406,  0.1261],
         [ 0.5231, -1.2928, -0.5530,  1.3226],
         [-0.5783, -1.0915,  1.5697,  0.1002]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans.shape: 

```python
torch.Size([1, 5, 4])
```


# DecoderLayer


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-1.2759,  1.4300, -0.4741,  0.3200],
         [ 1.7019, -0.6333, -0.2778, -0.7908],
         [-0.7691,  1.5836, -0.9406,  0.1261],
         [ 0.5231, -1.2928, -0.5530,  1.3226],
         [-0.5783, -1.0915,  1.5697,  0.1002]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_K: 

```python
tensor([[[-1.2759,  1.4300, -0.4741,  0.3200],
         [ 1.7019, -0.6333, -0.2778, -0.7908],
         [-0.7691,  1.5836, -0.9406,  0.1261],
         [ 0.5231, -1.2928, -0.5530,  1.3226],
         [-0.5783, -1.0915,  1.5697,  0.1002]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[-1.2759,  1.4300, -0.4741,  0.3200],
         [ 1.7019, -0.6333, -0.2778, -0.7908],
         [-0.7691,  1.5836, -0.9406,  0.1261],
         [ 0.5231, -1.2928, -0.5530,  1.3226],
         [-0.5783, -1.0915,  1.5697,  0.1002]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False,  True,  True,  True,  True],
         [False, False,  True,  True,  True],
         [False, False, False,  True,  True],
         [False, False, False, False,  True],
         [False, False, False, False, False]]])
```


attn_mask.shape: 

```python
torch.Size([1, 5, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 0.1357,  1.0987],
          [-0.6463, -0.8054],
          [-0.2126,  1.0850],
          [-0.0756, -0.3771],
          [ 0.8170, -0.5935]],

         [[ 0.3595,  0.0625],
          [ 0.2871, -0.2306],
          [ 0.6292, -0.1198],
          [-0.7679, -0.6102],
          [-0.7993,  0.5176]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 5, 2])
```


K: 

```python
tensor([[[[ 0.3278, -0.2817],
          [ 0.4502,  0.5112],
          [ 0.7516, -0.0151],
          [-0.1650,  0.7412],
          [-1.2629, -0.6159]],

         [[ 0.2026, -0.5223],
          [-0.1968, -0.1694],
          [ 0.2086, -0.9047],
          [ 0.2806, -0.1984],
          [-0.1833,  1.3322]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.3576,  0.2596],
          [-0.3007, -0.8180],
          [ 0.3034, -0.1079],
          [-0.3521,  0.1797],
          [-0.0320,  0.7510]],

         [[ 0.6058, -0.6189],
          [-0.4632,  0.2841],
          [ 0.6202, -0.6672],
          [ 0.0974,  0.6662],
          [-0.4285,  0.4101]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False,  True,  True,  True,  True],
          [False, False,  True,  True,  True],
          [False, False, False,  True,  True],
          [False, False, False, False,  True],
          [False, False, False, False, False]],

         [[False,  True,  True,  True,  True],
          [False, False,  True,  True,  True],
          [False, False, False,  True,  True],
          [False, False, False, False,  True],
          [False, False, False, False, False]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 0.1357,  1.0987],
          [-0.6463, -0.8054],
          [-0.2126,  1.0850],
          [-0.0756, -0.3771],
          [ 0.8170, -0.5935]],

         [[ 0.3595,  0.0625],
          [ 0.2871, -0.2306],
          [ 0.6292, -0.1198],
          [-0.7679, -0.6102],
          [-0.7993,  0.5176]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 5, 2])
```


K: 

```python
tensor([[[[ 0.3278, -0.2817],
          [ 0.4502,  0.5112],
          [ 0.7516, -0.0151],
          [-0.1650,  0.7412],
          [-1.2629, -0.6159]],

         [[ 0.2026, -0.5223],
          [-0.1968, -0.1694],
          [ 0.2086, -0.9047],
          [ 0.2806, -0.1984],
          [-0.1833,  1.3322]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 0.3576,  0.2596],
          [-0.3007, -0.8180],
          [ 0.3034, -0.1079],
          [-0.3521,  0.1797],
          [-0.0320,  0.7510]],

         [[ 0.6058, -0.6189],
          [-0.4632,  0.2841],
          [ 0.6202, -0.6672],
          [ 0.0974,  0.6662],
          [-0.4285,  0.4101]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False,  True,  True,  True,  True],
          [False, False,  True,  True,  True],
          [False, False, False,  True,  True],
          [False, False, False, False,  True],
          [False, False, False, False, False]],

         [[False,  True,  True,  True,  True],
          [False, False,  True,  True,  True],
          [False, False, False,  True,  True],
          [False, False, False, False,  True],
          [False, False, False, False, False]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[-0.1874,  0.4403,  0.0604,  0.5600, -0.5997],
          [ 0.0106, -0.4968, -0.3349, -0.3467,  0.9279],
          [-0.2654,  0.3245, -0.1246,  0.5935, -0.2827],
          [ 0.0576, -0.1604, -0.0361, -0.1888,  0.2317],
          [ 0.3076,  0.0456,  0.4405, -0.4064, -0.4711]],

         [[ 0.0284, -0.0575,  0.0130,  0.0626,  0.0123],
          [ 0.1263, -0.0123,  0.1899,  0.0893, -0.2544],
          [ 0.1344, -0.0732,  0.1694,  0.1416, -0.1944],
          [ 0.1154,  0.1800,  0.2771, -0.0668, -0.4753],
          [-0.3056,  0.0493, -0.4490, -0.2312,  0.5911]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[-1.8736e-01, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],
          [ 1.0593e-02, -4.9684e-01, -1.0000e+09, -1.0000e+09, -1.0000e+09],
          [-2.6538e-01,  3.2451e-01, -1.2456e-01, -1.0000e+09, -1.0000e+09],
          [ 5.7590e-02, -1.6036e-01, -3.6138e-02, -1.8883e-01, -1.0000e+09],
          [ 3.0758e-01,  4.5575e-02,  4.4052e-01, -4.0636e-01, -4.7110e-01]],

         [[ 2.8393e-02, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],
          [ 1.2630e-01, -1.2340e-02, -1.0000e+09, -1.0000e+09, -1.0000e+09],
          [ 1.3436e-01, -7.3228e-02,  1.6944e-01, -1.0000e+09, -1.0000e+09],
          [ 1.1538e-01,  1.7997e-01,  2.7708e-01, -6.6756e-02, -1.0000e+09],
          [-3.0565e-01,  4.9254e-02, -4.4903e-01, -2.3120e-01,  5.9115e-01]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.6242, 0.3758, 0.0000, 0.0000, 0.0000],
          [0.2528, 0.4561, 0.2911, 0.0000, 0.0000],
          [0.2860, 0.2300, 0.2604, 0.2235, 0.0000],
          [0.2590, 0.1993, 0.2959, 0.1269, 0.1189]],

         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5346, 0.4654, 0.0000, 0.0000, 0.0000],
          [0.3511, 0.2853, 0.3636, 0.0000, 0.0000],
          [0.2454, 0.2617, 0.2884, 0.2045, 0.0000],
          [0.1466, 0.2091, 0.1270, 0.1579, 0.3594]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.3576,  0.2596],
          [ 0.1102, -0.1453],
          [ 0.0416, -0.3388],
          [ 0.0334, -0.1018],
          [ 0.0740, -0.0156]],

         [[ 0.6058, -0.6189],
          [ 0.1083, -0.1986],
          [ 0.3060, -0.3789],
          [ 0.2262, -0.1337],
          [-0.0679,  0.1365]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.6242, 0.3758, 0.0000, 0.0000, 0.0000],
          [0.2528, 0.4561, 0.2911, 0.0000, 0.0000],
          [0.2860, 0.2300, 0.2604, 0.2235, 0.0000],
          [0.2590, 0.1993, 0.2959, 0.1269, 0.1189]],

         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],
          [0.5346, 0.4654, 0.0000, 0.0000, 0.0000],
          [0.3511, 0.2853, 0.3636, 0.0000, 0.0000],
          [0.2454, 0.2617, 0.2884, 0.2045, 0.0000],
          [0.1466, 0.2091, 0.1270, 0.1579, 0.3594]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 5, 5])
```


context: 

```python
tensor([[[[ 0.3576,  0.2596],
          [ 0.1102, -0.1453],
          [ 0.0416, -0.3388],
          [ 0.0334, -0.1018],
          [ 0.0740, -0.0156]],

         [[ 0.6058, -0.6189],
          [ 0.1083, -0.1986],
          [ 0.3060, -0.3789],
          [ 0.2262, -0.1337],
          [-0.0679,  0.1365]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.3576,  0.2596,  0.6058, -0.6189],
         [ 0.1102, -0.1453,  0.1083, -0.1986],
         [ 0.0416, -0.3388,  0.3060, -0.3789],
         [ 0.0334, -0.1018,  0.2262, -0.1337],
         [ 0.0740, -0.0156, -0.0679,  0.1365]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[-0.2674,  0.2568,  0.0468,  0.5361],
         [ 0.0442,  0.0074, -0.0303,  0.0530],
         [ 0.1298, -0.0220, -0.1120,  0.1482],
         [ 0.0021,  0.0236, -0.0152,  0.0966],
         [-0.0162,  0.0022,  0.0570, -0.1119]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 5, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-1.2759,  1.4300, -0.4741,  0.3200],
         [ 1.7019, -0.6333, -0.2778, -0.7908],
         [-0.7691,  1.5836, -0.9406,  0.1261],
         [ 0.5231, -1.2928, -0.5530,  1.3226],
         [-0.5783, -1.0915,  1.5697,  0.1002]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 5, 4])
```


output + residual: 

```python
tensor([[[-1.5433,  1.6868, -0.4273,  0.8561],
         [ 1.7461, -0.6259, -0.3081, -0.7378],
         [-0.6393,  1.5616, -1.0525,  0.2743],
         [ 0.5252, -1.2692, -0.5682,  1.4192],
         [-0.5945, -1.0894,  1.6267, -0.0118]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-1.3700,  1.2541, -0.4634,  0.5793],
         [ 1.7108, -0.6382, -0.3235, -0.7491],
         [-0.6732,  1.5208, -1.0851,  0.2376],
         [ 0.4853, -1.2616, -0.5792,  1.3555],
         [-0.5643, -1.0481,  1.6071,  0.0054]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 5, 4])
```


## MultiHeadAttention


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


input_Q: 

```python
tensor([[[-1.3700,  1.2541, -0.4634,  0.5793],
         [ 1.7108, -0.6382, -0.3235, -0.7491],
         [-0.6732,  1.5208, -1.0851,  0.2376],
         [ 0.4853, -1.2616, -0.5792,  1.3555],
         [-0.5643, -1.0481,  1.6071,  0.0054]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_Q.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_K: 

```python
tensor([[[ 0.6868, -1.7263,  0.5829,  0.4565],
         [ 1.6033, -1.1500, -0.2725, -0.1809],
         [ 1.1261, -0.7021, -1.2486,  0.8246],
         [-0.2686, -0.4144, -0.9857,  1.6687],
         [-0.2267, -1.5400,  0.9742,  0.7925]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_K.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


input_V: 

```python
tensor([[[ 0.6868, -1.7263,  0.5829,  0.4565],
         [ 1.6033, -1.1500, -0.2725, -0.1809],
         [ 1.1261, -0.7021, -1.2486,  0.8246],
         [-0.2686, -0.4144, -0.9857,  1.6687],
         [-0.2267, -1.5400,  0.9742,  0.7925]]],
       grad_fn=<NativeLayerNormBackward0>)
```


input_V.shape：[batch_size, seq_len, d_model]: 

```python
torch.Size([1, 5, 4])
```


attn_mask: 

```python
tensor([[[False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True],
         [False, False, False, False,  True]]])
```


attn_mask.shape: 

```python
torch.Size([1, 5, 5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>QKV的分头操作</div>


例如Q的分头操作: 

```python
Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)
```


Q: 

```python
tensor([[[[ 0.0433,  0.4987],
          [ 0.0708, -0.8455],
          [ 0.1549,  0.0338],
          [-0.9536, -0.4007],
          [-0.0438,  0.6568]],

         [[ 0.0344,  0.3453],
          [-0.1933, -0.7081],
          [-0.1245, -0.0866],
          [-0.2383, -0.8358],
          [ 0.3322,  0.7814]]]], grad_fn=<TransposeBackward0>)
```


Q.view.shape：[batch_size, seq_len, n_heads, d_q]: 

```python
[1, 'seq_len', 2, 2]
```


Q.shape：[batch_size, n_heads, seq_len, d_q]: 

```python
torch.Size([1, 2, 5, 2])
```


K: 

```python
tensor([[[[ 0.0340,  0.0352],
          [ 0.1903,  0.0466],
          [-0.2709,  0.3840],
          [-0.6189,  0.4860],
          [-0.1048,  0.0250]],

         [[ 0.8016, -0.1494],
          [ 1.0380, -0.4053],
          [ 0.4957,  0.0590],
          [-0.2779,  0.5567],
          [ 0.3398,  0.1011]]]], grad_fn=<TransposeBackward0>)
```


K.shape：[batch_size, n_heads, seq_len, d_k]: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 1.0637, -0.5323],
          [ 0.9685, -0.5174],
          [-0.2034, -0.3953],
          [-0.9852, -0.1468],
          [ 0.7337, -0.3573]],

         [[ 0.1639, -0.2189],
          [-0.3600, -0.3702],
          [-0.3778, -0.5270],
          [ 0.0821, -0.3430],
          [ 0.4870, -0.0390]]]], grad_fn=<TransposeBackward0>)
```


V.shape：[batch_size, n_heads, seq_len, d_v]: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>attn_mask的分头操作</div>


: 

```python
attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5, 5])
```


### ScaledDotProductAttention


<div style='color:#fe618e;font-weight:800;font-size:23px;'>输入</div>


Q: 

```python
tensor([[[[ 0.0433,  0.4987],
          [ 0.0708, -0.8455],
          [ 0.1549,  0.0338],
          [-0.9536, -0.4007],
          [-0.0438,  0.6568]],

         [[ 0.0344,  0.3453],
          [-0.1933, -0.7081],
          [-0.1245, -0.0866],
          [-0.2383, -0.8358],
          [ 0.3322,  0.7814]]]], grad_fn=<TransposeBackward0>)
```


Q.shape: 

```python
torch.Size([1, 2, 5, 2])
```


K: 

```python
tensor([[[[ 0.0340,  0.0352],
          [ 0.1903,  0.0466],
          [-0.2709,  0.3840],
          [-0.6189,  0.4860],
          [-0.1048,  0.0250]],

         [[ 0.8016, -0.1494],
          [ 1.0380, -0.4053],
          [ 0.4957,  0.0590],
          [-0.2779,  0.5567],
          [ 0.3398,  0.1011]]]], grad_fn=<TransposeBackward0>)
```


K.shape: 

```python
torch.Size([1, 2, 5, 2])
```


V: 

```python
tensor([[[[ 1.0637, -0.5323],
          [ 0.9685, -0.5174],
          [-0.2034, -0.3953],
          [-0.9852, -0.1468],
          [ 0.7337, -0.3573]],

         [[ 0.1639, -0.2189],
          [-0.3600, -0.3702],
          [-0.3778, -0.5270],
          [ 0.0821, -0.3430],
          [ 0.4870, -0.0390]]]], grad_fn=<TransposeBackward0>)
```


V.shape: 

```python
torch.Size([1, 2, 5, 2])
```


attn_mask: 

```python
tensor([[[[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]],

         [[False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True],
          [False, False, False, False,  True]]]])
```


attn_mask.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#fd7949;font-weight:800;font-size:23px;'>计算相似性得分</div>


: 

```python
scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)
```


scores: 

```python
tensor([[[[ 0.0134,  0.0222,  0.1271,  0.1524,  0.0056],
          [-0.0193, -0.0183, -0.2431, -0.3215, -0.0202],
          [ 0.0046,  0.0220, -0.0205, -0.0561, -0.0109],
          [-0.0329, -0.1415,  0.0739,  0.2797,  0.0636],
          [ 0.0153,  0.0157,  0.1867,  0.2448,  0.0149]],

         [[-0.0170, -0.0737,  0.0264,  0.1292,  0.0330],
          [-0.0347,  0.0611, -0.0973, -0.2408, -0.0971],
          [-0.0614, -0.0666, -0.0473, -0.0096, -0.0361],
          [-0.0468,  0.0647, -0.1184, -0.2822, -0.1170],
          [ 0.1057,  0.0198,  0.1490,  0.2423,  0.1357]]]],
       grad_fn=<DivBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#ff9702;font-weight:800;font-size:23px;'>mask操作</div>


: 

```python
scores.masked_fill_(attn_mask, -1e9)
```


scores: 

```python
tensor([[[[ 1.3450e-02,  2.2249e-02,  1.2709e-01,  1.5241e-01, -1.0000e+09],
          [-1.9344e-02, -1.8321e-02, -2.4312e-01, -3.2153e-01, -1.0000e+09],
          [ 4.5606e-03,  2.1954e-02, -2.0479e-02, -5.6149e-02, -1.0000e+09],
          [-3.2870e-02, -1.4152e-01,  7.3891e-02,  2.7967e-01, -1.0000e+09],
          [ 1.5294e-02,  1.5740e-02,  1.8670e-01,  2.4484e-01, -1.0000e+09]],

         [[-1.6993e-02, -7.3746e-02,  2.6445e-02,  1.2918e-01, -1.0000e+09],
          [-3.4744e-02,  6.1121e-02, -9.7272e-02, -2.4079e-01, -1.0000e+09],
          [-6.1443e-02, -6.6590e-02, -4.7263e-02, -9.6057e-03, -1.0000e+09],
          [-4.6784e-02,  6.4656e-02, -1.1838e-01, -2.8219e-01, -1.0000e+09],
          [ 1.0574e-01,  1.9827e-02,  1.4902e-01,  2.4235e-01, -1.0000e+09]]]],
       grad_fn=<MaskedFillBackward0>)
```


scores.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>计算相似性权重</div>


: 

```python
attn = nn.Softmax(dim=-1)(scores)
```


attn: 

```python
tensor([[[[0.2337, 0.2358, 0.2619, 0.2686, 0.0000],
          [0.2825, 0.2828, 0.2259, 0.2088, 0.0000],
          [0.2542, 0.2587, 0.2479, 0.2392, 0.0000],
          [0.2285, 0.2050, 0.2542, 0.3123, 0.0000],
          [0.2249, 0.2250, 0.2670, 0.2830, 0.0000]],

         [[0.2412, 0.2279, 0.2519, 0.2791, 0.0000],
          [0.2595, 0.2856, 0.2438, 0.2112, 0.0000],
          [0.2462, 0.2449, 0.2497, 0.2593, 0.0000],
          [0.2605, 0.2912, 0.2425, 0.2058, 0.0000],
          [0.2434, 0.2234, 0.2542, 0.2790, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 5, 5])
```


<div style='color:#3296ee;font-weight:800;font-size:23px;'>计算attention</div>


: 

```python
context = torch.matmul(attn, V)
```


context: 

```python
tensor([[[[ 0.1591, -0.3893],
          [ 0.3227, -0.4166],
          [ 0.2348, -0.4022],
          [ 0.0821, -0.3740],
          [ 0.1241, -0.3832]],

         [[-0.1147, -0.3656],
          [-0.1350, -0.3634],
          [-0.1209, -0.3650],
          [-0.1369, -0.3632],
          [-0.1136, -0.3656]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>获得attention的结果和相似性</div>


: 

```python
context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)
```


attn: 

```python
tensor([[[[0.2337, 0.2358, 0.2619, 0.2686, 0.0000],
          [0.2825, 0.2828, 0.2259, 0.2088, 0.0000],
          [0.2542, 0.2587, 0.2479, 0.2392, 0.0000],
          [0.2285, 0.2050, 0.2542, 0.3123, 0.0000],
          [0.2249, 0.2250, 0.2670, 0.2830, 0.0000]],

         [[0.2412, 0.2279, 0.2519, 0.2791, 0.0000],
          [0.2595, 0.2856, 0.2438, 0.2112, 0.0000],
          [0.2462, 0.2449, 0.2497, 0.2593, 0.0000],
          [0.2605, 0.2912, 0.2425, 0.2058, 0.0000],
          [0.2434, 0.2234, 0.2542, 0.2790, 0.0000]]]],
       grad_fn=<SoftmaxBackward0>)
```


attn.shape: 

```python
torch.Size([1, 2, 5, 5])
```


context: 

```python
tensor([[[[ 0.1591, -0.3893],
          [ 0.3227, -0.4166],
          [ 0.2348, -0.4022],
          [ 0.0821, -0.3740],
          [ 0.1241, -0.3832]],

         [[-0.1147, -0.3656],
          [-0.1350, -0.3634],
          [-0.1209, -0.3650],
          [-0.1369, -0.3632],
          [-0.1136, -0.3656]]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 2, 5, 2])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>将不同头的输出向量拼接在一起：reshape(batch_size, -1, n_heads * d_v</div>


: 

```python
context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)
```


context: 

```python
tensor([[[ 0.1591, -0.3893, -0.1147, -0.3656],
         [ 0.3227, -0.4166, -0.1350, -0.3634],
         [ 0.2348, -0.4022, -0.1209, -0.3650],
         [ 0.0821, -0.3740, -0.1369, -0.3632],
         [ 0.1241, -0.3832, -0.1136, -0.3656]]], grad_fn=<UnsafeViewBackward0>)
```


context.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>再经过fc操作</div>


: 

```python
output = self.fc(context)
```


self.fc: 

```python
Linear(in_features=4, out_features=4, bias=False)
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>多头注意力机制算出的attention</div>


output: 

```python
tensor([[[ 0.1116, -0.0040,  0.0624, -0.1185],
         [ 0.0733,  0.0247,  0.1043, -0.0886],
         [ 0.0925,  0.0087,  0.0825, -0.1045],
         [ 0.1432, -0.0117,  0.0350, -0.1346],
         [ 0.1212, -0.0095,  0.0526, -0.1251]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 5, 4])
```


## 残差操作和层归一化


<div style='color:#3296ee;font-weight:800;font-size:23px;'>残差操作</div>


residual: 

```python
tensor([[[-1.3700,  1.2541, -0.4634,  0.5793],
         [ 1.7108, -0.6382, -0.3235, -0.7491],
         [-0.6732,  1.5208, -1.0851,  0.2376],
         [ 0.4853, -1.2616, -0.5792,  1.3555],
         [-0.5643, -1.0481,  1.6071,  0.0054]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 5, 4])
```


output + residual: 

```python
tensor([[[-1.2584,  1.2501, -0.4010,  0.4607],
         [ 1.7841, -0.6136, -0.2193, -0.8376],
         [-0.5807,  1.5295, -1.0026,  0.1330],
         [ 0.6285, -1.2733, -0.5442,  1.2209],
         [-0.4431, -1.0577,  1.6598, -0.1198]]], grad_fn=<AddBackward0>)
```


(output + residual).shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#7fd02b;font-weight:800;font-size:23px;'>层归一化之后</div>


ans_tuple1[0]: 

```python
tensor([[[-1.3554,  1.3191, -0.4413,  0.4775],
         [ 1.6922, -0.6187, -0.2387, -0.8347],
         [-0.6245,  1.5701, -1.0634,  0.1178],
         [ 0.6364, -1.3141, -0.5663,  1.2440],
         [-0.4482, -1.0565,  1.6329, -0.1282]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans_tuple1[0].shape: 

```python
torch.Size([1, 5, 4])
```


## PoswiseFeedForwardNet


<div style='color:#fd7949;font-weight:800;font-size:23px;'>输入</div>


inputs: 

```python
tensor([[[-1.3554,  1.3191, -0.4413,  0.4775],
         [ 1.6922, -0.6187, -0.2387, -0.8347],
         [-0.6245,  1.5701, -1.0634,  0.1178],
         [ 0.6364, -1.3141, -0.5663,  1.2440],
         [-0.4482, -1.0565,  1.6329, -0.1282]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc操作的代码</div>


: 

```python
output = self.fc(inputs)
```


inputs: 

```python
tensor([[[-1.3554,  1.3191, -0.4413,  0.4775],
         [ 1.6922, -0.6187, -0.2387, -0.8347],
         [-0.6245,  1.5701, -1.0634,  0.1178],
         [ 0.6364, -1.3141, -0.5663,  1.2440],
         [-0.4482, -1.0565,  1.6329, -0.1282]]],
       grad_fn=<NativeLayerNormBackward0>)
```


inputs.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>fc原来是d_model->d_ff->d_model</div>


self.fc: 

```python
Sequential(
  (0): Linear(in_features=4, out_features=8, bias=False)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=4, bias=False)
)
```


output: 

```python
tensor([[[-0.0223, -0.1665,  0.3323,  0.1385],
         [-0.2340, -0.0152, -0.2748, -0.1125],
         [-0.0408, -0.1559,  0.1479,  0.0995],
         [-0.1554,  0.0570, -0.2524, -0.1121],
         [ 0.0017,  0.1817,  0.2671, -0.3700]]], grad_fn=<UnsafeViewBackward0>)
```


output.shape: 

```python
torch.Size([1, 5, 4])
```


## 前馈层后的层归一化和残差


<div style='color:#fe618e;font-weight:800;font-size:23px;'>FeedForward后的层归一化和残差</div>


: 

```python
ans = nn.LayerNorm(d_model).to(device)(output + residual)
```


residual: 

```python
tensor([[[-1.3554,  1.3191, -0.4413,  0.4775],
         [ 1.6922, -0.6187, -0.2387, -0.8347],
         [-0.6245,  1.5701, -1.0634,  0.1178],
         [ 0.6364, -1.3141, -0.5663,  1.2440],
         [-0.4482, -1.0565,  1.6329, -0.1282]]],
       grad_fn=<NativeLayerNormBackward0>)
```


residual.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#00c2ea;font-weight:800;font-size:23px;'>残差和层归一化之后的结果</div>


ans: 

```python
tensor([[[-1.5269,  1.1410, -0.1892,  0.5752],
         [ 1.7077, -0.5013, -0.3742, -0.8322],
         [-0.7434,  1.5367, -1.0176,  0.2243],
         [ 0.6196, -1.1852, -0.7300,  1.2956],
         [-0.4251, -0.8151,  1.7123, -0.4721]]],
       grad_fn=<NativeLayerNormBackward0>)
```


ans.shape: 

```python
torch.Size([1, 5, 4])
```


# Decoder结束


<div style='color:#fe618e;font-weight:800;font-size:23px;'>model的decode操作</div>


: 

```python
dec_outputs, _, _ = model.decoder(dec_input, enc_input, enc_outputs)
```


dec_outputs: 

```python
tensor([[[-1.5269,  1.1410, -0.1892,  0.5752],
         [ 1.7077, -0.5013, -0.3742, -0.8322],
         [-0.7434,  1.5367, -1.0176,  0.2243],
         [ 0.6196, -1.1852, -0.7300,  1.2956],
         [-0.4251, -0.8151,  1.7123, -0.4721]]],
       grad_fn=<NativeLayerNormBackward0>)
```


dec_outputs.shape: 

```python
torch.Size([1, 5, 4])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>model的projection操作</div>


: 

```python
projected = model.projection(dec_outputs)
```


projected: 

```python
tensor([[[-0.1054,  3.5657, -3.4626,  0.4159, -0.1576, -0.8695, -1.0392],
         [-0.0058, -2.9183,  4.2125,  1.5481, -0.0509, -1.0258, -0.4025],
         [-0.2201,  3.1963, -1.4838,  3.0186, -0.4317, -3.3029, -2.1673],
         [ 0.0683, -1.6645, -0.5991, -0.0841, -0.2203, -0.3545,  4.2450],
         [ 0.2118, -1.0946, -0.3283, -4.1451,  0.6214,  4.4055,  0.4111]]],
       grad_fn=<UnsafeViewBackward0>)
```


projected.shape: 

```python
torch.Size([1, 5, 7])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>生成prob</div>


: 

```python
prob = projected.squeeze(0).max(dim=-1, keepdim=False)[1]
```


prob: 

```python
tensor([1, 2, 1, 6, 5])
```


prob.shape: 

```python
torch.Size([5])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>生成next_word</div>


: 

```python
next_word = prob.data[-1]
```


next_word: 

```python
tensor(5)
```


next_word.shape: 

```python
torch.Size([])
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>迭代下一轮</div>


: 

```python
next_symbol = next_word
```


next_symbol: 

```python
tensor(5)
```


<div style='color:#fe618e;font-weight:800;font-size:23px;'>【greedy_decoder】输出</div>


greedy_dec_predict: 

```python
tensor([[1, 2, 3, 6]])
```


greedy_dec_predict.shape: 

```python
torch.Size([1, 4])
```


# greedy_decoder结束

tensor([1, 2, 3, 4, 0]) -> tensor([1, 2, 3, 6])
['我', '喜', '欢', '你', 'P'] -> ['I', 'love', 'you', '.']

# 结束

